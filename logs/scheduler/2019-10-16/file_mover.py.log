[2019-10-16 11:34:17,908] {logging_mixin.py:95} INFO - [2019-10-16 11:34:17,908] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=764
[2019-10-16 11:34:17,911] {scheduler_job.py:146} INFO - Started process (PID=764) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 11:34:17,913] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 11:34:17,913] {logging_mixin.py:95} INFO - [2019-10-16 11:34:17,913] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 11:34:17,921] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 11:34:17,959] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 11:34:17,993] {scheduler_job.py:1265} INFO - Created <DagRun file_operations_pipeline @ 2019-10-16T05:55:00+00:00: scheduled__2019-10-16T05:55:00+00:00, externally triggered: False>
[2019-10-16 11:34:17,997] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:25:00+00:00: scheduled__2019-10-15T10:25:00+00:00, externally triggered: False>
[2019-10-16 11:34:18,020] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:30:00+00:00: scheduled__2019-10-15T10:30:00+00:00, externally triggered: False>
[2019-10-16 11:34:18,045] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 05:55:00+00:00: scheduled__2019-10-16T05:55:00+00:00, externally triggered: False>
[2019-10-16 11:34:18,116] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 11:34:18,120] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.unzip_source 2019-10-15 10:25:00+00:00 [scheduled]> in ORM
[2019-10-16 11:34:18,131] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.sleep 2019-10-15 10:30:00+00:00 [scheduled]> in ORM
[2019-10-16 11:34:18,135] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.zip_target 2019-10-15 10:30:00+00:00 [scheduled]> in ORM
[2019-10-16 11:34:18,139] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.sleep 2019-10-16 05:55:00+00:00 [scheduled]> in ORM
[2019-10-16 11:34:18,143] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.zip_target 2019-10-16 05:55:00+00:00 [scheduled]> in ORM
[2019-10-16 11:34:18,165] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.254 seconds
[2019-10-16 12:23:44,551] {logging_mixin.py:95} INFO - [2019-10-16 12:23:44,550] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=4190
[2019-10-16 12:23:44,553] {scheduler_job.py:146} INFO - Started process (PID=4190) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:23:44,556] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 12:23:44,557] {logging_mixin.py:95} INFO - [2019-10-16 12:23:44,557] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:23:44,564] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:23:44,594] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 12:23:44,626] {scheduler_job.py:1265} INFO - Created <DagRun file_operations_pipeline @ 2019-10-16T06:45:00+00:00: scheduled__2019-10-16T06:45:00+00:00, externally triggered: False>
[2019-10-16 12:23:44,630] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:25:00+00:00: scheduled__2019-10-15T10:25:00+00:00, externally triggered: False>
[2019-10-16 12:23:44,653] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:30:00+00:00: scheduled__2019-10-15T10:30:00+00:00, externally triggered: False>
[2019-10-16 12:23:44,677] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 05:55:00+00:00: scheduled__2019-10-16T05:55:00+00:00, externally triggered: False>
[2019-10-16 12:23:44,701] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:45:00+00:00: scheduled__2019-10-16T06:45:00+00:00, externally triggered: False>
[2019-10-16 12:23:44,797] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 12:23:44,801] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.unzip_source 2019-10-15 10:25:00+00:00 [scheduled]> in ORM
[2019-10-16 12:23:44,805] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.sleep 2019-10-15 10:30:00+00:00 [scheduled]> in ORM
[2019-10-16 12:23:44,809] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.zip_target 2019-10-15 10:30:00+00:00 [scheduled]> in ORM
[2019-10-16 12:23:44,813] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.sleep 2019-10-16 05:55:00+00:00 [scheduled]> in ORM
[2019-10-16 12:23:44,817] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.zip_target 2019-10-16 05:55:00+00:00 [scheduled]> in ORM
[2019-10-16 12:23:44,821] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.sleep 2019-10-16 06:45:00+00:00 [scheduled]> in ORM
[2019-10-16 12:23:44,825] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.zip_target 2019-10-16 06:45:00+00:00 [scheduled]> in ORM
[2019-10-16 12:23:44,838] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.285 seconds
[2019-10-16 12:23:54,677] {logging_mixin.py:95} INFO - [2019-10-16 12:23:54,677] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=4352
[2019-10-16 12:23:54,705] {scheduler_job.py:146} INFO - Started process (PID=4352) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:23:54,726] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 12:23:54,727] {logging_mixin.py:95} INFO - [2019-10-16 12:23:54,727] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:23:54,807] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:23:54,970] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 12:23:55,047] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:25:00+00:00: scheduled__2019-10-15T10:25:00+00:00, externally triggered: False>
[2019-10-16 12:23:55,111] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:30:00+00:00: scheduled__2019-10-15T10:30:00+00:00, externally triggered: False>
[2019-10-16 12:23:55,174] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 05:55:00+00:00: scheduled__2019-10-16T05:55:00+00:00, externally triggered: False>
[2019-10-16 12:23:55,258] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:45:00+00:00: scheduled__2019-10-16T06:45:00+00:00, externally triggered: False>
[2019-10-16 12:23:55,578] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 12:23:55,602] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.897 seconds
[2019-10-16 12:24:04,883] {logging_mixin.py:95} INFO - [2019-10-16 12:24:04,882] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=4480
[2019-10-16 12:24:04,887] {scheduler_job.py:146} INFO - Started process (PID=4480) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:24:04,893] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 12:24:04,894] {logging_mixin.py:95} INFO - [2019-10-16 12:24:04,894] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:24:04,913] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:24:04,972] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 12:24:05,008] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:25:00+00:00: scheduled__2019-10-15T10:25:00+00:00, externally triggered: False>
[2019-10-16 12:24:05,053] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:30:00+00:00: scheduled__2019-10-15T10:30:00+00:00, externally triggered: False>
[2019-10-16 12:24:05,089] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 05:55:00+00:00: scheduled__2019-10-16T05:55:00+00:00, externally triggered: False>
[2019-10-16 12:24:05,120] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:45:00+00:00: scheduled__2019-10-16T06:45:00+00:00, externally triggered: False>
[2019-10-16 12:24:05,243] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 12:24:05,249] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.print_first_ten_lines 2019-10-15 10:25:00+00:00 [scheduled]> in ORM
[2019-10-16 12:24:05,256] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.move_target_to_source 2019-10-15 10:30:00+00:00 [scheduled]> in ORM
[2019-10-16 12:24:05,265] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.move_target_to_source 2019-10-16 05:55:00+00:00 [scheduled]> in ORM
[2019-10-16 12:24:05,271] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.move_target_to_source 2019-10-16 06:45:00+00:00 [scheduled]> in ORM
[2019-10-16 12:24:05,288] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.400 seconds
[2019-10-16 12:24:15,004] {logging_mixin.py:95} INFO - [2019-10-16 12:24:15,004] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=4607
[2019-10-16 12:24:15,006] {scheduler_job.py:146} INFO - Started process (PID=4607) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:24:15,009] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 12:24:15,010] {logging_mixin.py:95} INFO - [2019-10-16 12:24:15,010] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:24:15,018] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:24:15,050] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 12:24:15,069] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:25:00+00:00: scheduled__2019-10-15T10:25:00+00:00, externally triggered: False>
[2019-10-16 12:24:15,087] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:30:00+00:00: scheduled__2019-10-15T10:30:00+00:00, externally triggered: False>
[2019-10-16 12:24:15,101] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 05:55:00+00:00: scheduled__2019-10-16T05:55:00+00:00, externally triggered: False>
[2019-10-16 12:24:15,118] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:45:00+00:00: scheduled__2019-10-16T06:45:00+00:00, externally triggered: False>
[2019-10-16 12:24:15,193] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 12:24:15,197] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.unzip_source 2019-10-16 06:45:00+00:00 [scheduled]> in ORM
[2019-10-16 12:24:15,214] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.208 seconds
[2019-10-16 12:24:25,097] {logging_mixin.py:95} INFO - [2019-10-16 12:24:25,097] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=4672
[2019-10-16 12:24:25,099] {scheduler_job.py:146} INFO - Started process (PID=4672) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:24:25,103] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 12:24:25,103] {logging_mixin.py:95} INFO - [2019-10-16 12:24:25,103] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:24:25,111] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:24:25,144] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 12:24:25,165] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:25:00+00:00: scheduled__2019-10-15T10:25:00+00:00, externally triggered: False>
[2019-10-16 12:24:25,179] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:30:00+00:00: scheduled__2019-10-15T10:30:00+00:00, externally triggered: False>
[2019-10-16 12:24:25,190] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 05:55:00+00:00: scheduled__2019-10-16T05:55:00+00:00, externally triggered: False>
[2019-10-16 12:24:25,203] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:45:00+00:00: scheduled__2019-10-16T06:45:00+00:00, externally triggered: False>
[2019-10-16 12:24:25,269] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 12:24:25,273] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.print_first_ten_lines 2019-10-16 06:45:00+00:00 [scheduled]> in ORM
[2019-10-16 12:24:25,286] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.187 seconds
[2019-10-16 12:24:35,186] {logging_mixin.py:95} INFO - [2019-10-16 12:24:35,186] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=4734
[2019-10-16 12:24:35,189] {scheduler_job.py:146} INFO - Started process (PID=4734) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:24:35,192] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 12:24:35,192] {logging_mixin.py:95} INFO - [2019-10-16 12:24:35,192] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:24:35,200] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:24:35,234] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 12:24:35,253] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:25:00+00:00: scheduled__2019-10-15T10:25:00+00:00, externally triggered: False>
[2019-10-16 12:24:35,267] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:30:00+00:00: scheduled__2019-10-15T10:30:00+00:00, externally triggered: False>
[2019-10-16 12:24:35,278] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 05:55:00+00:00: scheduled__2019-10-16T05:55:00+00:00, externally triggered: False>
[2019-10-16 12:24:35,291] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:45:00+00:00: scheduled__2019-10-16T06:45:00+00:00, externally triggered: False>
[2019-10-16 12:24:35,357] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 12:24:35,366] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.178 seconds
[2019-10-16 12:24:45,279] {logging_mixin.py:95} INFO - [2019-10-16 12:24:45,279] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=4759
[2019-10-16 12:24:45,282] {scheduler_job.py:146} INFO - Started process (PID=4759) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:24:45,285] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 12:24:45,285] {logging_mixin.py:95} INFO - [2019-10-16 12:24:45,285] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:24:45,293] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:24:45,327] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 12:24:45,345] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:25:00+00:00: scheduled__2019-10-15T10:25:00+00:00, externally triggered: False>
[2019-10-16 12:24:45,359] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:30:00+00:00: scheduled__2019-10-15T10:30:00+00:00, externally triggered: False>
[2019-10-16 12:24:45,371] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 05:55:00+00:00: scheduled__2019-10-16T05:55:00+00:00, externally triggered: False>
[2019-10-16 12:24:45,383] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:45:00+00:00: scheduled__2019-10-16T06:45:00+00:00, externally triggered: False>
[2019-10-16 12:24:45,448] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 12:24:45,454] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.172 seconds
[2019-10-16 12:24:55,411] {logging_mixin.py:95} INFO - [2019-10-16 12:24:55,410] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=4825
[2019-10-16 12:24:55,418] {scheduler_job.py:146} INFO - Started process (PID=4825) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:24:55,427] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 12:24:55,428] {logging_mixin.py:95} INFO - [2019-10-16 12:24:55,428] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:24:55,444] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:24:55,487] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 12:24:55,508] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:25:00+00:00: scheduled__2019-10-15T10:25:00+00:00, externally triggered: False>
[2019-10-16 12:24:55,523] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:30:00+00:00: scheduled__2019-10-15T10:30:00+00:00, externally triggered: False>
[2019-10-16 12:24:55,535] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 05:55:00+00:00: scheduled__2019-10-16T05:55:00+00:00, externally triggered: False>
[2019-10-16 12:24:55,549] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:45:00+00:00: scheduled__2019-10-16T06:45:00+00:00, externally triggered: False>
[2019-10-16 12:24:55,619] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 12:24:55,625] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.208 seconds
[2019-10-16 12:25:05,546] {logging_mixin.py:95} INFO - [2019-10-16 12:25:05,545] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=4884
[2019-10-16 12:25:05,554] {scheduler_job.py:146} INFO - Started process (PID=4884) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:25:05,562] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 12:25:05,563] {logging_mixin.py:95} INFO - [2019-10-16 12:25:05,563] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:25:05,586] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:25:05,657] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 12:25:05,714] {scheduler_job.py:1265} INFO - Created <DagRun file_operations_pipeline @ 2019-10-16T06:50:00+00:00: scheduled__2019-10-16T06:50:00+00:00, externally triggered: False>
[2019-10-16 12:25:05,720] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:25:00+00:00: scheduled__2019-10-15T10:25:00+00:00, externally triggered: False>
[2019-10-16 12:25:05,739] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:30:00+00:00: scheduled__2019-10-15T10:30:00+00:00, externally triggered: False>
[2019-10-16 12:25:05,753] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 05:55:00+00:00: scheduled__2019-10-16T05:55:00+00:00, externally triggered: False>
[2019-10-16 12:25:05,764] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:45:00+00:00: scheduled__2019-10-16T06:45:00+00:00, externally triggered: False>
[2019-10-16 12:25:05,776] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:50:00+00:00: scheduled__2019-10-16T06:50:00+00:00, externally triggered: False>
[2019-10-16 12:25:05,872] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 12:25:05,876] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.sleep 2019-10-16 06:50:00+00:00 [scheduled]> in ORM
[2019-10-16 12:25:05,881] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.zip_target 2019-10-16 06:50:00+00:00 [scheduled]> in ORM
[2019-10-16 12:25:05,898] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.344 seconds
[2019-10-16 12:25:15,656] {logging_mixin.py:95} INFO - [2019-10-16 12:25:15,656] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=4982
[2019-10-16 12:25:15,662] {scheduler_job.py:146} INFO - Started process (PID=4982) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:25:15,669] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 12:25:15,670] {logging_mixin.py:95} INFO - [2019-10-16 12:25:15,669] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:25:15,683] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:25:15,716] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 12:25:15,735] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:25:00+00:00: scheduled__2019-10-15T10:25:00+00:00, externally triggered: False>
[2019-10-16 12:25:15,749] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:30:00+00:00: scheduled__2019-10-15T10:30:00+00:00, externally triggered: False>
[2019-10-16 12:25:15,762] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 05:55:00+00:00: scheduled__2019-10-16T05:55:00+00:00, externally triggered: False>
[2019-10-16 12:25:15,775] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:45:00+00:00: scheduled__2019-10-16T06:45:00+00:00, externally triggered: False>
[2019-10-16 12:25:15,789] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:50:00+00:00: scheduled__2019-10-16T06:50:00+00:00, externally triggered: False>
[2019-10-16 12:25:15,923] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 12:25:15,929] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.move_target_to_source 2019-10-16 06:50:00+00:00 [scheduled]> in ORM
[2019-10-16 12:25:15,947] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.285 seconds
[2019-10-16 12:25:25,766] {logging_mixin.py:95} INFO - [2019-10-16 12:25:25,766] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=5043
[2019-10-16 12:25:25,770] {scheduler_job.py:146} INFO - Started process (PID=5043) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:25:25,775] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 12:25:25,776] {logging_mixin.py:95} INFO - [2019-10-16 12:25:25,776] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:25:25,790] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:25:25,838] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 12:25:25,875] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:25:00+00:00: scheduled__2019-10-15T10:25:00+00:00, externally triggered: False>
[2019-10-16 12:25:25,896] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:30:00+00:00: scheduled__2019-10-15T10:30:00+00:00, externally triggered: False>
[2019-10-16 12:25:25,919] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 05:55:00+00:00: scheduled__2019-10-16T05:55:00+00:00, externally triggered: False>
[2019-10-16 12:25:25,947] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:45:00+00:00: scheduled__2019-10-16T06:45:00+00:00, externally triggered: False>
[2019-10-16 12:25:25,963] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:50:00+00:00: scheduled__2019-10-16T06:50:00+00:00, externally triggered: False>
[2019-10-16 12:25:26,110] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 12:25:26,114] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.unzip_source 2019-10-16 06:50:00+00:00 [scheduled]> in ORM
[2019-10-16 12:25:26,125] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.355 seconds
[2019-10-16 12:25:35,865] {logging_mixin.py:95} INFO - [2019-10-16 12:25:35,865] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=5110
[2019-10-16 12:25:35,869] {scheduler_job.py:146} INFO - Started process (PID=5110) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:25:35,874] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 12:25:35,875] {logging_mixin.py:95} INFO - [2019-10-16 12:25:35,874] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:25:35,887] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:25:35,939] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 12:25:35,964] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:25:00+00:00: scheduled__2019-10-15T10:25:00+00:00, externally triggered: False>
[2019-10-16 12:25:35,982] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:30:00+00:00: scheduled__2019-10-15T10:30:00+00:00, externally triggered: False>
[2019-10-16 12:25:35,996] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 05:55:00+00:00: scheduled__2019-10-16T05:55:00+00:00, externally triggered: False>
[2019-10-16 12:25:36,010] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:45:00+00:00: scheduled__2019-10-16T06:45:00+00:00, externally triggered: False>
[2019-10-16 12:25:36,021] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:50:00+00:00: scheduled__2019-10-16T06:50:00+00:00, externally triggered: False>
[2019-10-16 12:25:36,097] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 12:25:36,101] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.print_first_ten_lines 2019-10-16 06:50:00+00:00 [scheduled]> in ORM
[2019-10-16 12:25:36,113] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.244 seconds
[2019-10-16 12:25:45,977] {logging_mixin.py:95} INFO - [2019-10-16 12:25:45,977] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=5190
[2019-10-16 12:25:45,980] {scheduler_job.py:146} INFO - Started process (PID=5190) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:25:45,984] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 12:25:45,985] {logging_mixin.py:95} INFO - [2019-10-16 12:25:45,985] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:25:45,997] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:25:46,034] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 12:25:46,056] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:25:00+00:00: scheduled__2019-10-15T10:25:00+00:00, externally triggered: False>
[2019-10-16 12:25:46,072] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:30:00+00:00: scheduled__2019-10-15T10:30:00+00:00, externally triggered: False>
[2019-10-16 12:25:46,090] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 05:55:00+00:00: scheduled__2019-10-16T05:55:00+00:00, externally triggered: False>
[2019-10-16 12:25:46,108] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:45:00+00:00: scheduled__2019-10-16T06:45:00+00:00, externally triggered: False>
[2019-10-16 12:25:46,123] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:50:00+00:00: scheduled__2019-10-16T06:50:00+00:00, externally triggered: False>
[2019-10-16 12:25:46,249] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 12:25:46,262] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.281 seconds
[2019-10-16 12:25:56,107] {logging_mixin.py:95} INFO - [2019-10-16 12:25:56,106] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=5225
[2019-10-16 12:25:56,113] {scheduler_job.py:146} INFO - Started process (PID=5225) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:25:56,122] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 12:25:56,123] {logging_mixin.py:95} INFO - [2019-10-16 12:25:56,123] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:25:56,138] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:25:56,171] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 12:25:56,190] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:25:00+00:00: scheduled__2019-10-15T10:25:00+00:00, externally triggered: False>
[2019-10-16 12:25:56,204] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:30:00+00:00: scheduled__2019-10-15T10:30:00+00:00, externally triggered: False>
[2019-10-16 12:25:56,216] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 05:55:00+00:00: scheduled__2019-10-16T05:55:00+00:00, externally triggered: False>
[2019-10-16 12:25:56,228] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:45:00+00:00: scheduled__2019-10-16T06:45:00+00:00, externally triggered: False>
[2019-10-16 12:25:56,240] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:50:00+00:00: scheduled__2019-10-16T06:50:00+00:00, externally triggered: False>
[2019-10-16 12:25:56,315] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 12:25:56,321] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.208 seconds
[2019-10-16 12:26:06,219] {logging_mixin.py:95} INFO - [2019-10-16 12:26:06,218] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=5251
[2019-10-16 12:26:06,221] {scheduler_job.py:146} INFO - Started process (PID=5251) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:26:06,224] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 12:26:06,225] {logging_mixin.py:95} INFO - [2019-10-16 12:26:06,225] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:26:06,232] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:26:06,264] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 12:26:06,279] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:25:00+00:00: scheduled__2019-10-15T10:25:00+00:00, externally triggered: False>
[2019-10-16 12:26:06,292] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:30:00+00:00: scheduled__2019-10-15T10:30:00+00:00, externally triggered: False>
[2019-10-16 12:26:06,303] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 05:55:00+00:00: scheduled__2019-10-16T05:55:00+00:00, externally triggered: False>
[2019-10-16 12:26:06,316] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:45:00+00:00: scheduled__2019-10-16T06:45:00+00:00, externally triggered: False>
[2019-10-16 12:26:06,327] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:50:00+00:00: scheduled__2019-10-16T06:50:00+00:00, externally triggered: False>
[2019-10-16 12:26:06,399] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 12:26:06,405] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.184 seconds
[2019-10-16 12:26:16,380] {logging_mixin.py:95} INFO - [2019-10-16 12:26:16,379] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=5286
[2019-10-16 12:26:16,386] {scheduler_job.py:146} INFO - Started process (PID=5286) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:26:16,392] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 12:26:16,393] {logging_mixin.py:95} INFO - [2019-10-16 12:26:16,393] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:26:16,403] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:26:16,443] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 12:26:16,464] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:25:00+00:00: scheduled__2019-10-15T10:25:00+00:00, externally triggered: False>
[2019-10-16 12:26:16,481] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:30:00+00:00: scheduled__2019-10-15T10:30:00+00:00, externally triggered: False>
[2019-10-16 12:26:16,493] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 05:55:00+00:00: scheduled__2019-10-16T05:55:00+00:00, externally triggered: False>
[2019-10-16 12:26:16,508] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:45:00+00:00: scheduled__2019-10-16T06:45:00+00:00, externally triggered: False>
[2019-10-16 12:26:16,520] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:50:00+00:00: scheduled__2019-10-16T06:50:00+00:00, externally triggered: False>
[2019-10-16 12:26:16,595] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 12:26:16,599] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.print_first_ten_lines 2019-10-15 10:25:00+00:00 [scheduled]> in ORM
[2019-10-16 12:26:16,603] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.move_target_to_source 2019-10-15 10:30:00+00:00 [scheduled]> in ORM
[2019-10-16 12:26:16,607] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.move_target_to_source 2019-10-16 05:55:00+00:00 [scheduled]> in ORM
[2019-10-16 12:26:16,628] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.242 seconds
[2019-10-16 12:26:26,477] {logging_mixin.py:95} INFO - [2019-10-16 12:26:26,477] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=5404
[2019-10-16 12:26:26,482] {scheduler_job.py:146} INFO - Started process (PID=5404) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:26:26,486] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 12:26:26,487] {logging_mixin.py:95} INFO - [2019-10-16 12:26:26,487] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:26:26,500] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:26:26,603] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 12:26:26,617] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:25:00+00:00: scheduled__2019-10-15T10:25:00+00:00, externally triggered: False>
[2019-10-16 12:26:26,631] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:30:00+00:00: scheduled__2019-10-15T10:30:00+00:00, externally triggered: False>
[2019-10-16 12:26:26,642] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 05:55:00+00:00: scheduled__2019-10-16T05:55:00+00:00, externally triggered: False>
[2019-10-16 12:26:26,656] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:45:00+00:00: scheduled__2019-10-16T06:45:00+00:00, externally triggered: False>
[2019-10-16 12:26:26,668] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:50:00+00:00: scheduled__2019-10-16T06:50:00+00:00, externally triggered: False>
[2019-10-16 12:26:26,748] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 12:26:26,760] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.278 seconds
[2019-10-16 12:26:36,605] {logging_mixin.py:95} INFO - [2019-10-16 12:26:36,605] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=5443
[2019-10-16 12:26:36,612] {scheduler_job.py:146} INFO - Started process (PID=5443) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:26:36,619] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 12:26:36,619] {logging_mixin.py:95} INFO - [2019-10-16 12:26:36,619] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:26:36,630] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:26:36,663] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 12:26:36,683] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:25:00+00:00: scheduled__2019-10-15T10:25:00+00:00, externally triggered: False>
[2019-10-16 12:26:36,699] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:30:00+00:00: scheduled__2019-10-15T10:30:00+00:00, externally triggered: False>
[2019-10-16 12:26:36,710] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 05:55:00+00:00: scheduled__2019-10-16T05:55:00+00:00, externally triggered: False>
[2019-10-16 12:26:36,723] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:45:00+00:00: scheduled__2019-10-16T06:45:00+00:00, externally triggered: False>
[2019-10-16 12:26:36,734] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:50:00+00:00: scheduled__2019-10-16T06:50:00+00:00, externally triggered: False>
[2019-10-16 12:26:36,807] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 12:26:36,810] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.print_first_ten_lines 2019-10-16 06:45:00+00:00 [scheduled]> in ORM
[2019-10-16 12:26:36,823] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.211 seconds
[2019-10-16 12:26:46,735] {logging_mixin.py:95} INFO - [2019-10-16 12:26:46,735] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=5502
[2019-10-16 12:26:46,741] {scheduler_job.py:146} INFO - Started process (PID=5502) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:26:46,747] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 12:26:46,747] {logging_mixin.py:95} INFO - [2019-10-16 12:26:46,747] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:26:46,759] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:26:46,794] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 12:26:46,811] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:25:00+00:00: scheduled__2019-10-15T10:25:00+00:00, externally triggered: False>
[2019-10-16 12:26:46,825] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:30:00+00:00: scheduled__2019-10-15T10:30:00+00:00, externally triggered: False>
[2019-10-16 12:26:46,838] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 05:55:00+00:00: scheduled__2019-10-16T05:55:00+00:00, externally triggered: False>
[2019-10-16 12:26:46,851] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:45:00+00:00: scheduled__2019-10-16T06:45:00+00:00, externally triggered: False>
[2019-10-16 12:26:46,864] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:50:00+00:00: scheduled__2019-10-16T06:50:00+00:00, externally triggered: False>
[2019-10-16 12:26:46,940] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 12:26:46,947] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.206 seconds
[2019-10-16 12:26:56,865] {logging_mixin.py:95} INFO - [2019-10-16 12:26:56,865] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=5531
[2019-10-16 12:26:56,871] {scheduler_job.py:146} INFO - Started process (PID=5531) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:26:56,879] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 12:26:56,880] {logging_mixin.py:95} INFO - [2019-10-16 12:26:56,880] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:26:56,899] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:26:56,958] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 12:26:56,978] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:25:00+00:00: scheduled__2019-10-15T10:25:00+00:00, externally triggered: False>
[2019-10-16 12:26:56,992] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:30:00+00:00: scheduled__2019-10-15T10:30:00+00:00, externally triggered: False>
[2019-10-16 12:26:57,003] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 05:55:00+00:00: scheduled__2019-10-16T05:55:00+00:00, externally triggered: False>
[2019-10-16 12:26:57,016] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:45:00+00:00: scheduled__2019-10-16T06:45:00+00:00, externally triggered: False>
[2019-10-16 12:26:57,027] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:50:00+00:00: scheduled__2019-10-16T06:50:00+00:00, externally triggered: False>
[2019-10-16 12:26:57,107] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 12:26:57,114] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.243 seconds
[2019-10-16 12:27:06,966] {logging_mixin.py:95} INFO - [2019-10-16 12:27:06,966] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=5553
[2019-10-16 12:27:06,969] {scheduler_job.py:146} INFO - Started process (PID=5553) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:27:06,972] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 12:27:06,972] {logging_mixin.py:95} INFO - [2019-10-16 12:27:06,972] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:27:06,980] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:27:07,013] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 12:27:07,027] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:25:00+00:00: scheduled__2019-10-15T10:25:00+00:00, externally triggered: False>
[2019-10-16 12:27:07,041] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:30:00+00:00: scheduled__2019-10-15T10:30:00+00:00, externally triggered: False>
[2019-10-16 12:27:07,052] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 05:55:00+00:00: scheduled__2019-10-16T05:55:00+00:00, externally triggered: False>
[2019-10-16 12:27:07,064] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:45:00+00:00: scheduled__2019-10-16T06:45:00+00:00, externally triggered: False>
[2019-10-16 12:27:07,075] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:50:00+00:00: scheduled__2019-10-16T06:50:00+00:00, externally triggered: False>
[2019-10-16 12:27:07,150] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 12:27:07,156] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.188 seconds
[2019-10-16 12:27:17,098] {logging_mixin.py:95} INFO - [2019-10-16 12:27:17,097] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=5589
[2019-10-16 12:27:17,101] {scheduler_job.py:146} INFO - Started process (PID=5589) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:27:17,104] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 12:27:17,104] {logging_mixin.py:95} INFO - [2019-10-16 12:27:17,104] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:27:17,115] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:27:17,155] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 12:27:17,174] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:25:00+00:00: scheduled__2019-10-15T10:25:00+00:00, externally triggered: False>
[2019-10-16 12:27:17,189] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:30:00+00:00: scheduled__2019-10-15T10:30:00+00:00, externally triggered: False>
[2019-10-16 12:27:17,203] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 05:55:00+00:00: scheduled__2019-10-16T05:55:00+00:00, externally triggered: False>
[2019-10-16 12:27:17,218] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:45:00+00:00: scheduled__2019-10-16T06:45:00+00:00, externally triggered: False>
[2019-10-16 12:27:17,232] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:50:00+00:00: scheduled__2019-10-16T06:50:00+00:00, externally triggered: False>
[2019-10-16 12:27:17,320] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 12:27:17,329] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.228 seconds
[2019-10-16 12:27:27,227] {logging_mixin.py:95} INFO - [2019-10-16 12:27:27,226] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=5618
[2019-10-16 12:27:27,232] {scheduler_job.py:146} INFO - Started process (PID=5618) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:27:27,239] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 12:27:27,240] {logging_mixin.py:95} INFO - [2019-10-16 12:27:27,240] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:27:27,255] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:27:27,287] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 12:27:27,302] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:25:00+00:00: scheduled__2019-10-15T10:25:00+00:00, externally triggered: False>
[2019-10-16 12:27:27,316] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:30:00+00:00: scheduled__2019-10-15T10:30:00+00:00, externally triggered: False>
[2019-10-16 12:27:27,327] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 05:55:00+00:00: scheduled__2019-10-16T05:55:00+00:00, externally triggered: False>
[2019-10-16 12:27:27,340] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:45:00+00:00: scheduled__2019-10-16T06:45:00+00:00, externally triggered: False>
[2019-10-16 12:27:27,352] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:50:00+00:00: scheduled__2019-10-16T06:50:00+00:00, externally triggered: False>
[2019-10-16 12:27:27,425] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 12:27:27,431] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.199 seconds
[2019-10-16 12:27:37,339] {logging_mixin.py:95} INFO - [2019-10-16 12:27:37,339] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=5642
[2019-10-16 12:27:37,345] {scheduler_job.py:146} INFO - Started process (PID=5642) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:27:37,352] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 12:27:37,353] {logging_mixin.py:95} INFO - [2019-10-16 12:27:37,353] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:27:37,371] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:27:37,426] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 12:27:37,442] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:25:00+00:00: scheduled__2019-10-15T10:25:00+00:00, externally triggered: False>
[2019-10-16 12:27:37,455] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:30:00+00:00: scheduled__2019-10-15T10:30:00+00:00, externally triggered: False>
[2019-10-16 12:27:37,467] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 05:55:00+00:00: scheduled__2019-10-16T05:55:00+00:00, externally triggered: False>
[2019-10-16 12:27:37,480] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:45:00+00:00: scheduled__2019-10-16T06:45:00+00:00, externally triggered: False>
[2019-10-16 12:27:37,491] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:50:00+00:00: scheduled__2019-10-16T06:50:00+00:00, externally triggered: False>
[2019-10-16 12:27:37,565] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 12:27:37,571] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.227 seconds
[2019-10-16 12:27:47,434] {logging_mixin.py:95} INFO - [2019-10-16 12:27:47,434] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=5662
[2019-10-16 12:27:47,437] {scheduler_job.py:146} INFO - Started process (PID=5662) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:27:47,440] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 12:27:47,440] {logging_mixin.py:95} INFO - [2019-10-16 12:27:47,440] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:27:47,448] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:27:47,483] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 12:27:47,499] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:25:00+00:00: scheduled__2019-10-15T10:25:00+00:00, externally triggered: False>
[2019-10-16 12:27:47,513] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:30:00+00:00: scheduled__2019-10-15T10:30:00+00:00, externally triggered: False>
[2019-10-16 12:27:47,524] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 05:55:00+00:00: scheduled__2019-10-16T05:55:00+00:00, externally triggered: False>
[2019-10-16 12:27:47,536] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:45:00+00:00: scheduled__2019-10-16T06:45:00+00:00, externally triggered: False>
[2019-10-16 12:27:47,547] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:50:00+00:00: scheduled__2019-10-16T06:50:00+00:00, externally triggered: False>
[2019-10-16 12:27:47,619] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 12:27:47,623] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.print_first_ten_lines 2019-10-16 06:50:00+00:00 [scheduled]> in ORM
[2019-10-16 12:27:47,634] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.197 seconds
[2019-10-16 12:27:57,534] {logging_mixin.py:95} INFO - [2019-10-16 12:27:57,534] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=5729
[2019-10-16 12:27:57,537] {scheduler_job.py:146} INFO - Started process (PID=5729) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:27:57,540] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 12:27:57,540] {logging_mixin.py:95} INFO - [2019-10-16 12:27:57,540] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:27:57,548] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:27:57,580] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 12:27:57,596] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:25:00+00:00: scheduled__2019-10-15T10:25:00+00:00, externally triggered: False>
[2019-10-16 12:27:57,610] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:30:00+00:00: scheduled__2019-10-15T10:30:00+00:00, externally triggered: False>
[2019-10-16 12:27:57,621] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 05:55:00+00:00: scheduled__2019-10-16T05:55:00+00:00, externally triggered: False>
[2019-10-16 12:27:57,634] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:45:00+00:00: scheduled__2019-10-16T06:45:00+00:00, externally triggered: False>
[2019-10-16 12:27:57,646] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:50:00+00:00: scheduled__2019-10-16T06:50:00+00:00, externally triggered: False>
[2019-10-16 12:27:57,721] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 12:27:57,727] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.190 seconds
[2019-10-16 12:28:07,648] {logging_mixin.py:95} INFO - [2019-10-16 12:28:07,648] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=5749
[2019-10-16 12:28:07,651] {scheduler_job.py:146} INFO - Started process (PID=5749) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:28:07,654] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 12:28:07,654] {logging_mixin.py:95} INFO - [2019-10-16 12:28:07,654] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:28:07,664] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:28:07,693] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 12:28:07,708] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:25:00+00:00: scheduled__2019-10-15T10:25:00+00:00, externally triggered: False>
[2019-10-16 12:28:07,722] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:30:00+00:00: scheduled__2019-10-15T10:30:00+00:00, externally triggered: False>
[2019-10-16 12:28:07,735] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 05:55:00+00:00: scheduled__2019-10-16T05:55:00+00:00, externally triggered: False>
[2019-10-16 12:28:07,749] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:45:00+00:00: scheduled__2019-10-16T06:45:00+00:00, externally triggered: False>
[2019-10-16 12:28:07,761] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:50:00+00:00: scheduled__2019-10-16T06:50:00+00:00, externally triggered: False>
[2019-10-16 12:28:07,833] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 12:28:07,839] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.189 seconds
[2019-10-16 12:28:17,757] {logging_mixin.py:95} INFO - [2019-10-16 12:28:17,757] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=5772
[2019-10-16 12:28:17,761] {scheduler_job.py:146} INFO - Started process (PID=5772) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:28:17,764] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 12:28:17,764] {logging_mixin.py:95} INFO - [2019-10-16 12:28:17,764] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:28:17,773] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:28:17,806] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 12:28:17,823] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:25:00+00:00: scheduled__2019-10-15T10:25:00+00:00, externally triggered: False>
[2019-10-16 12:28:17,837] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:30:00+00:00: scheduled__2019-10-15T10:30:00+00:00, externally triggered: False>
[2019-10-16 12:28:17,849] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 05:55:00+00:00: scheduled__2019-10-16T05:55:00+00:00, externally triggered: False>
[2019-10-16 12:28:17,862] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:45:00+00:00: scheduled__2019-10-16T06:45:00+00:00, externally triggered: False>
[2019-10-16 12:28:17,873] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:50:00+00:00: scheduled__2019-10-16T06:50:00+00:00, externally triggered: False>
[2019-10-16 12:28:17,947] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 12:28:17,953] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.193 seconds
[2019-10-16 12:28:27,890] {logging_mixin.py:95} INFO - [2019-10-16 12:28:27,890] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=5802
[2019-10-16 12:28:27,898] {scheduler_job.py:146} INFO - Started process (PID=5802) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:28:27,902] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 12:28:27,903] {logging_mixin.py:95} INFO - [2019-10-16 12:28:27,903] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:28:27,913] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:28:28,021] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 12:28:28,044] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:25:00+00:00: scheduled__2019-10-15T10:25:00+00:00, externally triggered: False>
[2019-10-16 12:28:28,063] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:30:00+00:00: scheduled__2019-10-15T10:30:00+00:00, externally triggered: False>
[2019-10-16 12:28:28,077] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 05:55:00+00:00: scheduled__2019-10-16T05:55:00+00:00, externally triggered: False>
[2019-10-16 12:28:28,090] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:45:00+00:00: scheduled__2019-10-16T06:45:00+00:00, externally triggered: False>
[2019-10-16 12:28:28,102] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:50:00+00:00: scheduled__2019-10-16T06:50:00+00:00, externally triggered: False>
[2019-10-16 12:28:28,181] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 12:28:28,186] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.print_first_ten_lines 2019-10-15 10:25:00+00:00 [scheduled]> in ORM
[2019-10-16 12:28:28,190] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.move_target_to_source 2019-10-15 10:30:00+00:00 [scheduled]> in ORM
[2019-10-16 12:28:28,195] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.move_target_to_source 2019-10-16 05:55:00+00:00 [scheduled]> in ORM
[2019-10-16 12:28:28,285] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.387 seconds
[2019-10-16 12:28:38,047] {logging_mixin.py:95} INFO - [2019-10-16 12:28:38,047] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=5900
[2019-10-16 12:28:38,054] {scheduler_job.py:146} INFO - Started process (PID=5900) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:28:38,062] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 12:28:38,063] {logging_mixin.py:95} INFO - [2019-10-16 12:28:38,063] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:28:38,083] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:28:38,140] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 12:28:38,158] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:25:00+00:00: scheduled__2019-10-15T10:25:00+00:00, externally triggered: False>
[2019-10-16 12:28:38,173] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:30:00+00:00: scheduled__2019-10-15T10:30:00+00:00, externally triggered: False>
[2019-10-16 12:28:38,186] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 05:55:00+00:00: scheduled__2019-10-16T05:55:00+00:00, externally triggered: False>
[2019-10-16 12:28:38,199] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:45:00+00:00: scheduled__2019-10-16T06:45:00+00:00, externally triggered: False>
[2019-10-16 12:28:38,211] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:50:00+00:00: scheduled__2019-10-16T06:50:00+00:00, externally triggered: False>
[2019-10-16 12:28:38,285] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 12:28:38,292] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.238 seconds
[2019-10-16 12:28:48,222] {logging_mixin.py:95} INFO - [2019-10-16 12:28:48,221] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=5926
[2019-10-16 12:28:48,228] {scheduler_job.py:146} INFO - Started process (PID=5926) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:28:48,232] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 12:28:48,233] {logging_mixin.py:95} INFO - [2019-10-16 12:28:48,233] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:28:48,253] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:28:48,297] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 12:28:48,314] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:25:00+00:00: scheduled__2019-10-15T10:25:00+00:00, externally triggered: False>
[2019-10-16 12:28:48,329] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:30:00+00:00: scheduled__2019-10-15T10:30:00+00:00, externally triggered: False>
[2019-10-16 12:28:48,340] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 05:55:00+00:00: scheduled__2019-10-16T05:55:00+00:00, externally triggered: False>
[2019-10-16 12:28:48,353] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:45:00+00:00: scheduled__2019-10-16T06:45:00+00:00, externally triggered: False>
[2019-10-16 12:28:48,364] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:50:00+00:00: scheduled__2019-10-16T06:50:00+00:00, externally triggered: False>
[2019-10-16 12:28:48,437] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 12:28:48,442] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.print_first_ten_lines 2019-10-16 06:45:00+00:00 [scheduled]> in ORM
[2019-10-16 12:28:48,456] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.228 seconds
[2019-10-16 12:28:58,323] {logging_mixin.py:95} INFO - [2019-10-16 12:28:58,323] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=5988
[2019-10-16 12:28:58,328] {scheduler_job.py:146} INFO - Started process (PID=5988) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:28:58,333] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 12:28:58,334] {logging_mixin.py:95} INFO - [2019-10-16 12:28:58,333] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:28:58,353] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:28:58,413] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 12:28:58,441] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:25:00+00:00: scheduled__2019-10-15T10:25:00+00:00, externally triggered: False>
[2019-10-16 12:28:58,464] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:30:00+00:00: scheduled__2019-10-15T10:30:00+00:00, externally triggered: False>
[2019-10-16 12:28:58,480] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 05:55:00+00:00: scheduled__2019-10-16T05:55:00+00:00, externally triggered: False>
[2019-10-16 12:28:58,495] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:45:00+00:00: scheduled__2019-10-16T06:45:00+00:00, externally triggered: False>
[2019-10-16 12:28:58,508] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:50:00+00:00: scheduled__2019-10-16T06:50:00+00:00, externally triggered: False>
[2019-10-16 12:28:58,589] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 12:28:58,595] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.267 seconds
[2019-10-16 12:29:08,460] {logging_mixin.py:95} INFO - [2019-10-16 12:29:08,459] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=6014
[2019-10-16 12:29:08,467] {scheduler_job.py:146} INFO - Started process (PID=6014) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:29:08,472] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 12:29:08,473] {logging_mixin.py:95} INFO - [2019-10-16 12:29:08,473] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:29:08,493] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:29:08,525] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 12:29:08,541] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:25:00+00:00: scheduled__2019-10-15T10:25:00+00:00, externally triggered: False>
[2019-10-16 12:29:08,556] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:30:00+00:00: scheduled__2019-10-15T10:30:00+00:00, externally triggered: False>
[2019-10-16 12:29:08,568] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 05:55:00+00:00: scheduled__2019-10-16T05:55:00+00:00, externally triggered: False>
[2019-10-16 12:29:08,581] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:45:00+00:00: scheduled__2019-10-16T06:45:00+00:00, externally triggered: False>
[2019-10-16 12:29:08,594] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:50:00+00:00: scheduled__2019-10-16T06:50:00+00:00, externally triggered: False>
[2019-10-16 12:29:08,677] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 12:29:08,684] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.217 seconds
[2019-10-16 12:30:34,421] {logging_mixin.py:95} INFO - [2019-10-16 12:30:34,421] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=6190
[2019-10-16 12:30:34,423] {scheduler_job.py:146} INFO - Started process (PID=6190) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:30:34,426] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 12:30:34,426] {logging_mixin.py:95} INFO - [2019-10-16 12:30:34,426] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:30:34,434] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:30:34,466] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 12:30:34,499] {scheduler_job.py:1265} INFO - Created <DagRun file_operations_pipeline @ 2019-10-16T06:55:00+00:00: scheduled__2019-10-16T06:55:00+00:00, externally triggered: False>
[2019-10-16 12:30:34,503] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:25:00+00:00: scheduled__2019-10-15T10:25:00+00:00, externally triggered: False>
[2019-10-16 12:30:34,515] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:30:00+00:00: scheduled__2019-10-15T10:30:00+00:00, externally triggered: False>
[2019-10-16 12:30:34,526] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 05:55:00+00:00: scheduled__2019-10-16T05:55:00+00:00, externally triggered: False>
[2019-10-16 12:30:34,540] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:45:00+00:00: scheduled__2019-10-16T06:45:00+00:00, externally triggered: False>
[2019-10-16 12:30:34,554] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:50:00+00:00: scheduled__2019-10-16T06:50:00+00:00, externally triggered: False>
[2019-10-16 12:30:34,565] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:55:00+00:00: scheduled__2019-10-16T06:55:00+00:00, externally triggered: False>
[2019-10-16 12:30:34,670] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 12:30:34,674] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.print_first_ten_lines 2019-10-16 06:50:00+00:00 [scheduled]> in ORM
[2019-10-16 12:30:34,678] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.sleep 2019-10-16 06:55:00+00:00 [scheduled]> in ORM
[2019-10-16 12:30:34,683] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.zip_target 2019-10-16 06:55:00+00:00 [scheduled]> in ORM
[2019-10-16 12:30:34,700] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.277 seconds
[2019-10-16 12:30:44,519] {logging_mixin.py:95} INFO - [2019-10-16 12:30:44,519] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=6302
[2019-10-16 12:30:44,522] {scheduler_job.py:146} INFO - Started process (PID=6302) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:30:44,524] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 12:30:44,524] {logging_mixin.py:95} INFO - [2019-10-16 12:30:44,524] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:30:44,533] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:30:44,568] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 12:30:44,582] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:25:00+00:00: scheduled__2019-10-15T10:25:00+00:00, externally triggered: False>
[2019-10-16 12:30:44,596] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:30:00+00:00: scheduled__2019-10-15T10:30:00+00:00, externally triggered: False>
[2019-10-16 12:30:44,607] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 05:55:00+00:00: scheduled__2019-10-16T05:55:00+00:00, externally triggered: False>
[2019-10-16 12:30:44,619] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:45:00+00:00: scheduled__2019-10-16T06:45:00+00:00, externally triggered: False>
[2019-10-16 12:30:44,632] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:50:00+00:00: scheduled__2019-10-16T06:50:00+00:00, externally triggered: False>
[2019-10-16 12:30:44,644] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:55:00+00:00: scheduled__2019-10-16T06:55:00+00:00, externally triggered: False>
[2019-10-16 12:30:44,734] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 12:30:44,739] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.print_first_ten_lines 2019-10-15 10:25:00+00:00 [scheduled]> in ORM
[2019-10-16 12:30:44,743] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.move_target_to_source 2019-10-15 10:30:00+00:00 [scheduled]> in ORM
[2019-10-16 12:30:44,748] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.move_target_to_source 2019-10-16 05:55:00+00:00 [scheduled]> in ORM
[2019-10-16 12:30:44,753] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.move_target_to_source 2019-10-16 06:55:00+00:00 [scheduled]> in ORM
[2019-10-16 12:30:44,775] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.254 seconds
[2019-10-16 12:30:54,629] {logging_mixin.py:95} INFO - [2019-10-16 12:30:54,629] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=6438
[2019-10-16 12:30:54,631] {scheduler_job.py:146} INFO - Started process (PID=6438) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:30:54,633] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 12:30:54,634] {logging_mixin.py:95} INFO - [2019-10-16 12:30:54,634] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:30:54,642] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:30:54,708] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 12:30:54,732] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:25:00+00:00: scheduled__2019-10-15T10:25:00+00:00, externally triggered: False>
[2019-10-16 12:30:54,747] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:30:00+00:00: scheduled__2019-10-15T10:30:00+00:00, externally triggered: False>
[2019-10-16 12:30:54,771] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 05:55:00+00:00: scheduled__2019-10-16T05:55:00+00:00, externally triggered: False>
[2019-10-16 12:30:54,782] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:45:00+00:00: scheduled__2019-10-16T06:45:00+00:00, externally triggered: False>
[2019-10-16 12:30:54,794] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:50:00+00:00: scheduled__2019-10-16T06:50:00+00:00, externally triggered: False>
[2019-10-16 12:30:54,807] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:55:00+00:00: scheduled__2019-10-16T06:55:00+00:00, externally triggered: False>
[2019-10-16 12:30:54,918] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 12:30:54,923] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.unzip_source 2019-10-15 10:30:00+00:00 [scheduled]> in ORM
[2019-10-16 12:30:54,928] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.print_first_ten_lines 2019-10-16 06:45:00+00:00 [scheduled]> in ORM
[2019-10-16 12:30:54,972] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.340 seconds
[2019-10-16 12:31:04,749] {logging_mixin.py:95} INFO - [2019-10-16 12:31:04,749] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=6524
[2019-10-16 12:31:04,756] {scheduler_job.py:146} INFO - Started process (PID=6524) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:31:04,763] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 12:31:04,765] {logging_mixin.py:95} INFO - [2019-10-16 12:31:04,764] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:31:04,790] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:31:04,938] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 12:31:04,959] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:25:00+00:00: scheduled__2019-10-15T10:25:00+00:00, externally triggered: False>
[2019-10-16 12:31:04,981] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:30:00+00:00: scheduled__2019-10-15T10:30:00+00:00, externally triggered: False>
[2019-10-16 12:31:05,000] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 05:55:00+00:00: scheduled__2019-10-16T05:55:00+00:00, externally triggered: False>
[2019-10-16 12:31:05,016] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:45:00+00:00: scheduled__2019-10-16T06:45:00+00:00, externally triggered: False>
[2019-10-16 12:31:05,031] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:50:00+00:00: scheduled__2019-10-16T06:50:00+00:00, externally triggered: False>
[2019-10-16 12:31:05,042] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:55:00+00:00: scheduled__2019-10-16T06:55:00+00:00, externally triggered: False>
[2019-10-16 12:31:05,130] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 12:31:05,135] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.print_first_ten_lines 2019-10-15 10:30:00+00:00 [scheduled]> in ORM
[2019-10-16 12:31:05,208] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.452 seconds
[2019-10-16 12:31:14,871] {logging_mixin.py:95} INFO - [2019-10-16 12:31:14,870] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=6589
[2019-10-16 12:31:14,875] {scheduler_job.py:146} INFO - Started process (PID=6589) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:31:14,878] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 12:31:14,879] {logging_mixin.py:95} INFO - [2019-10-16 12:31:14,879] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:31:14,894] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:31:14,932] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 12:31:14,946] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:25:00+00:00: scheduled__2019-10-15T10:25:00+00:00, externally triggered: False>
[2019-10-16 12:31:14,960] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:30:00+00:00: scheduled__2019-10-15T10:30:00+00:00, externally triggered: False>
[2019-10-16 12:31:14,974] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 05:55:00+00:00: scheduled__2019-10-16T05:55:00+00:00, externally triggered: False>
[2019-10-16 12:31:14,986] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:45:00+00:00: scheduled__2019-10-16T06:45:00+00:00, externally triggered: False>
[2019-10-16 12:31:15,002] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:50:00+00:00: scheduled__2019-10-16T06:50:00+00:00, externally triggered: False>
[2019-10-16 12:31:15,016] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:55:00+00:00: scheduled__2019-10-16T06:55:00+00:00, externally triggered: False>
[2019-10-16 12:31:15,097] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 12:31:15,104] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.229 seconds
[2019-10-16 12:31:24,976] {logging_mixin.py:95} INFO - [2019-10-16 12:31:24,976] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=6614
[2019-10-16 12:31:24,979] {scheduler_job.py:146} INFO - Started process (PID=6614) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:31:24,981] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 12:31:24,981] {logging_mixin.py:95} INFO - [2019-10-16 12:31:24,981] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:31:24,990] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:31:25,024] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 12:31:25,039] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:25:00+00:00: scheduled__2019-10-15T10:25:00+00:00, externally triggered: False>
[2019-10-16 12:31:25,053] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:30:00+00:00: scheduled__2019-10-15T10:30:00+00:00, externally triggered: False>
[2019-10-16 12:31:25,065] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 05:55:00+00:00: scheduled__2019-10-16T05:55:00+00:00, externally triggered: False>
[2019-10-16 12:31:25,077] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:45:00+00:00: scheduled__2019-10-16T06:45:00+00:00, externally triggered: False>
[2019-10-16 12:31:25,090] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:50:00+00:00: scheduled__2019-10-16T06:50:00+00:00, externally triggered: False>
[2019-10-16 12:31:25,101] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:55:00+00:00: scheduled__2019-10-16T06:55:00+00:00, externally triggered: False>
[2019-10-16 12:31:25,186] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 12:31:25,193] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.214 seconds
[2019-10-16 12:31:35,104] {logging_mixin.py:95} INFO - [2019-10-16 12:31:35,104] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=6645
[2019-10-16 12:31:35,107] {scheduler_job.py:146} INFO - Started process (PID=6645) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:31:35,109] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 12:31:35,109] {logging_mixin.py:95} INFO - [2019-10-16 12:31:35,109] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:31:35,118] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:31:35,147] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 12:31:35,161] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:25:00+00:00: scheduled__2019-10-15T10:25:00+00:00, externally triggered: False>
[2019-10-16 12:31:35,175] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:30:00+00:00: scheduled__2019-10-15T10:30:00+00:00, externally triggered: False>
[2019-10-16 12:31:35,186] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 05:55:00+00:00: scheduled__2019-10-16T05:55:00+00:00, externally triggered: False>
[2019-10-16 12:31:35,198] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:45:00+00:00: scheduled__2019-10-16T06:45:00+00:00, externally triggered: False>
[2019-10-16 12:31:35,211] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:50:00+00:00: scheduled__2019-10-16T06:50:00+00:00, externally triggered: False>
[2019-10-16 12:31:35,222] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:55:00+00:00: scheduled__2019-10-16T06:55:00+00:00, externally triggered: False>
[2019-10-16 12:31:35,303] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 12:31:35,310] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.203 seconds
[2019-10-16 12:31:45,228] {logging_mixin.py:95} INFO - [2019-10-16 12:31:45,228] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=6675
[2019-10-16 12:31:45,236] {scheduler_job.py:146} INFO - Started process (PID=6675) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:31:45,242] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 12:31:45,243] {logging_mixin.py:95} INFO - [2019-10-16 12:31:45,243] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:31:45,257] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:31:45,289] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 12:31:45,305] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:25:00+00:00: scheduled__2019-10-15T10:25:00+00:00, externally triggered: False>
[2019-10-16 12:31:45,319] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:30:00+00:00: scheduled__2019-10-15T10:30:00+00:00, externally triggered: False>
[2019-10-16 12:31:45,332] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 05:55:00+00:00: scheduled__2019-10-16T05:55:00+00:00, externally triggered: False>
[2019-10-16 12:31:45,344] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:45:00+00:00: scheduled__2019-10-16T06:45:00+00:00, externally triggered: False>
[2019-10-16 12:31:45,359] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:50:00+00:00: scheduled__2019-10-16T06:50:00+00:00, externally triggered: False>
[2019-10-16 12:31:45,371] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:55:00+00:00: scheduled__2019-10-16T06:55:00+00:00, externally triggered: False>
[2019-10-16 12:31:45,461] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 12:31:45,467] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.231 seconds
[2019-10-16 12:31:55,369] {logging_mixin.py:95} INFO - [2019-10-16 12:31:55,369] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=6697
[2019-10-16 12:31:55,372] {scheduler_job.py:146} INFO - Started process (PID=6697) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:31:55,374] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 12:31:55,374] {logging_mixin.py:95} INFO - [2019-10-16 12:31:55,374] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:31:55,383] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:31:55,415] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 12:31:55,429] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:25:00+00:00: scheduled__2019-10-15T10:25:00+00:00, externally triggered: False>
[2019-10-16 12:31:55,443] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:30:00+00:00: scheduled__2019-10-15T10:30:00+00:00, externally triggered: False>
[2019-10-16 12:31:55,454] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 05:55:00+00:00: scheduled__2019-10-16T05:55:00+00:00, externally triggered: False>
[2019-10-16 12:31:55,465] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:45:00+00:00: scheduled__2019-10-16T06:45:00+00:00, externally triggered: False>
[2019-10-16 12:31:55,478] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:50:00+00:00: scheduled__2019-10-16T06:50:00+00:00, externally triggered: False>
[2019-10-16 12:31:55,490] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:55:00+00:00: scheduled__2019-10-16T06:55:00+00:00, externally triggered: False>
[2019-10-16 12:31:55,577] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 12:31:55,584] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.212 seconds
[2019-10-16 12:32:05,498] {logging_mixin.py:95} INFO - [2019-10-16 12:32:05,498] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=6723
[2019-10-16 12:32:05,503] {scheduler_job.py:146} INFO - Started process (PID=6723) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:32:05,507] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 12:32:05,507] {logging_mixin.py:95} INFO - [2019-10-16 12:32:05,507] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:32:05,520] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:32:05,550] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 12:32:05,564] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:25:00+00:00: scheduled__2019-10-15T10:25:00+00:00, externally triggered: False>
[2019-10-16 12:32:05,578] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:30:00+00:00: scheduled__2019-10-15T10:30:00+00:00, externally triggered: False>
[2019-10-16 12:32:05,590] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 05:55:00+00:00: scheduled__2019-10-16T05:55:00+00:00, externally triggered: False>
[2019-10-16 12:32:05,602] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:45:00+00:00: scheduled__2019-10-16T06:45:00+00:00, externally triggered: False>
[2019-10-16 12:32:05,620] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:50:00+00:00: scheduled__2019-10-16T06:50:00+00:00, externally triggered: False>
[2019-10-16 12:32:05,632] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:55:00+00:00: scheduled__2019-10-16T06:55:00+00:00, externally triggered: False>
[2019-10-16 12:32:05,721] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 12:32:05,728] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.225 seconds
[2019-10-16 12:32:15,671] {logging_mixin.py:95} INFO - [2019-10-16 12:32:15,670] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=6746
[2019-10-16 12:32:15,677] {scheduler_job.py:146} INFO - Started process (PID=6746) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:32:15,682] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 12:32:15,683] {logging_mixin.py:95} INFO - [2019-10-16 12:32:15,683] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:32:15,705] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:32:15,779] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 12:32:15,795] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:25:00+00:00: scheduled__2019-10-15T10:25:00+00:00, externally triggered: False>
[2019-10-16 12:32:15,810] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:30:00+00:00: scheduled__2019-10-15T10:30:00+00:00, externally triggered: False>
[2019-10-16 12:32:15,825] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 05:55:00+00:00: scheduled__2019-10-16T05:55:00+00:00, externally triggered: False>
[2019-10-16 12:32:15,838] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:45:00+00:00: scheduled__2019-10-16T06:45:00+00:00, externally triggered: False>
[2019-10-16 12:32:15,851] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:50:00+00:00: scheduled__2019-10-16T06:50:00+00:00, externally triggered: False>
[2019-10-16 12:32:15,862] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:55:00+00:00: scheduled__2019-10-16T06:55:00+00:00, externally triggered: False>
[2019-10-16 12:32:15,943] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 12:32:15,950] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.273 seconds
[2019-10-16 12:32:25,849] {logging_mixin.py:95} INFO - [2019-10-16 12:32:25,847] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=6808
[2019-10-16 12:32:25,859] {scheduler_job.py:146} INFO - Started process (PID=6808) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:32:25,868] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 12:32:25,869] {logging_mixin.py:95} INFO - [2019-10-16 12:32:25,869] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:32:25,905] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:32:25,948] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 12:32:25,963] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:25:00+00:00: scheduled__2019-10-15T10:25:00+00:00, externally triggered: False>
[2019-10-16 12:32:25,982] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:30:00+00:00: scheduled__2019-10-15T10:30:00+00:00, externally triggered: False>
[2019-10-16 12:32:25,995] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 05:55:00+00:00: scheduled__2019-10-16T05:55:00+00:00, externally triggered: False>
[2019-10-16 12:32:26,009] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:45:00+00:00: scheduled__2019-10-16T06:45:00+00:00, externally triggered: False>
[2019-10-16 12:32:26,022] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:50:00+00:00: scheduled__2019-10-16T06:50:00+00:00, externally triggered: False>
[2019-10-16 12:32:26,037] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:55:00+00:00: scheduled__2019-10-16T06:55:00+00:00, externally triggered: False>
[2019-10-16 12:32:26,132] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 12:32:26,139] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.279 seconds
[2019-10-16 12:32:35,977] {logging_mixin.py:95} INFO - [2019-10-16 12:32:35,976] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=6877
[2019-10-16 12:32:35,983] {scheduler_job.py:146} INFO - Started process (PID=6877) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:32:35,989] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 12:32:35,990] {logging_mixin.py:95} INFO - [2019-10-16 12:32:35,990] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:32:36,009] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:32:36,040] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 12:32:36,053] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:25:00+00:00: scheduled__2019-10-15T10:25:00+00:00, externally triggered: False>
[2019-10-16 12:32:36,067] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:30:00+00:00: scheduled__2019-10-15T10:30:00+00:00, externally triggered: False>
[2019-10-16 12:32:36,079] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 05:55:00+00:00: scheduled__2019-10-16T05:55:00+00:00, externally triggered: False>
[2019-10-16 12:32:36,090] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:45:00+00:00: scheduled__2019-10-16T06:45:00+00:00, externally triggered: False>
[2019-10-16 12:32:36,107] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:50:00+00:00: scheduled__2019-10-16T06:50:00+00:00, externally triggered: False>
[2019-10-16 12:32:36,123] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:55:00+00:00: scheduled__2019-10-16T06:55:00+00:00, externally triggered: False>
[2019-10-16 12:32:36,225] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 12:32:36,236] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.252 seconds
[2019-10-16 12:32:46,125] {logging_mixin.py:95} INFO - [2019-10-16 12:32:46,124] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=6914
[2019-10-16 12:32:46,132] {scheduler_job.py:146} INFO - Started process (PID=6914) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:32:46,139] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 12:32:46,140] {logging_mixin.py:95} INFO - [2019-10-16 12:32:46,139] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:32:46,163] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:32:46,206] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 12:32:46,223] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:25:00+00:00: scheduled__2019-10-15T10:25:00+00:00, externally triggered: False>
[2019-10-16 12:32:46,239] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:30:00+00:00: scheduled__2019-10-15T10:30:00+00:00, externally triggered: False>
[2019-10-16 12:32:46,251] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 05:55:00+00:00: scheduled__2019-10-16T05:55:00+00:00, externally triggered: False>
[2019-10-16 12:32:46,263] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:45:00+00:00: scheduled__2019-10-16T06:45:00+00:00, externally triggered: False>
[2019-10-16 12:32:46,276] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:50:00+00:00: scheduled__2019-10-16T06:50:00+00:00, externally triggered: False>
[2019-10-16 12:32:46,289] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:55:00+00:00: scheduled__2019-10-16T06:55:00+00:00, externally triggered: False>
[2019-10-16 12:32:46,382] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 12:32:46,387] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.print_first_ten_lines 2019-10-16 06:50:00+00:00 [scheduled]> in ORM
[2019-10-16 12:32:46,401] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.268 seconds
[2019-10-16 12:32:56,240] {logging_mixin.py:95} INFO - [2019-10-16 12:32:56,240] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=6975
[2019-10-16 12:32:56,246] {scheduler_job.py:146} INFO - Started process (PID=6975) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:32:56,250] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 12:32:56,250] {logging_mixin.py:95} INFO - [2019-10-16 12:32:56,250] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:32:56,261] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:32:56,289] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 12:32:56,303] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:25:00+00:00: scheduled__2019-10-15T10:25:00+00:00, externally triggered: False>
[2019-10-16 12:32:56,317] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:30:00+00:00: scheduled__2019-10-15T10:30:00+00:00, externally triggered: False>
[2019-10-16 12:32:56,328] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 05:55:00+00:00: scheduled__2019-10-16T05:55:00+00:00, externally triggered: False>
[2019-10-16 12:32:56,339] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:45:00+00:00: scheduled__2019-10-16T06:45:00+00:00, externally triggered: False>
[2019-10-16 12:32:56,351] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:50:00+00:00: scheduled__2019-10-16T06:50:00+00:00, externally triggered: False>
[2019-10-16 12:32:56,363] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:55:00+00:00: scheduled__2019-10-16T06:55:00+00:00, externally triggered: False>
[2019-10-16 12:32:56,443] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 12:32:56,447] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.print_first_ten_lines 2019-10-15 10:25:00+00:00 [scheduled]> in ORM
[2019-10-16 12:32:56,451] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.move_target_to_source 2019-10-16 05:55:00+00:00 [scheduled]> in ORM
[2019-10-16 12:32:56,455] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.move_target_to_source 2019-10-16 06:55:00+00:00 [scheduled]> in ORM
[2019-10-16 12:32:56,473] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.227 seconds
[2019-10-16 12:33:06,357] {logging_mixin.py:95} INFO - [2019-10-16 12:33:06,357] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=7095
[2019-10-16 12:33:06,363] {scheduler_job.py:146} INFO - Started process (PID=7095) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:33:06,368] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 12:33:06,368] {logging_mixin.py:95} INFO - [2019-10-16 12:33:06,368] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:33:06,382] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:33:06,409] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 12:33:06,423] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:25:00+00:00: scheduled__2019-10-15T10:25:00+00:00, externally triggered: False>
[2019-10-16 12:33:06,444] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:30:00+00:00: scheduled__2019-10-15T10:30:00+00:00, externally triggered: False>
[2019-10-16 12:33:06,456] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 05:55:00+00:00: scheduled__2019-10-16T05:55:00+00:00, externally triggered: False>
[2019-10-16 12:33:06,485] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:45:00+00:00: scheduled__2019-10-16T06:45:00+00:00, externally triggered: False>
[2019-10-16 12:33:06,497] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:50:00+00:00: scheduled__2019-10-16T06:50:00+00:00, externally triggered: False>
[2019-10-16 12:33:06,508] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:55:00+00:00: scheduled__2019-10-16T06:55:00+00:00, externally triggered: False>
[2019-10-16 12:33:06,589] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 12:33:06,594] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.print_first_ten_lines 2019-10-16 06:45:00+00:00 [scheduled]> in ORM
[2019-10-16 12:33:06,604] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.241 seconds
[2019-10-16 12:33:16,450] {logging_mixin.py:95} INFO - [2019-10-16 12:33:16,450] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=7168
[2019-10-16 12:33:16,453] {scheduler_job.py:146} INFO - Started process (PID=7168) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:33:16,455] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 12:33:16,455] {logging_mixin.py:95} INFO - [2019-10-16 12:33:16,455] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:33:16,464] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:33:16,495] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 12:33:16,508] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:25:00+00:00: scheduled__2019-10-15T10:25:00+00:00, externally triggered: False>
[2019-10-16 12:33:16,518] {logging_mixin.py:95} INFO - [2019-10-16 12:33:16,518] {dagrun.py:308} INFO - Marking run <DagRun file_operations_pipeline @ 2019-10-15 10:25:00+00:00: scheduled__2019-10-15T10:25:00+00:00, externally triggered: False> failed
[2019-10-16 12:33:16,523] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:30:00+00:00: scheduled__2019-10-15T10:30:00+00:00, externally triggered: False>
[2019-10-16 12:33:16,536] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 05:55:00+00:00: scheduled__2019-10-16T05:55:00+00:00, externally triggered: False>
[2019-10-16 12:33:16,543] {logging_mixin.py:95} INFO - [2019-10-16 12:33:16,543] {dagrun.py:308} INFO - Marking run <DagRun file_operations_pipeline @ 2019-10-16 05:55:00+00:00: scheduled__2019-10-16T05:55:00+00:00, externally triggered: False> failed
[2019-10-16 12:33:16,547] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:45:00+00:00: scheduled__2019-10-16T06:45:00+00:00, externally triggered: False>
[2019-10-16 12:33:16,566] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:50:00+00:00: scheduled__2019-10-16T06:50:00+00:00, externally triggered: False>
[2019-10-16 12:33:16,577] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:55:00+00:00: scheduled__2019-10-16T06:55:00+00:00, externally triggered: False>
[2019-10-16 12:33:16,626] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 12:33:16,630] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.print_first_ten_lines 2019-10-15 10:30:00+00:00 [scheduled]> in ORM
[2019-10-16 12:33:16,641] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.188 seconds
[2019-10-16 12:33:26,553] {logging_mixin.py:95} INFO - [2019-10-16 12:33:26,553] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=7232
[2019-10-16 12:33:26,559] {scheduler_job.py:146} INFO - Started process (PID=7232) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:33:26,564] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 12:33:26,565] {logging_mixin.py:95} INFO - [2019-10-16 12:33:26,565] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:33:26,580] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:33:26,611] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 12:33:26,625] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:30:00+00:00: scheduled__2019-10-15T10:30:00+00:00, externally triggered: False>
[2019-10-16 12:33:26,639] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:45:00+00:00: scheduled__2019-10-16T06:45:00+00:00, externally triggered: False>
[2019-10-16 12:33:26,647] {logging_mixin.py:95} INFO - [2019-10-16 12:33:26,647] {dagrun.py:308} INFO - Marking run <DagRun file_operations_pipeline @ 2019-10-16 06:45:00+00:00: scheduled__2019-10-16T06:45:00+00:00, externally triggered: False> failed
[2019-10-16 12:33:26,651] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:50:00+00:00: scheduled__2019-10-16T06:50:00+00:00, externally triggered: False>
[2019-10-16 12:33:26,662] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:55:00+00:00: scheduled__2019-10-16T06:55:00+00:00, externally triggered: False>
[2019-10-16 12:33:26,711] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 12:33:26,717] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.158 seconds
[2019-10-16 12:33:36,666] {logging_mixin.py:95} INFO - [2019-10-16 12:33:36,665] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=7267
[2019-10-16 12:33:36,668] {scheduler_job.py:146} INFO - Started process (PID=7267) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:33:36,671] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 12:33:36,671] {logging_mixin.py:95} INFO - [2019-10-16 12:33:36,671] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:33:36,682] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:33:36,711] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 12:33:36,725] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:30:00+00:00: scheduled__2019-10-15T10:30:00+00:00, externally triggered: False>
[2019-10-16 12:33:36,739] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:50:00+00:00: scheduled__2019-10-16T06:50:00+00:00, externally triggered: False>
[2019-10-16 12:33:36,750] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:55:00+00:00: scheduled__2019-10-16T06:55:00+00:00, externally triggered: False>
[2019-10-16 12:33:36,800] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 12:33:36,806] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.138 seconds
[2019-10-16 12:33:46,766] {logging_mixin.py:95} INFO - [2019-10-16 12:33:46,765] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=7292
[2019-10-16 12:33:46,768] {scheduler_job.py:146} INFO - Started process (PID=7292) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:33:46,770] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 12:33:46,771] {logging_mixin.py:95} INFO - [2019-10-16 12:33:46,771] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:33:46,779] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:33:46,807] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 12:33:46,823] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:30:00+00:00: scheduled__2019-10-15T10:30:00+00:00, externally triggered: False>
[2019-10-16 12:33:46,838] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:50:00+00:00: scheduled__2019-10-16T06:50:00+00:00, externally triggered: False>
[2019-10-16 12:33:46,850] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:55:00+00:00: scheduled__2019-10-16T06:55:00+00:00, externally triggered: False>
[2019-10-16 12:33:46,900] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 12:33:46,906] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.138 seconds
[2019-10-16 12:33:56,872] {logging_mixin.py:95} INFO - [2019-10-16 12:33:56,871] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=7312
[2019-10-16 12:33:56,875] {scheduler_job.py:146} INFO - Started process (PID=7312) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:33:56,877] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 12:33:56,878] {logging_mixin.py:95} INFO - [2019-10-16 12:33:56,878] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:33:56,888] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:33:56,919] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 12:33:56,933] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:30:00+00:00: scheduled__2019-10-15T10:30:00+00:00, externally triggered: False>
[2019-10-16 12:33:56,947] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:50:00+00:00: scheduled__2019-10-16T06:50:00+00:00, externally triggered: False>
[2019-10-16 12:33:56,958] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:55:00+00:00: scheduled__2019-10-16T06:55:00+00:00, externally triggered: False>
[2019-10-16 12:33:57,005] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 12:33:57,011] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.137 seconds
[2019-10-16 12:34:06,983] {logging_mixin.py:95} INFO - [2019-10-16 12:34:06,983] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=7338
[2019-10-16 12:34:06,989] {scheduler_job.py:146} INFO - Started process (PID=7338) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:34:06,993] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 12:34:06,994] {logging_mixin.py:95} INFO - [2019-10-16 12:34:06,994] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:34:07,007] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:34:07,035] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 12:34:07,049] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:30:00+00:00: scheduled__2019-10-15T10:30:00+00:00, externally triggered: False>
[2019-10-16 12:34:07,062] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:50:00+00:00: scheduled__2019-10-16T06:50:00+00:00, externally triggered: False>
[2019-10-16 12:34:07,074] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:55:00+00:00: scheduled__2019-10-16T06:55:00+00:00, externally triggered: False>
[2019-10-16 12:34:07,121] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 12:34:07,127] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.139 seconds
[2019-10-16 12:34:17,065] {logging_mixin.py:95} INFO - [2019-10-16 12:34:17,065] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=7374
[2019-10-16 12:34:17,068] {scheduler_job.py:146} INFO - Started process (PID=7374) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:34:17,071] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 12:34:17,071] {logging_mixin.py:95} INFO - [2019-10-16 12:34:17,071] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:34:17,082] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:34:17,111] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 12:34:17,125] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:30:00+00:00: scheduled__2019-10-15T10:30:00+00:00, externally triggered: False>
[2019-10-16 12:34:17,140] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:50:00+00:00: scheduled__2019-10-16T06:50:00+00:00, externally triggered: False>
[2019-10-16 12:34:17,151] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:55:00+00:00: scheduled__2019-10-16T06:55:00+00:00, externally triggered: False>
[2019-10-16 12:34:17,201] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 12:34:17,207] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.139 seconds
[2019-10-16 12:34:27,174] {logging_mixin.py:95} INFO - [2019-10-16 12:34:27,173] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=7402
[2019-10-16 12:34:27,176] {scheduler_job.py:146} INFO - Started process (PID=7402) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:34:27,178] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 12:34:27,178] {logging_mixin.py:95} INFO - [2019-10-16 12:34:27,178] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:34:27,187] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:34:27,217] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 12:34:27,230] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:30:00+00:00: scheduled__2019-10-15T10:30:00+00:00, externally triggered: False>
[2019-10-16 12:34:27,244] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:50:00+00:00: scheduled__2019-10-16T06:50:00+00:00, externally triggered: False>
[2019-10-16 12:34:27,256] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:55:00+00:00: scheduled__2019-10-16T06:55:00+00:00, externally triggered: False>
[2019-10-16 12:34:27,305] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 12:34:27,311] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.135 seconds
[2019-10-16 12:34:37,282] {logging_mixin.py:95} INFO - [2019-10-16 12:34:37,281] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=7432
[2019-10-16 12:34:37,286] {scheduler_job.py:146} INFO - Started process (PID=7432) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:34:37,289] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 12:34:37,290] {logging_mixin.py:95} INFO - [2019-10-16 12:34:37,290] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:34:37,302] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:34:37,343] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 12:34:37,368] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:30:00+00:00: scheduled__2019-10-15T10:30:00+00:00, externally triggered: False>
[2019-10-16 12:34:37,387] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:50:00+00:00: scheduled__2019-10-16T06:50:00+00:00, externally triggered: False>
[2019-10-16 12:34:37,402] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:55:00+00:00: scheduled__2019-10-16T06:55:00+00:00, externally triggered: False>
[2019-10-16 12:34:37,456] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 12:34:37,462] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.176 seconds
[2019-10-16 12:34:47,385] {logging_mixin.py:95} INFO - [2019-10-16 12:34:47,385] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=7459
[2019-10-16 12:34:47,388] {scheduler_job.py:146} INFO - Started process (PID=7459) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:34:47,390] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 12:34:47,390] {logging_mixin.py:95} INFO - [2019-10-16 12:34:47,390] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:34:47,399] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:34:47,428] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 12:34:47,443] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:30:00+00:00: scheduled__2019-10-15T10:30:00+00:00, externally triggered: False>
[2019-10-16 12:34:47,458] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:50:00+00:00: scheduled__2019-10-16T06:50:00+00:00, externally triggered: False>
[2019-10-16 12:34:47,470] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:55:00+00:00: scheduled__2019-10-16T06:55:00+00:00, externally triggered: False>
[2019-10-16 12:34:47,519] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 12:34:47,526] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.138 seconds
[2019-10-16 12:34:57,483] {logging_mixin.py:95} INFO - [2019-10-16 12:34:57,483] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=7480
[2019-10-16 12:34:57,487] {scheduler_job.py:146} INFO - Started process (PID=7480) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:34:57,490] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 12:34:57,491] {logging_mixin.py:95} INFO - [2019-10-16 12:34:57,491] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:34:57,504] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:34:57,549] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 12:34:57,568] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:30:00+00:00: scheduled__2019-10-15T10:30:00+00:00, externally triggered: False>
[2019-10-16 12:34:57,587] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:50:00+00:00: scheduled__2019-10-16T06:50:00+00:00, externally triggered: False>
[2019-10-16 12:34:57,602] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:55:00+00:00: scheduled__2019-10-16T06:55:00+00:00, externally triggered: False>
[2019-10-16 12:34:57,666] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 12:34:57,671] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.print_first_ten_lines 2019-10-16 06:50:00+00:00 [scheduled]> in ORM
[2019-10-16 12:34:57,688] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.201 seconds
[2019-10-16 12:35:07,581] {logging_mixin.py:95} INFO - [2019-10-16 12:35:07,581] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=7548
[2019-10-16 12:35:07,587] {scheduler_job.py:146} INFO - Started process (PID=7548) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:35:07,590] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 12:35:07,591] {logging_mixin.py:95} INFO - [2019-10-16 12:35:07,590] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:35:07,604] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:35:07,662] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 12:35:07,723] {scheduler_job.py:1265} INFO - Created <DagRun file_operations_pipeline @ 2019-10-16T07:00:00+00:00: scheduled__2019-10-16T07:00:00+00:00, externally triggered: False>
[2019-10-16 12:35:07,728] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:30:00+00:00: scheduled__2019-10-15T10:30:00+00:00, externally triggered: False>
[2019-10-16 12:35:07,741] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:50:00+00:00: scheduled__2019-10-16T06:50:00+00:00, externally triggered: False>
[2019-10-16 12:35:07,771] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:55:00+00:00: scheduled__2019-10-16T06:55:00+00:00, externally triggered: False>
[2019-10-16 12:35:07,795] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 07:00:00+00:00: scheduled__2019-10-16T07:00:00+00:00, externally triggered: False>
[2019-10-16 12:35:07,895] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 12:35:07,899] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.move_target_to_source 2019-10-16 06:55:00+00:00 [scheduled]> in ORM
[2019-10-16 12:35:07,904] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.sleep 2019-10-16 07:00:00+00:00 [scheduled]> in ORM
[2019-10-16 12:35:07,909] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.zip_target 2019-10-16 07:00:00+00:00 [scheduled]> in ORM
[2019-10-16 12:35:07,928] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.342 seconds
[2019-10-16 12:35:17,719] {logging_mixin.py:95} INFO - [2019-10-16 12:35:17,718] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=7672
[2019-10-16 12:35:17,723] {scheduler_job.py:146} INFO - Started process (PID=7672) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:35:17,727] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 12:35:17,728] {logging_mixin.py:95} INFO - [2019-10-16 12:35:17,728] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:35:17,760] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:35:17,813] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 12:35:17,847] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:30:00+00:00: scheduled__2019-10-15T10:30:00+00:00, externally triggered: False>
[2019-10-16 12:35:17,877] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:50:00+00:00: scheduled__2019-10-16T06:50:00+00:00, externally triggered: False>
[2019-10-16 12:35:17,896] {logging_mixin.py:95} INFO - [2019-10-16 12:35:17,896] {dagrun.py:308} INFO - Marking run <DagRun file_operations_pipeline @ 2019-10-16 06:50:00+00:00: scheduled__2019-10-16T06:50:00+00:00, externally triggered: False> failed
[2019-10-16 12:35:17,908] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:55:00+00:00: scheduled__2019-10-16T06:55:00+00:00, externally triggered: False>
[2019-10-16 12:35:17,934] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 07:00:00+00:00: scheduled__2019-10-16T07:00:00+00:00, externally triggered: False>
[2019-10-16 12:35:18,021] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 12:35:18,025] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.move_target_to_source 2019-10-16 07:00:00+00:00 [scheduled]> in ORM
[2019-10-16 12:35:18,044] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.321 seconds
[2019-10-16 12:35:27,873] {logging_mixin.py:95} INFO - [2019-10-16 12:35:27,873] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=7752
[2019-10-16 12:35:27,877] {scheduler_job.py:146} INFO - Started process (PID=7752) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:35:27,882] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 12:35:27,883] {logging_mixin.py:95} INFO - [2019-10-16 12:35:27,883] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:35:27,897] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:35:27,936] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 12:35:27,955] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:30:00+00:00: scheduled__2019-10-15T10:30:00+00:00, externally triggered: False>
[2019-10-16 12:35:27,975] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:55:00+00:00: scheduled__2019-10-16T06:55:00+00:00, externally triggered: False>
[2019-10-16 12:35:27,989] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 07:00:00+00:00: scheduled__2019-10-16T07:00:00+00:00, externally triggered: False>
[2019-10-16 12:35:28,063] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 12:35:28,068] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.print_first_ten_lines 2019-10-15 10:30:00+00:00 [scheduled]> in ORM
[2019-10-16 12:35:28,072] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.unzip_source 2019-10-16 07:00:00+00:00 [scheduled]> in ORM
[2019-10-16 12:35:28,094] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.217 seconds
[2019-10-16 12:35:37,991] {logging_mixin.py:95} INFO - [2019-10-16 12:35:37,991] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=7844
[2019-10-16 12:35:37,995] {scheduler_job.py:146} INFO - Started process (PID=7844) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:35:37,998] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 12:35:37,999] {logging_mixin.py:95} INFO - [2019-10-16 12:35:37,999] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:35:38,010] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:35:38,049] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 12:35:38,070] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:30:00+00:00: scheduled__2019-10-15T10:30:00+00:00, externally triggered: False>
[2019-10-16 12:35:38,091] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:55:00+00:00: scheduled__2019-10-16T06:55:00+00:00, externally triggered: False>
[2019-10-16 12:35:38,108] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 07:00:00+00:00: scheduled__2019-10-16T07:00:00+00:00, externally triggered: False>
[2019-10-16 12:35:38,176] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 12:35:38,180] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.print_first_ten_lines 2019-10-16 07:00:00+00:00 [scheduled]> in ORM
[2019-10-16 12:35:38,195] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.200 seconds
[2019-10-16 12:35:48,091] {logging_mixin.py:95} INFO - [2019-10-16 12:35:48,090] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=7900
[2019-10-16 12:35:48,093] {scheduler_job.py:146} INFO - Started process (PID=7900) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:35:48,096] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 12:35:48,096] {logging_mixin.py:95} INFO - [2019-10-16 12:35:48,096] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:35:48,106] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:35:48,138] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 12:35:48,152] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:25:00+00:00: scheduled__2019-10-15T10:25:00+00:00, externally triggered: False>
[2019-10-16 12:35:48,179] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:30:00+00:00: scheduled__2019-10-15T10:30:00+00:00, externally triggered: False>
[2019-10-16 12:35:48,202] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 05:55:00+00:00: scheduled__2019-10-16T05:55:00+00:00, externally triggered: False>
[2019-10-16 12:35:48,226] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:45:00+00:00: scheduled__2019-10-16T06:45:00+00:00, externally triggered: False>
[2019-10-16 12:35:48,250] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:50:00+00:00: scheduled__2019-10-16T06:50:00+00:00, externally triggered: False>
[2019-10-16 12:35:48,274] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:55:00+00:00: scheduled__2019-10-16T06:55:00+00:00, externally triggered: False>
[2019-10-16 12:35:48,297] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 07:00:00+00:00: scheduled__2019-10-16T07:00:00+00:00, externally triggered: False>
[2019-10-16 12:35:48,434] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 12:35:48,438] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.sleep 2019-10-15 10:25:00+00:00 [scheduled]> in ORM
[2019-10-16 12:35:48,443] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.zip_target 2019-10-15 10:25:00+00:00 [scheduled]> in ORM
[2019-10-16 12:35:48,447] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.sleep 2019-10-15 10:30:00+00:00 [scheduled]> in ORM
[2019-10-16 12:35:48,451] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.zip_target 2019-10-15 10:30:00+00:00 [scheduled]> in ORM
[2019-10-16 12:35:48,455] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.sleep 2019-10-16 05:55:00+00:00 [scheduled]> in ORM
[2019-10-16 12:35:48,459] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.zip_target 2019-10-16 05:55:00+00:00 [scheduled]> in ORM
[2019-10-16 12:35:48,463] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.sleep 2019-10-16 06:45:00+00:00 [scheduled]> in ORM
[2019-10-16 12:35:48,466] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.zip_target 2019-10-16 06:45:00+00:00 [scheduled]> in ORM
[2019-10-16 12:35:48,470] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.sleep 2019-10-16 06:50:00+00:00 [scheduled]> in ORM
[2019-10-16 12:35:48,474] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.zip_target 2019-10-16 06:50:00+00:00 [scheduled]> in ORM
[2019-10-16 12:35:48,478] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.sleep 2019-10-16 06:55:00+00:00 [scheduled]> in ORM
[2019-10-16 12:35:48,482] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.zip_target 2019-10-16 06:55:00+00:00 [scheduled]> in ORM
[2019-10-16 12:35:48,486] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.sleep 2019-10-16 07:00:00+00:00 [scheduled]> in ORM
[2019-10-16 12:35:48,490] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.zip_target 2019-10-16 07:00:00+00:00 [scheduled]> in ORM
[2019-10-16 12:35:48,508] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.415 seconds
[2019-10-16 12:35:58,210] {logging_mixin.py:95} INFO - [2019-10-16 12:35:58,209] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=8037
[2019-10-16 12:35:58,217] {scheduler_job.py:146} INFO - Started process (PID=8037) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:35:58,226] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 12:35:58,226] {logging_mixin.py:95} INFO - [2019-10-16 12:35:58,226] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:35:58,260] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:35:58,320] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 12:35:58,350] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:25:00+00:00: scheduled__2019-10-15T10:25:00+00:00, externally triggered: False>
[2019-10-16 12:35:58,422] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:30:00+00:00: scheduled__2019-10-15T10:30:00+00:00, externally triggered: False>
[2019-10-16 12:35:58,477] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 05:55:00+00:00: scheduled__2019-10-16T05:55:00+00:00, externally triggered: False>
[2019-10-16 12:35:58,529] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:45:00+00:00: scheduled__2019-10-16T06:45:00+00:00, externally triggered: False>
[2019-10-16 12:35:58,583] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:50:00+00:00: scheduled__2019-10-16T06:50:00+00:00, externally triggered: False>
[2019-10-16 12:35:58,634] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 06:55:00+00:00: scheduled__2019-10-16T06:55:00+00:00, externally triggered: False>
[2019-10-16 12:35:58,678] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 07:00:00+00:00: scheduled__2019-10-16T07:00:00+00:00, externally triggered: False>
[2019-10-16 12:35:58,950] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 12:35:58,962] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.745 seconds
[2019-10-16 12:36:10,630] {logging_mixin.py:95} INFO - [2019-10-16 12:36:10,629] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=8216
[2019-10-16 12:36:10,644] {scheduler_job.py:146} INFO - Started process (PID=8216) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:36:10,652] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 12:36:10,653] {logging_mixin.py:95} INFO - [2019-10-16 12:36:10,652] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:36:10,683] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 12:36:11,552] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 12:36:11,623] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-15 10:25:00+00:00: scheduled__2019-10-15T10:25:00+00:00, externally triggered: False>
[2019-10-16 13:12:04,083] {logging_mixin.py:95} INFO - [2019-10-16 13:12:04,083] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=4069
[2019-10-16 13:12:04,086] {scheduler_job.py:146} INFO - Started process (PID=4069) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:12:04,088] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 13:12:04,088] {logging_mixin.py:95} INFO - [2019-10-16 13:12:04,088] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:12:04,096] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:12:04,126] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.041 seconds
[2019-10-16 13:12:15,195] {logging_mixin.py:95} INFO - [2019-10-16 13:12:15,194] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=4189
[2019-10-16 13:12:15,209] {scheduler_job.py:146} INFO - Started process (PID=4189) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:12:15,217] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 13:12:15,218] {logging_mixin.py:95} INFO - [2019-10-16 13:12:15,218] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:12:15,250] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:12:15,291] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.082 seconds
[2019-10-16 13:12:25,302] {logging_mixin.py:95} INFO - [2019-10-16 13:12:25,302] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=4223
[2019-10-16 13:12:25,309] {scheduler_job.py:146} INFO - Started process (PID=4223) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:12:25,314] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 13:12:25,315] {logging_mixin.py:95} INFO - [2019-10-16 13:12:25,315] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:12:25,339] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:12:25,404] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.096 seconds
[2019-10-16 13:12:35,423] {logging_mixin.py:95} INFO - [2019-10-16 13:12:35,422] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=4252
[2019-10-16 13:12:35,430] {scheduler_job.py:146} INFO - Started process (PID=4252) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:12:35,435] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 13:12:35,436] {logging_mixin.py:95} INFO - [2019-10-16 13:12:35,436] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:12:35,458] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:12:35,490] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 13:12:35,520] {scheduler_job.py:1265} INFO - Created <DagRun file_operations_pipeline @ 2019-10-16T07:35:00+00:00: scheduled__2019-10-16T07:35:00+00:00, externally triggered: False>
[2019-10-16 13:12:35,524] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 07:35:00+00:00: scheduled__2019-10-16T07:35:00+00:00, externally triggered: False>
[2019-10-16 13:12:35,568] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 13:12:35,574] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.sleep 2019-10-16 07:35:00+00:00 [scheduled]> in ORM
[2019-10-16 13:12:35,579] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.zip_target 2019-10-16 07:35:00+00:00 [scheduled]> in ORM
[2019-10-16 13:12:35,590] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.161 seconds
[2019-10-16 13:12:45,534] {logging_mixin.py:95} INFO - [2019-10-16 13:12:45,533] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=4344
[2019-10-16 13:12:45,540] {scheduler_job.py:146} INFO - Started process (PID=4344) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:12:45,545] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 13:12:45,546] {logging_mixin.py:95} INFO - [2019-10-16 13:12:45,546] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:12:45,562] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:12:45,597] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 13:12:45,610] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 07:35:00+00:00: scheduled__2019-10-16T07:35:00+00:00, externally triggered: False>
[2019-10-16 13:12:45,642] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 13:12:45,645] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.move_target_to_source 2019-10-16 07:35:00+00:00 [scheduled]> in ORM
[2019-10-16 13:12:45,658] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.118 seconds
[2019-10-16 13:12:55,627] {logging_mixin.py:95} INFO - [2019-10-16 13:12:55,626] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=4407
[2019-10-16 13:12:55,629] {scheduler_job.py:146} INFO - Started process (PID=4407) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:12:55,632] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 13:12:55,632] {logging_mixin.py:95} INFO - [2019-10-16 13:12:55,632] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:12:55,640] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:12:55,677] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 13:12:55,690] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 07:35:00+00:00: scheduled__2019-10-16T07:35:00+00:00, externally triggered: False>
[2019-10-16 13:12:55,723] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 13:12:55,731] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.101 seconds
[2019-10-16 13:13:05,736] {logging_mixin.py:95} INFO - [2019-10-16 13:13:05,735] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=4435
[2019-10-16 13:13:05,742] {scheduler_job.py:146} INFO - Started process (PID=4435) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:13:05,746] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 13:13:05,747] {logging_mixin.py:95} INFO - [2019-10-16 13:13:05,747] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:13:05,758] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:13:05,788] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 13:13:05,802] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 07:35:00+00:00: scheduled__2019-10-16T07:35:00+00:00, externally triggered: False>
[2019-10-16 13:13:05,833] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 13:13:05,841] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.100 seconds
[2019-10-16 13:13:15,840] {logging_mixin.py:95} INFO - [2019-10-16 13:13:15,840] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=4466
[2019-10-16 13:13:15,844] {scheduler_job.py:146} INFO - Started process (PID=4466) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:13:15,846] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 13:13:15,847] {logging_mixin.py:95} INFO - [2019-10-16 13:13:15,847] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:13:15,858] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:13:15,898] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 13:13:15,923] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 07:35:00+00:00: scheduled__2019-10-16T07:35:00+00:00, externally triggered: False>
[2019-10-16 13:13:15,969] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 13:13:15,979] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.136 seconds
[2019-10-16 13:13:25,955] {logging_mixin.py:95} INFO - [2019-10-16 13:13:25,954] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=4490
[2019-10-16 13:13:25,961] {scheduler_job.py:146} INFO - Started process (PID=4490) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:13:25,966] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 13:13:25,967] {logging_mixin.py:95} INFO - [2019-10-16 13:13:25,967] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:13:25,988] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:13:26,049] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 13:13:26,063] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 07:35:00+00:00: scheduled__2019-10-16T07:35:00+00:00, externally triggered: False>
[2019-10-16 13:13:26,094] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 13:13:26,102] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.141 seconds
[2019-10-16 13:13:36,071] {logging_mixin.py:95} INFO - [2019-10-16 13:13:36,071] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=4515
[2019-10-16 13:13:36,074] {scheduler_job.py:146} INFO - Started process (PID=4515) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:13:36,076] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 13:13:36,076] {logging_mixin.py:95} INFO - [2019-10-16 13:13:36,076] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:13:36,084] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:13:36,112] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 13:13:36,125] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 07:35:00+00:00: scheduled__2019-10-16T07:35:00+00:00, externally triggered: False>
[2019-10-16 13:13:36,156] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 13:13:36,164] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.091 seconds
[2019-10-16 13:13:46,190] {logging_mixin.py:95} INFO - [2019-10-16 13:13:46,190] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=4544
[2019-10-16 13:13:46,197] {scheduler_job.py:146} INFO - Started process (PID=4544) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:13:46,201] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 13:13:46,202] {logging_mixin.py:95} INFO - [2019-10-16 13:13:46,201] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:13:46,214] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:13:46,248] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 13:13:46,263] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 07:35:00+00:00: scheduled__2019-10-16T07:35:00+00:00, externally triggered: False>
[2019-10-16 13:13:46,293] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 13:13:46,302] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.105 seconds
[2019-10-16 13:13:56,291] {logging_mixin.py:95} INFO - [2019-10-16 13:13:56,290] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=4568
[2019-10-16 13:13:56,294] {scheduler_job.py:146} INFO - Started process (PID=4568) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:13:56,297] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 13:13:56,297] {logging_mixin.py:95} INFO - [2019-10-16 13:13:56,297] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:13:56,309] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:13:56,350] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 13:13:56,370] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 07:35:00+00:00: scheduled__2019-10-16T07:35:00+00:00, externally triggered: False>
[2019-10-16 13:13:56,417] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 13:13:56,428] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.134 seconds
[2019-10-16 13:14:06,393] {logging_mixin.py:95} INFO - [2019-10-16 13:14:06,393] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=4599
[2019-10-16 13:14:06,396] {scheduler_job.py:146} INFO - Started process (PID=4599) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:14:06,398] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 13:14:06,398] {logging_mixin.py:95} INFO - [2019-10-16 13:14:06,398] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:14:06,406] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:14:06,442] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 13:14:06,456] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 07:35:00+00:00: scheduled__2019-10-16T07:35:00+00:00, externally triggered: False>
[2019-10-16 13:14:06,486] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 13:14:06,494] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.099 seconds
[2019-10-16 13:14:16,495] {logging_mixin.py:95} INFO - [2019-10-16 13:14:16,495] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=4623
[2019-10-16 13:14:16,502] {scheduler_job.py:146} INFO - Started process (PID=4623) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:14:16,508] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 13:14:16,508] {logging_mixin.py:95} INFO - [2019-10-16 13:14:16,508] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:14:16,527] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:14:16,566] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 13:14:16,580] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 07:35:00+00:00: scheduled__2019-10-16T07:35:00+00:00, externally triggered: False>
[2019-10-16 13:14:16,610] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 13:14:16,618] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.116 seconds
[2019-10-16 13:14:26,590] {logging_mixin.py:95} INFO - [2019-10-16 13:14:26,589] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=4659
[2019-10-16 13:14:26,592] {scheduler_job.py:146} INFO - Started process (PID=4659) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:14:26,594] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 13:14:26,595] {logging_mixin.py:95} INFO - [2019-10-16 13:14:26,595] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:14:26,603] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:14:26,634] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 13:14:26,647] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 07:35:00+00:00: scheduled__2019-10-16T07:35:00+00:00, externally triggered: False>
[2019-10-16 13:14:26,677] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 13:14:26,684] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.092 seconds
[2019-10-16 13:20:27,633] {logging_mixin.py:95} INFO - [2019-10-16 13:20:27,632] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=4830
[2019-10-16 13:20:27,635] {scheduler_job.py:146} INFO - Started process (PID=4830) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:20:27,637] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 13:20:27,637] {logging_mixin.py:95} INFO - [2019-10-16 13:20:27,637] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:20:27,647] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:20:27,678] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 13:20:27,714] {scheduler_job.py:1265} INFO - Created <DagRun file_operations_pipeline @ 2019-10-16T07:45:00+00:00: scheduled__2019-10-16T07:45:00+00:00, externally triggered: False>
[2019-10-16 13:20:27,717] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 07:45:00+00:00: scheduled__2019-10-16T07:45:00+00:00, externally triggered: False>
[2019-10-16 13:20:27,758] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 13:20:27,762] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.sleep 2019-10-16 07:45:00+00:00 [scheduled]> in ORM
[2019-10-16 13:20:27,766] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.zip_target 2019-10-16 07:45:00+00:00 [scheduled]> in ORM
[2019-10-16 13:20:27,777] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.142 seconds
[2019-10-16 13:20:37,733] {logging_mixin.py:95} INFO - [2019-10-16 13:20:37,732] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=4914
[2019-10-16 13:20:37,735] {scheduler_job.py:146} INFO - Started process (PID=4914) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:20:37,737] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 13:20:37,738] {logging_mixin.py:95} INFO - [2019-10-16 13:20:37,738] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:20:37,746] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:20:37,782] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 13:20:37,798] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 07:45:00+00:00: scheduled__2019-10-16T07:45:00+00:00, externally triggered: False>
[2019-10-16 13:20:37,829] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 13:20:37,833] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.move_target_to_source 2019-10-16 07:45:00+00:00 [scheduled]> in ORM
[2019-10-16 13:20:37,845] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.110 seconds
[2019-10-16 13:20:47,833] {logging_mixin.py:95} INFO - [2019-10-16 13:20:47,832] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=4989
[2019-10-16 13:20:47,835] {scheduler_job.py:146} INFO - Started process (PID=4989) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:20:47,837] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 13:20:47,838] {logging_mixin.py:95} INFO - [2019-10-16 13:20:47,838] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:20:47,847] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:20:47,879] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 13:20:47,896] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 07:45:00+00:00: scheduled__2019-10-16T07:45:00+00:00, externally triggered: False>
[2019-10-16 13:20:47,929] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 13:20:47,937] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.101 seconds
[2019-10-16 13:20:57,942] {logging_mixin.py:95} INFO - [2019-10-16 13:20:57,941] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=5033
[2019-10-16 13:20:57,945] {scheduler_job.py:146} INFO - Started process (PID=5033) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:20:57,947] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 13:20:57,947] {logging_mixin.py:95} INFO - [2019-10-16 13:20:57,947] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:20:57,956] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:20:57,989] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 13:20:58,003] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 07:45:00+00:00: scheduled__2019-10-16T07:45:00+00:00, externally triggered: False>
[2019-10-16 13:20:58,036] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 13:20:58,044] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.100 seconds
[2019-10-16 13:21:08,045] {logging_mixin.py:95} INFO - [2019-10-16 13:21:08,045] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=5055
[2019-10-16 13:21:08,047] {scheduler_job.py:146} INFO - Started process (PID=5055) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:21:08,049] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 13:21:08,050] {logging_mixin.py:95} INFO - [2019-10-16 13:21:08,050] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:21:08,058] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:21:08,099] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 13:21:08,118] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 07:45:00+00:00: scheduled__2019-10-16T07:45:00+00:00, externally triggered: False>
[2019-10-16 13:21:08,150] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 13:21:08,158] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.111 seconds
[2019-10-16 13:21:18,139] {logging_mixin.py:95} INFO - [2019-10-16 13:21:18,139] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=5111
[2019-10-16 13:21:18,142] {scheduler_job.py:146} INFO - Started process (PID=5111) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:21:18,145] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 13:21:18,145] {logging_mixin.py:95} INFO - [2019-10-16 13:21:18,145] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:21:18,159] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:21:18,199] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 13:21:18,220] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 07:45:00+00:00: scheduled__2019-10-16T07:45:00+00:00, externally triggered: False>
[2019-10-16 13:21:18,265] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 13:21:18,276] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.134 seconds
[2019-10-16 13:21:28,255] {logging_mixin.py:95} INFO - [2019-10-16 13:21:28,255] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=5137
[2019-10-16 13:21:28,257] {scheduler_job.py:146} INFO - Started process (PID=5137) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:21:28,259] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 13:21:28,260] {logging_mixin.py:95} INFO - [2019-10-16 13:21:28,260] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:21:28,269] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:21:28,305] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 13:21:28,321] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 07:45:00+00:00: scheduled__2019-10-16T07:45:00+00:00, externally triggered: False>
[2019-10-16 13:21:28,353] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 13:21:28,361] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.103 seconds
[2019-10-16 13:21:38,398] {logging_mixin.py:95} INFO - [2019-10-16 13:21:38,397] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=5244
[2019-10-16 13:21:38,406] {scheduler_job.py:146} INFO - Started process (PID=5244) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:21:38,413] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 13:21:38,415] {logging_mixin.py:95} INFO - [2019-10-16 13:21:38,414] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:21:38,441] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:21:38,513] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 13:21:38,531] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 07:45:00+00:00: scheduled__2019-10-16T07:45:00+00:00, externally triggered: False>
[2019-10-16 13:21:38,566] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 13:21:38,574] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.168 seconds
[2019-10-16 13:21:48,509] {logging_mixin.py:95} INFO - [2019-10-16 13:21:48,509] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=5270
[2019-10-16 13:21:48,511] {scheduler_job.py:146} INFO - Started process (PID=5270) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:21:48,513] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 13:21:48,514] {logging_mixin.py:95} INFO - [2019-10-16 13:21:48,514] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:21:48,523] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:21:48,556] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 13:21:48,572] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 07:45:00+00:00: scheduled__2019-10-16T07:45:00+00:00, externally triggered: False>
[2019-10-16 13:21:48,604] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 13:21:48,612] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.101 seconds
[2019-10-16 13:21:58,619] {logging_mixin.py:95} INFO - [2019-10-16 13:21:58,619] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=5299
[2019-10-16 13:21:58,622] {scheduler_job.py:146} INFO - Started process (PID=5299) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:21:58,624] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 13:21:58,624] {logging_mixin.py:95} INFO - [2019-10-16 13:21:58,624] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:21:58,633] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:21:58,664] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 13:21:58,680] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 07:45:00+00:00: scheduled__2019-10-16T07:45:00+00:00, externally triggered: False>
[2019-10-16 13:21:58,712] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 13:21:58,720] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.098 seconds
[2019-10-16 13:22:08,724] {logging_mixin.py:95} INFO - [2019-10-16 13:22:08,724] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=5322
[2019-10-16 13:22:08,727] {scheduler_job.py:146} INFO - Started process (PID=5322) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:22:08,729] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 13:22:08,729] {logging_mixin.py:95} INFO - [2019-10-16 13:22:08,729] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:22:08,738] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:22:08,769] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 13:22:08,784] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 07:45:00+00:00: scheduled__2019-10-16T07:45:00+00:00, externally triggered: False>
[2019-10-16 13:22:08,816] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 13:22:08,824] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.097 seconds
[2019-10-16 13:22:18,831] {logging_mixin.py:95} INFO - [2019-10-16 13:22:18,830] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=5346
[2019-10-16 13:22:18,837] {scheduler_job.py:146} INFO - Started process (PID=5346) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:22:18,842] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 13:22:18,843] {logging_mixin.py:95} INFO - [2019-10-16 13:22:18,843] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:22:18,858] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:22:18,894] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 13:22:18,913] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 07:45:00+00:00: scheduled__2019-10-16T07:45:00+00:00, externally triggered: False>
[2019-10-16 13:22:18,944] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 13:22:18,951] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.114 seconds
[2019-10-16 13:22:28,929] {logging_mixin.py:95} INFO - [2019-10-16 13:22:28,929] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=5367
[2019-10-16 13:22:28,932] {scheduler_job.py:146} INFO - Started process (PID=5367) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:22:28,934] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 13:22:28,934] {logging_mixin.py:95} INFO - [2019-10-16 13:22:28,934] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:22:28,943] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:22:28,975] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 13:22:28,990] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 07:45:00+00:00: scheduled__2019-10-16T07:45:00+00:00, externally triggered: False>
[2019-10-16 13:22:29,022] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 13:22:29,031] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.099 seconds
[2019-10-16 13:22:39,028] {logging_mixin.py:95} INFO - [2019-10-16 13:22:39,028] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=5387
[2019-10-16 13:22:39,031] {scheduler_job.py:146} INFO - Started process (PID=5387) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:22:39,033] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 13:22:39,033] {logging_mixin.py:95} INFO - [2019-10-16 13:22:39,033] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:22:39,042] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:22:39,093] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 13:22:39,125] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 07:45:00+00:00: scheduled__2019-10-16T07:45:00+00:00, externally triggered: False>
[2019-10-16 13:22:39,161] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 13:22:39,171] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.140 seconds
[2019-10-16 13:22:49,165] {logging_mixin.py:95} INFO - [2019-10-16 13:22:49,164] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=5415
[2019-10-16 13:22:49,168] {scheduler_job.py:146} INFO - Started process (PID=5415) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:22:49,171] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 13:22:49,171] {logging_mixin.py:95} INFO - [2019-10-16 13:22:49,171] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:22:49,184] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:22:49,223] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 13:22:49,238] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 07:45:00+00:00: scheduled__2019-10-16T07:45:00+00:00, externally triggered: False>
[2019-10-16 13:22:49,277] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 13:22:49,282] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.move_target_to_source 2019-10-16 07:45:00+00:00 [scheduled]> in ORM
[2019-10-16 13:22:49,296] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.128 seconds
[2019-10-16 13:22:59,314] {logging_mixin.py:95} INFO - [2019-10-16 13:22:59,314] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=5476
[2019-10-16 13:22:59,321] {scheduler_job.py:146} INFO - Started process (PID=5476) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:22:59,327] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 13:22:59,328] {logging_mixin.py:95} INFO - [2019-10-16 13:22:59,328] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:22:59,355] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:22:59,411] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 13:22:59,435] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 07:45:00+00:00: scheduled__2019-10-16T07:45:00+00:00, externally triggered: False>
[2019-10-16 13:22:59,474] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 13:22:59,482] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.161 seconds
[2019-10-16 13:23:09,458] {logging_mixin.py:95} INFO - [2019-10-16 13:23:09,458] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=5497
[2019-10-16 13:23:09,461] {scheduler_job.py:146} INFO - Started process (PID=5497) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:23:09,463] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 13:23:09,464] {logging_mixin.py:95} INFO - [2019-10-16 13:23:09,464] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:23:09,472] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:23:09,508] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 13:23:09,527] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 07:45:00+00:00: scheduled__2019-10-16T07:45:00+00:00, externally triggered: False>
[2019-10-16 13:23:09,562] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 13:23:09,575] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.114 seconds
[2019-10-16 13:23:19,565] {logging_mixin.py:95} INFO - [2019-10-16 13:23:19,565] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=5519
[2019-10-16 13:23:19,569] {scheduler_job.py:146} INFO - Started process (PID=5519) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:23:19,573] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 13:23:19,573] {logging_mixin.py:95} INFO - [2019-10-16 13:23:19,573] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:23:19,586] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:23:19,643] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 13:23:19,667] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 07:45:00+00:00: scheduled__2019-10-16T07:45:00+00:00, externally triggered: False>
[2019-10-16 13:23:19,733] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 13:23:19,748] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.179 seconds
[2019-10-16 13:23:29,678] {logging_mixin.py:95} INFO - [2019-10-16 13:23:29,678] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=5553
[2019-10-16 13:23:29,680] {scheduler_job.py:146} INFO - Started process (PID=5553) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:23:29,683] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 13:23:29,683] {logging_mixin.py:95} INFO - [2019-10-16 13:23:29,683] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:23:29,692] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:23:29,740] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 13:23:29,773] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 07:45:00+00:00: scheduled__2019-10-16T07:45:00+00:00, externally triggered: False>
[2019-10-16 13:23:29,805] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 13:23:29,813] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.133 seconds
[2019-10-16 13:23:39,768] {logging_mixin.py:95} INFO - [2019-10-16 13:23:39,768] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=5573
[2019-10-16 13:23:39,771] {scheduler_job.py:146} INFO - Started process (PID=5573) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:23:39,773] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 13:23:39,773] {logging_mixin.py:95} INFO - [2019-10-16 13:23:39,773] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:23:39,782] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:23:39,808] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 13:23:39,823] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 07:45:00+00:00: scheduled__2019-10-16T07:45:00+00:00, externally triggered: False>
[2019-10-16 13:23:39,854] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 13:23:39,862] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.091 seconds
[2019-10-16 13:23:49,888] {logging_mixin.py:95} INFO - [2019-10-16 13:23:49,888] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=5599
[2019-10-16 13:23:49,895] {scheduler_job.py:146} INFO - Started process (PID=5599) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:23:49,900] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 13:23:49,901] {logging_mixin.py:95} INFO - [2019-10-16 13:23:49,901] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:23:49,926] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:23:49,972] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 13:23:49,988] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 07:45:00+00:00: scheduled__2019-10-16T07:45:00+00:00, externally triggered: False>
[2019-10-16 13:23:50,023] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 13:23:50,031] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.137 seconds
[2019-10-16 13:24:00,001] {logging_mixin.py:95} INFO - [2019-10-16 13:24:00,001] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=5630
[2019-10-16 13:24:00,005] {scheduler_job.py:146} INFO - Started process (PID=5630) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:24:00,007] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 13:24:00,008] {logging_mixin.py:95} INFO - [2019-10-16 13:24:00,008] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:24:00,017] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:24:00,047] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 13:24:00,063] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 07:45:00+00:00: scheduled__2019-10-16T07:45:00+00:00, externally triggered: False>
[2019-10-16 13:24:00,095] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 13:24:00,103] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.098 seconds
[2019-10-16 13:24:10,110] {logging_mixin.py:95} INFO - [2019-10-16 13:24:10,110] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=5651
[2019-10-16 13:24:10,113] {scheduler_job.py:146} INFO - Started process (PID=5651) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:24:10,115] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 13:24:10,115] {logging_mixin.py:95} INFO - [2019-10-16 13:24:10,115] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:24:10,124] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:24:10,156] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 13:24:10,171] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 07:45:00+00:00: scheduled__2019-10-16T07:45:00+00:00, externally triggered: False>
[2019-10-16 13:24:10,203] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 13:24:10,211] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.099 seconds
[2019-10-16 13:24:20,213] {logging_mixin.py:95} INFO - [2019-10-16 13:24:20,212] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=5684
[2019-10-16 13:24:20,219] {scheduler_job.py:146} INFO - Started process (PID=5684) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:24:20,223] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 13:24:20,224] {logging_mixin.py:95} INFO - [2019-10-16 13:24:20,224] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:24:20,235] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:24:20,270] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 13:24:20,289] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 07:45:00+00:00: scheduled__2019-10-16T07:45:00+00:00, externally triggered: False>
[2019-10-16 13:24:20,323] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 13:24:20,332] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.114 seconds
[2019-10-16 13:24:30,316] {logging_mixin.py:95} INFO - [2019-10-16 13:24:30,316] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=5711
[2019-10-16 13:24:30,319] {scheduler_job.py:146} INFO - Started process (PID=5711) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:24:30,321] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 13:24:30,321] {logging_mixin.py:95} INFO - [2019-10-16 13:24:30,321] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:24:30,329] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:24:30,364] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 13:24:30,382] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 07:45:00+00:00: scheduled__2019-10-16T07:45:00+00:00, externally triggered: False>
[2019-10-16 13:24:30,418] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 13:24:30,426] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.107 seconds
[2019-10-16 13:24:40,418] {logging_mixin.py:95} INFO - [2019-10-16 13:24:40,418] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=5732
[2019-10-16 13:24:40,421] {scheduler_job.py:146} INFO - Started process (PID=5732) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:24:40,423] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 13:24:40,423] {logging_mixin.py:95} INFO - [2019-10-16 13:24:40,423] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:24:40,432] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:24:40,463] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 13:24:40,478] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 07:45:00+00:00: scheduled__2019-10-16T07:45:00+00:00, externally triggered: False>
[2019-10-16 13:24:40,510] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 13:24:40,518] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.098 seconds
[2019-10-16 13:24:50,512] {logging_mixin.py:95} INFO - [2019-10-16 13:24:50,512] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=5752
[2019-10-16 13:24:50,514] {scheduler_job.py:146} INFO - Started process (PID=5752) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:24:50,517] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 13:24:50,517] {logging_mixin.py:95} INFO - [2019-10-16 13:24:50,517] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:24:50,525] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:24:50,559] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 13:24:50,573] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 07:45:00+00:00: scheduled__2019-10-16T07:45:00+00:00, externally triggered: False>
[2019-10-16 13:24:50,604] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 13:24:50,612] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.098 seconds
[2019-10-16 13:25:00,613] {logging_mixin.py:95} INFO - [2019-10-16 13:25:00,613] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=5776
[2019-10-16 13:25:00,615] {scheduler_job.py:146} INFO - Started process (PID=5776) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:25:00,617] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 13:25:00,618] {logging_mixin.py:95} INFO - [2019-10-16 13:25:00,618] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:25:00,626] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:25:00,659] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 13:25:00,692] {scheduler_job.py:1265} INFO - Created <DagRun file_operations_pipeline @ 2019-10-16T07:50:00+00:00: scheduled__2019-10-16T07:50:00+00:00, externally triggered: False>
[2019-10-16 13:25:00,696] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 07:45:00+00:00: scheduled__2019-10-16T07:45:00+00:00, externally triggered: False>
[2019-10-16 13:25:00,707] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 07:50:00+00:00: scheduled__2019-10-16T07:50:00+00:00, externally triggered: False>
[2019-10-16 13:25:00,766] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 13:25:00,770] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.move_target_to_source 2019-10-16 07:45:00+00:00 [scheduled]> in ORM
[2019-10-16 13:25:00,775] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.sleep 2019-10-16 07:50:00+00:00 [scheduled]> in ORM
[2019-10-16 13:25:00,779] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.zip_target 2019-10-16 07:50:00+00:00 [scheduled]> in ORM
[2019-10-16 13:25:00,792] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.176 seconds
[2019-10-16 13:25:10,714] {logging_mixin.py:95} INFO - [2019-10-16 13:25:10,713] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=5883
[2019-10-16 13:25:10,717] {scheduler_job.py:146} INFO - Started process (PID=5883) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:25:10,719] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 13:25:10,719] {logging_mixin.py:95} INFO - [2019-10-16 13:25:10,719] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:25:10,728] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:25:10,757] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 13:25:10,772] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 07:45:00+00:00: scheduled__2019-10-16T07:45:00+00:00, externally triggered: False>
[2019-10-16 13:25:10,787] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 07:50:00+00:00: scheduled__2019-10-16T07:50:00+00:00, externally triggered: False>
[2019-10-16 13:25:10,834] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 13:25:10,838] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.move_target_to_source 2019-10-16 07:50:00+00:00 [scheduled]> in ORM
[2019-10-16 13:25:10,849] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.132 seconds
[2019-10-16 13:25:20,806] {logging_mixin.py:95} INFO - [2019-10-16 13:25:20,806] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=5951
[2019-10-16 13:25:20,809] {scheduler_job.py:146} INFO - Started process (PID=5951) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:25:20,811] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 13:25:20,811] {logging_mixin.py:95} INFO - [2019-10-16 13:25:20,811] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:25:20,820] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:25:20,850] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 13:25:20,865] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 07:45:00+00:00: scheduled__2019-10-16T07:45:00+00:00, externally triggered: False>
[2019-10-16 13:25:20,880] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 07:50:00+00:00: scheduled__2019-10-16T07:50:00+00:00, externally triggered: False>
[2019-10-16 13:25:20,932] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 13:25:20,938] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.129 seconds
[2019-10-16 13:25:30,946] {logging_mixin.py:95} INFO - [2019-10-16 13:25:30,946] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=5979
[2019-10-16 13:25:30,949] {scheduler_job.py:146} INFO - Started process (PID=5979) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:25:30,951] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 13:25:30,952] {logging_mixin.py:95} INFO - [2019-10-16 13:25:30,952] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:25:30,961] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:25:30,989] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 13:25:31,004] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 07:45:00+00:00: scheduled__2019-10-16T07:45:00+00:00, externally triggered: False>
[2019-10-16 13:25:31,020] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 07:50:00+00:00: scheduled__2019-10-16T07:50:00+00:00, externally triggered: False>
[2019-10-16 13:25:31,067] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 13:25:31,073] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.125 seconds
[2019-10-16 13:25:41,044] {logging_mixin.py:95} INFO - [2019-10-16 13:25:41,044] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=5999
[2019-10-16 13:25:41,046] {scheduler_job.py:146} INFO - Started process (PID=5999) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:25:41,049] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 13:25:41,049] {logging_mixin.py:95} INFO - [2019-10-16 13:25:41,049] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:25:41,058] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:25:41,087] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 13:25:41,101] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 07:45:00+00:00: scheduled__2019-10-16T07:45:00+00:00, externally triggered: False>
[2019-10-16 13:25:41,116] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 07:50:00+00:00: scheduled__2019-10-16T07:50:00+00:00, externally triggered: False>
[2019-10-16 13:25:41,162] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 13:25:41,168] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.121 seconds
[2019-10-16 13:25:51,147] {logging_mixin.py:95} INFO - [2019-10-16 13:25:51,146] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=6021
[2019-10-16 13:25:51,149] {scheduler_job.py:146} INFO - Started process (PID=6021) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:25:51,152] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 13:25:51,152] {logging_mixin.py:95} INFO - [2019-10-16 13:25:51,152] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:25:51,162] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:25:51,190] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 13:25:51,207] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 07:45:00+00:00: scheduled__2019-10-16T07:45:00+00:00, externally triggered: False>
[2019-10-16 13:25:51,222] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 07:50:00+00:00: scheduled__2019-10-16T07:50:00+00:00, externally triggered: False>
[2019-10-16 13:25:51,267] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 13:25:51,273] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.124 seconds
[2019-10-16 13:26:01,257] {logging_mixin.py:95} INFO - [2019-10-16 13:26:01,257] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=6046
[2019-10-16 13:26:01,260] {scheduler_job.py:146} INFO - Started process (PID=6046) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:26:01,262] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 13:26:01,263] {logging_mixin.py:95} INFO - [2019-10-16 13:26:01,263] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:26:01,271] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:26:01,302] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 13:26:01,320] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 07:45:00+00:00: scheduled__2019-10-16T07:45:00+00:00, externally triggered: False>
[2019-10-16 13:26:01,337] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 07:50:00+00:00: scheduled__2019-10-16T07:50:00+00:00, externally triggered: False>
[2019-10-16 13:26:01,384] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 13:26:01,390] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.131 seconds
[2019-10-16 13:26:11,369] {logging_mixin.py:95} INFO - [2019-10-16 13:26:11,369] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=6074
[2019-10-16 13:26:11,372] {scheduler_job.py:146} INFO - Started process (PID=6074) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:26:11,375] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 13:26:11,375] {logging_mixin.py:95} INFO - [2019-10-16 13:26:11,375] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:26:11,384] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:26:11,416] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 13:26:11,430] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 07:45:00+00:00: scheduled__2019-10-16T07:45:00+00:00, externally triggered: False>
[2019-10-16 13:26:11,445] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 07:50:00+00:00: scheduled__2019-10-16T07:50:00+00:00, externally triggered: False>
[2019-10-16 13:26:11,490] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 13:26:11,496] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.124 seconds
[2019-10-16 13:26:21,473] {logging_mixin.py:95} INFO - [2019-10-16 13:26:21,472] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=6096
[2019-10-16 13:26:21,476] {scheduler_job.py:146} INFO - Started process (PID=6096) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:26:21,480] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 13:26:21,481] {logging_mixin.py:95} INFO - [2019-10-16 13:26:21,481] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:26:21,491] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 13:26:21,543] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 13:26:21,567] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 07:45:00+00:00: scheduled__2019-10-16T07:45:00+00:00, externally triggered: False>
[2019-10-16 13:26:21,592] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 07:50:00+00:00: scheduled__2019-10-16T07:50:00+00:00, externally triggered: False>
[2019-10-16 13:26:21,654] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 13:26:21,662] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.186 seconds
[2019-10-16 14:34:34,280] {logging_mixin.py:95} INFO - [2019-10-16 14:34:34,279] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=9109
[2019-10-16 14:34:34,283] {scheduler_job.py:146} INFO - Started process (PID=9109) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:34:34,286] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:34:34,286] {logging_mixin.py:95} INFO - [2019-10-16 14:34:34,286] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:34:34,296] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:34:34,327] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.044 seconds
[2019-10-16 14:34:44,407] {logging_mixin.py:95} INFO - [2019-10-16 14:34:44,406] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=9138
[2019-10-16 14:34:44,412] {scheduler_job.py:146} INFO - Started process (PID=9138) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:34:44,417] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:34:44,418] {logging_mixin.py:95} INFO - [2019-10-16 14:34:44,417] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:34:44,431] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:34:44,458] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.045 seconds
[2019-10-16 14:34:54,498] {logging_mixin.py:95} INFO - [2019-10-16 14:34:54,498] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=9161
[2019-10-16 14:34:54,500] {scheduler_job.py:146} INFO - Started process (PID=9161) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:34:54,503] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:34:54,503] {logging_mixin.py:95} INFO - [2019-10-16 14:34:54,503] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:34:54,511] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:34:54,543] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.042 seconds
[2019-10-16 14:35:04,611] {logging_mixin.py:95} INFO - [2019-10-16 14:35:04,611] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=9228
[2019-10-16 14:35:04,614] {scheduler_job.py:146} INFO - Started process (PID=9228) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:35:04,616] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:35:04,616] {logging_mixin.py:95} INFO - [2019-10-16 14:35:04,616] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:35:04,625] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:35:04,652] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.038 seconds
[2019-10-16 14:35:14,742] {logging_mixin.py:95} INFO - [2019-10-16 14:35:14,742] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=9252
[2019-10-16 14:35:14,748] {scheduler_job.py:146} INFO - Started process (PID=9252) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:35:14,753] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:35:14,753] {logging_mixin.py:95} INFO - [2019-10-16 14:35:14,753] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:35:14,764] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:35:14,794] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.046 seconds
[2019-10-16 14:35:25,875] {logging_mixin.py:95} INFO - [2019-10-16 14:35:25,874] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=9353
[2019-10-16 14:35:25,883] {scheduler_job.py:146} INFO - Started process (PID=9353) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:35:25,889] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:35:25,890] {logging_mixin.py:95} INFO - [2019-10-16 14:35:25,890] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:35:26,318] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:35:27,807] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 1.924 seconds
[2019-10-16 14:35:38,033] {logging_mixin.py:95} INFO - [2019-10-16 14:35:38,033] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=9407
[2019-10-16 14:35:38,040] {scheduler_job.py:146} INFO - Started process (PID=9407) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:35:38,046] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:35:38,047] {logging_mixin.py:95} INFO - [2019-10-16 14:35:38,047] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:35:38,067] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:35:38,101] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.061 seconds
[2019-10-16 14:35:47,134] {logging_mixin.py:95} INFO - [2019-10-16 14:35:47,134] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=9427
[2019-10-16 14:35:47,136] {scheduler_job.py:146} INFO - Started process (PID=9427) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:35:47,138] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:35:47,139] {logging_mixin.py:95} INFO - [2019-10-16 14:35:47,139] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:35:47,147] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:35:47,175] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 14:35:47,205] {scheduler_job.py:1265} INFO - Created <DagRun file_operations_pipeline @ 2019-10-16T09:00:00+00:00: scheduled__2019-10-16T09:00:00+00:00, externally triggered: False>
[2019-10-16 14:35:47,209] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:00:00+00:00: scheduled__2019-10-16T09:00:00+00:00, externally triggered: False>
[2019-10-16 14:35:47,252] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 14:35:47,255] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.sleep 2019-10-16 09:00:00+00:00 [scheduled]> in ORM
[2019-10-16 14:35:47,260] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.zip_target 2019-10-16 09:00:00+00:00 [scheduled]> in ORM
[2019-10-16 14:35:47,271] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.135 seconds
[2019-10-16 14:35:57,267] {logging_mixin.py:95} INFO - [2019-10-16 14:35:57,266] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=9538
[2019-10-16 14:35:57,304] {scheduler_job.py:146} INFO - Started process (PID=9538) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:35:57,309] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:35:57,310] {logging_mixin.py:95} INFO - [2019-10-16 14:35:57,310] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:35:57,330] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:35:57,482] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 14:35:57,503] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:00:00+00:00: scheduled__2019-10-16T09:00:00+00:00, externally triggered: False>
[2019-10-16 14:35:57,596] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 14:35:57,601] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.move_target_to_source 2019-10-16 09:00:00+00:00 [scheduled]> in ORM
[2019-10-16 14:35:57,762] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.459 seconds
[2019-10-16 14:36:07,383] {logging_mixin.py:95} INFO - [2019-10-16 14:36:07,382] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=9606
[2019-10-16 14:36:07,389] {scheduler_job.py:146} INFO - Started process (PID=9606) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:36:07,396] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:36:07,397] {logging_mixin.py:95} INFO - [2019-10-16 14:36:07,396] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:36:07,418] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:36:07,505] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 14:36:07,538] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:00:00+00:00: scheduled__2019-10-16T09:00:00+00:00, externally triggered: False>
[2019-10-16 14:36:07,608] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 14:36:07,615] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.unzip_source 2019-10-16 09:00:00+00:00 [scheduled]> in ORM
[2019-10-16 14:36:07,633] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.244 seconds
[2019-10-16 14:36:17,500] {logging_mixin.py:95} INFO - [2019-10-16 14:36:17,499] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=9669
[2019-10-16 14:36:17,504] {scheduler_job.py:146} INFO - Started process (PID=9669) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:36:17,509] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:36:17,510] {logging_mixin.py:95} INFO - [2019-10-16 14:36:17,510] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:36:17,523] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:36:17,596] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 14:36:17,623] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:00:00+00:00: scheduled__2019-10-16T09:00:00+00:00, externally triggered: False>
[2019-10-16 14:36:17,673] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 14:36:17,678] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.print_first_ten_lines 2019-10-16 09:00:00+00:00 [scheduled]> in ORM
[2019-10-16 14:36:17,744] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.240 seconds
[2019-10-16 14:36:27,633] {logging_mixin.py:95} INFO - [2019-10-16 14:36:27,632] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=9738
[2019-10-16 14:36:27,639] {scheduler_job.py:146} INFO - Started process (PID=9738) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:36:27,644] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:36:27,645] {logging_mixin.py:95} INFO - [2019-10-16 14:36:27,645] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:36:27,668] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:36:27,704] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 14:36:27,719] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:00:00+00:00: scheduled__2019-10-16T09:00:00+00:00, externally triggered: False>
[2019-10-16 14:36:27,747] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 14:36:27,757] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.118 seconds
[2019-10-16 14:36:37,817] {logging_mixin.py:95} INFO - [2019-10-16 14:36:37,817] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=9770
[2019-10-16 14:36:37,821] {scheduler_job.py:146} INFO - Started process (PID=9770) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:36:37,825] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:36:37,825] {logging_mixin.py:95} INFO - [2019-10-16 14:36:37,825] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:36:37,840] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:36:37,881] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 14:36:37,899] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:00:00+00:00: scheduled__2019-10-16T09:00:00+00:00, externally triggered: False>
[2019-10-16 14:36:37,930] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 14:36:37,938] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.117 seconds
[2019-10-16 14:36:47,943] {logging_mixin.py:95} INFO - [2019-10-16 14:36:47,943] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=9798
[2019-10-16 14:36:47,946] {scheduler_job.py:146} INFO - Started process (PID=9798) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:36:47,948] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:36:47,949] {logging_mixin.py:95} INFO - [2019-10-16 14:36:47,948] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:36:47,964] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:36:47,996] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 14:36:48,010] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:00:00+00:00: scheduled__2019-10-16T09:00:00+00:00, externally triggered: False>
[2019-10-16 14:36:48,040] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 14:36:48,049] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.104 seconds
[2019-10-16 14:36:58,084] {logging_mixin.py:95} INFO - [2019-10-16 14:36:58,083] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=9826
[2019-10-16 14:36:58,089] {scheduler_job.py:146} INFO - Started process (PID=9826) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:36:58,092] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:36:58,093] {logging_mixin.py:95} INFO - [2019-10-16 14:36:58,093] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:36:58,104] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:36:58,138] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 14:36:58,156] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:00:00+00:00: scheduled__2019-10-16T09:00:00+00:00, externally triggered: False>
[2019-10-16 14:36:58,184] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 14:36:58,191] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.102 seconds
[2019-10-16 14:37:08,211] {logging_mixin.py:95} INFO - [2019-10-16 14:37:08,211] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=9850
[2019-10-16 14:37:08,214] {scheduler_job.py:146} INFO - Started process (PID=9850) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:37:08,217] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:37:08,217] {logging_mixin.py:95} INFO - [2019-10-16 14:37:08,217] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:37:08,226] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:37:08,267] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 14:37:08,283] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:00:00+00:00: scheduled__2019-10-16T09:00:00+00:00, externally triggered: False>
[2019-10-16 14:37:08,307] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 14:37:08,313] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.098 seconds
[2019-10-16 14:37:18,321] {logging_mixin.py:95} INFO - [2019-10-16 14:37:18,321] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=9872
[2019-10-16 14:37:18,324] {scheduler_job.py:146} INFO - Started process (PID=9872) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:37:18,326] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:37:18,327] {logging_mixin.py:95} INFO - [2019-10-16 14:37:18,326] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:37:18,335] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:37:18,363] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 14:37:18,379] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:00:00+00:00: scheduled__2019-10-16T09:00:00+00:00, externally triggered: False>
[2019-10-16 14:37:18,407] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 14:37:18,413] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.089 seconds
[2019-10-16 14:37:28,446] {logging_mixin.py:95} INFO - [2019-10-16 14:37:28,446] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=9905
[2019-10-16 14:37:28,453] {scheduler_job.py:146} INFO - Started process (PID=9905) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:37:28,458] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:37:28,459] {logging_mixin.py:95} INFO - [2019-10-16 14:37:28,459] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:37:28,474] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:37:28,527] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 14:37:28,554] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:00:00+00:00: scheduled__2019-10-16T09:00:00+00:00, externally triggered: False>
[2019-10-16 14:37:28,581] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 14:37:28,588] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.135 seconds
[2019-10-16 14:37:38,595] {logging_mixin.py:95} INFO - [2019-10-16 14:37:38,595] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=9933
[2019-10-16 14:37:38,599] {scheduler_job.py:146} INFO - Started process (PID=9933) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:37:38,601] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:37:38,601] {logging_mixin.py:95} INFO - [2019-10-16 14:37:38,601] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:37:38,611] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:37:38,642] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 14:37:38,657] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:00:00+00:00: scheduled__2019-10-16T09:00:00+00:00, externally triggered: False>
[2019-10-16 14:37:38,682] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 14:37:38,688] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.090 seconds
[2019-10-16 14:37:48,692] {logging_mixin.py:95} INFO - [2019-10-16 14:37:48,691] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=9953
[2019-10-16 14:37:48,695] {scheduler_job.py:146} INFO - Started process (PID=9953) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:37:48,697] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:37:48,697] {logging_mixin.py:95} INFO - [2019-10-16 14:37:48,697] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:37:48,706] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:37:48,734] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 14:37:48,747] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:00:00+00:00: scheduled__2019-10-16T09:00:00+00:00, externally triggered: False>
[2019-10-16 14:37:48,772] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 14:37:48,778] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.084 seconds
[2019-10-16 14:37:58,797] {logging_mixin.py:95} INFO - [2019-10-16 14:37:58,797] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=9979
[2019-10-16 14:37:58,801] {scheduler_job.py:146} INFO - Started process (PID=9979) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:37:58,804] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:37:58,804] {logging_mixin.py:95} INFO - [2019-10-16 14:37:58,804] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:37:58,815] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:37:58,850] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 14:37:58,869] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:00:00+00:00: scheduled__2019-10-16T09:00:00+00:00, externally triggered: False>
[2019-10-16 14:37:58,905] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 14:37:58,914] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.114 seconds
[2019-10-16 14:38:08,919] {logging_mixin.py:95} INFO - [2019-10-16 14:38:08,919] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=10003
[2019-10-16 14:38:08,924] {scheduler_job.py:146} INFO - Started process (PID=10003) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:38:08,928] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:38:08,928] {logging_mixin.py:95} INFO - [2019-10-16 14:38:08,928] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:38:08,939] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:38:08,970] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 14:38:08,984] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:00:00+00:00: scheduled__2019-10-16T09:00:00+00:00, externally triggered: False>
[2019-10-16 14:38:09,009] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 14:38:09,016] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.092 seconds
[2019-10-16 14:38:19,066] {logging_mixin.py:95} INFO - [2019-10-16 14:38:19,066] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=10026
[2019-10-16 14:38:19,069] {scheduler_job.py:146} INFO - Started process (PID=10026) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:38:19,071] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:38:19,072] {logging_mixin.py:95} INFO - [2019-10-16 14:38:19,072] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:38:19,080] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:38:19,113] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 14:38:19,128] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:00:00+00:00: scheduled__2019-10-16T09:00:00+00:00, externally triggered: False>
[2019-10-16 14:38:19,157] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 14:38:19,164] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.095 seconds
[2019-10-16 14:38:29,214] {logging_mixin.py:95} INFO - [2019-10-16 14:38:29,213] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=10048
[2019-10-16 14:38:29,220] {scheduler_job.py:146} INFO - Started process (PID=10048) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:38:29,226] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:38:29,228] {logging_mixin.py:95} INFO - [2019-10-16 14:38:29,228] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:38:29,254] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:38:29,307] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 14:38:29,334] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:00:00+00:00: scheduled__2019-10-16T09:00:00+00:00, externally triggered: False>
[2019-10-16 14:38:29,374] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 14:38:29,381] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.print_first_ten_lines 2019-10-16 09:00:00+00:00 [scheduled]> in ORM
[2019-10-16 14:38:29,402] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.182 seconds
[2019-10-16 14:38:39,340] {logging_mixin.py:95} INFO - [2019-10-16 14:38:39,340] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=10113
[2019-10-16 14:38:39,345] {scheduler_job.py:146} INFO - Started process (PID=10113) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:38:39,347] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:38:39,348] {logging_mixin.py:95} INFO - [2019-10-16 14:38:39,348] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:38:39,357] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:38:39,392] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 14:38:39,408] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:00:00+00:00: scheduled__2019-10-16T09:00:00+00:00, externally triggered: False>
[2019-10-16 14:38:39,438] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 14:38:39,445] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.101 seconds
[2019-10-16 14:38:49,468] {logging_mixin.py:95} INFO - [2019-10-16 14:38:49,467] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=10133
[2019-10-16 14:38:49,473] {scheduler_job.py:146} INFO - Started process (PID=10133) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:38:49,481] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:38:49,482] {logging_mixin.py:95} INFO - [2019-10-16 14:38:49,482] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:38:49,500] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:38:49,534] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 14:38:49,548] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:00:00+00:00: scheduled__2019-10-16T09:00:00+00:00, externally triggered: False>
[2019-10-16 14:38:49,573] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 14:38:49,582] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.109 seconds
[2019-10-16 14:40:45,932] {logging_mixin.py:95} INFO - [2019-10-16 14:40:45,931] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=10189
[2019-10-16 14:40:45,934] {scheduler_job.py:146} INFO - Started process (PID=10189) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:40:45,937] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:40:45,938] {logging_mixin.py:95} INFO - [2019-10-16 14:40:45,938] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:40:45,947] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:40:45,977] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.043 seconds
[2019-10-16 14:40:56,047] {logging_mixin.py:95} INFO - [2019-10-16 14:40:56,047] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=10275
[2019-10-16 14:40:56,054] {scheduler_job.py:146} INFO - Started process (PID=10275) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:40:56,059] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:40:56,060] {logging_mixin.py:95} INFO - [2019-10-16 14:40:56,060] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:40:56,082] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:40:56,155] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.101 seconds
[2019-10-16 14:41:06,193] {logging_mixin.py:95} INFO - [2019-10-16 14:41:06,192] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=10377
[2019-10-16 14:41:06,199] {scheduler_job.py:146} INFO - Started process (PID=10377) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:41:06,204] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:41:06,205] {logging_mixin.py:95} INFO - [2019-10-16 14:41:06,204] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:41:06,224] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:41:06,259] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.060 seconds
[2019-10-16 14:41:16,323] {logging_mixin.py:95} INFO - [2019-10-16 14:41:16,322] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=10410
[2019-10-16 14:41:16,327] {scheduler_job.py:146} INFO - Started process (PID=10410) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:41:16,330] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:41:16,331] {logging_mixin.py:95} INFO - [2019-10-16 14:41:16,330] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:41:16,346] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:41:16,376] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.050 seconds
[2019-10-16 14:41:26,447] {logging_mixin.py:95} INFO - [2019-10-16 14:41:26,447] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=10431
[2019-10-16 14:41:26,450] {scheduler_job.py:146} INFO - Started process (PID=10431) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:41:26,453] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:41:26,453] {logging_mixin.py:95} INFO - [2019-10-16 14:41:26,453] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:41:26,462] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:41:26,494] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 14:41:26,528] {scheduler_job.py:1265} INFO - Created <DagRun file_operations_pipeline @ 2019-10-16T09:05:00+00:00: scheduled__2019-10-16T09:05:00+00:00, externally triggered: False>
[2019-10-16 14:41:26,532] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:05:00+00:00: scheduled__2019-10-16T09:05:00+00:00, externally triggered: False>
[2019-10-16 14:41:26,573] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 14:41:26,577] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.sleep 2019-10-16 09:05:00+00:00 [scheduled]> in ORM
[2019-10-16 14:41:26,581] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.zip_target 2019-10-16 09:05:00+00:00 [scheduled]> in ORM
[2019-10-16 14:41:26,592] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.142 seconds
[2019-10-16 14:41:36,561] {logging_mixin.py:95} INFO - [2019-10-16 14:41:36,561] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=10524
[2019-10-16 14:41:36,568] {scheduler_job.py:146} INFO - Started process (PID=10524) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:41:36,573] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:41:36,573] {logging_mixin.py:95} INFO - [2019-10-16 14:41:36,573] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:41:36,586] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:41:36,673] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 14:41:36,689] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:05:00+00:00: scheduled__2019-10-16T09:05:00+00:00, externally triggered: False>
[2019-10-16 14:41:36,720] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 14:41:36,724] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.move_target_to_source 2019-10-16 09:05:00+00:00 [scheduled]> in ORM
[2019-10-16 14:41:36,762] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.195 seconds
[2019-10-16 14:41:46,671] {logging_mixin.py:95} INFO - [2019-10-16 14:41:46,671] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=10598
[2019-10-16 14:41:46,677] {scheduler_job.py:146} INFO - Started process (PID=10598) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:41:46,681] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:41:46,682] {logging_mixin.py:95} INFO - [2019-10-16 14:41:46,682] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:41:46,694] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:41:46,721] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 14:41:46,735] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:05:00+00:00: scheduled__2019-10-16T09:05:00+00:00, externally triggered: False>
[2019-10-16 14:41:46,774] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 14:41:46,778] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.unzip_source 2019-10-16 09:05:00+00:00 [scheduled]> in ORM
[2019-10-16 14:41:46,791] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.114 seconds
[2019-10-16 14:41:56,783] {logging_mixin.py:95} INFO - [2019-10-16 14:41:56,783] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=10662
[2019-10-16 14:41:56,786] {scheduler_job.py:146} INFO - Started process (PID=10662) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:41:56,789] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:41:56,789] {logging_mixin.py:95} INFO - [2019-10-16 14:41:56,789] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:41:56,801] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:41:56,831] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 14:41:56,845] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:05:00+00:00: scheduled__2019-10-16T09:05:00+00:00, externally triggered: False>
[2019-10-16 14:41:56,873] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 14:41:56,877] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.print_first_ten_lines 2019-10-16 09:05:00+00:00 [scheduled]> in ORM
[2019-10-16 14:41:56,891] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.105 seconds
[2019-10-16 14:42:06,883] {logging_mixin.py:95} INFO - [2019-10-16 14:42:06,883] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=10742
[2019-10-16 14:42:06,887] {scheduler_job.py:146} INFO - Started process (PID=10742) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:42:06,890] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:42:06,891] {logging_mixin.py:95} INFO - [2019-10-16 14:42:06,891] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:42:06,904] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:42:06,945] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 14:42:06,967] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:05:00+00:00: scheduled__2019-10-16T09:05:00+00:00, externally triggered: False>
[2019-10-16 14:42:07,001] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 14:42:07,008] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.121 seconds
[2019-10-16 14:42:17,021] {logging_mixin.py:95} INFO - [2019-10-16 14:42:17,021] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=10767
[2019-10-16 14:42:17,026] {scheduler_job.py:146} INFO - Started process (PID=10767) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:42:17,033] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:42:17,033] {logging_mixin.py:95} INFO - [2019-10-16 14:42:17,033] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:42:17,047] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:42:17,106] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 14:42:17,136] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:05:00+00:00: scheduled__2019-10-16T09:05:00+00:00, externally triggered: False>
[2019-10-16 14:42:17,186] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 14:42:17,201] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.175 seconds
[2019-10-16 14:42:27,186] {logging_mixin.py:95} INFO - [2019-10-16 14:42:27,185] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=10796
[2019-10-16 14:42:27,197] {scheduler_job.py:146} INFO - Started process (PID=10796) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:42:27,206] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:42:27,208] {logging_mixin.py:95} INFO - [2019-10-16 14:42:27,208] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:42:27,227] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:42:27,263] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 14:42:27,277] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:05:00+00:00: scheduled__2019-10-16T09:05:00+00:00, externally triggered: False>
[2019-10-16 14:42:27,301] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 14:42:27,307] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.110 seconds
[2019-10-16 14:42:37,299] {logging_mixin.py:95} INFO - [2019-10-16 14:42:37,299] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=10829
[2019-10-16 14:42:37,305] {scheduler_job.py:146} INFO - Started process (PID=10829) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:42:37,309] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:42:37,310] {logging_mixin.py:95} INFO - [2019-10-16 14:42:37,309] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:42:37,320] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:42:37,351] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 14:42:37,365] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:05:00+00:00: scheduled__2019-10-16T09:05:00+00:00, externally triggered: False>
[2019-10-16 14:42:37,392] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 14:42:37,399] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.093 seconds
[2019-10-16 14:42:47,424] {logging_mixin.py:95} INFO - [2019-10-16 14:42:47,424] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=10850
[2019-10-16 14:42:47,427] {scheduler_job.py:146} INFO - Started process (PID=10850) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:42:47,429] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:42:47,430] {logging_mixin.py:95} INFO - [2019-10-16 14:42:47,429] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:42:47,440] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:42:47,470] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 14:42:47,484] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:05:00+00:00: scheduled__2019-10-16T09:05:00+00:00, externally triggered: False>
[2019-10-16 14:42:47,513] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 14:42:47,520] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.093 seconds
[2019-10-16 14:42:57,597] {logging_mixin.py:95} INFO - [2019-10-16 14:42:57,597] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=10873
[2019-10-16 14:42:57,603] {scheduler_job.py:146} INFO - Started process (PID=10873) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:42:57,607] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:42:57,608] {logging_mixin.py:95} INFO - [2019-10-16 14:42:57,608] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:42:57,618] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:42:57,645] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 14:42:57,659] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:05:00+00:00: scheduled__2019-10-16T09:05:00+00:00, externally triggered: False>
[2019-10-16 14:42:57,682] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 14:42:57,688] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.085 seconds
[2019-10-16 14:43:07,724] {logging_mixin.py:95} INFO - [2019-10-16 14:43:07,723] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=10898
[2019-10-16 14:43:07,731] {scheduler_job.py:146} INFO - Started process (PID=10898) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:43:07,738] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:43:07,739] {logging_mixin.py:95} INFO - [2019-10-16 14:43:07,739] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:43:07,769] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:43:07,844] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 14:43:07,876] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:05:00+00:00: scheduled__2019-10-16T09:05:00+00:00, externally triggered: False>
[2019-10-16 14:43:07,907] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 14:43:07,919] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.187 seconds
[2019-10-16 14:43:17,861] {logging_mixin.py:95} INFO - [2019-10-16 14:43:17,860] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=10934
[2019-10-16 14:43:17,865] {scheduler_job.py:146} INFO - Started process (PID=10934) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:43:17,868] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:43:17,869] {logging_mixin.py:95} INFO - [2019-10-16 14:43:17,868] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:43:17,879] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:43:17,913] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 14:43:17,929] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:05:00+00:00: scheduled__2019-10-16T09:05:00+00:00, externally triggered: False>
[2019-10-16 14:43:17,953] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 14:43:17,960] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.095 seconds
[2019-10-16 14:43:27,967] {logging_mixin.py:95} INFO - [2019-10-16 14:43:27,966] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=10961
[2019-10-16 14:43:27,971] {scheduler_job.py:146} INFO - Started process (PID=10961) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:43:27,973] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:43:27,974] {logging_mixin.py:95} INFO - [2019-10-16 14:43:27,973] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:43:27,984] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:43:28,014] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 14:43:28,027] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:05:00+00:00: scheduled__2019-10-16T09:05:00+00:00, externally triggered: False>
[2019-10-16 14:43:28,051] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 14:43:28,058] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.087 seconds
[2019-10-16 14:43:38,060] {logging_mixin.py:95} INFO - [2019-10-16 14:43:38,060] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=10985
[2019-10-16 14:43:38,063] {scheduler_job.py:146} INFO - Started process (PID=10985) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:43:38,065] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:43:38,065] {logging_mixin.py:95} INFO - [2019-10-16 14:43:38,065] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:43:38,074] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:43:38,104] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 14:43:38,118] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:05:00+00:00: scheduled__2019-10-16T09:05:00+00:00, externally triggered: False>
[2019-10-16 14:43:38,143] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 14:43:38,149] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.086 seconds
[2019-10-16 14:43:48,207] {logging_mixin.py:95} INFO - [2019-10-16 14:43:48,207] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=11008
[2019-10-16 14:43:48,215] {scheduler_job.py:146} INFO - Started process (PID=11008) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:43:48,222] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:43:48,223] {logging_mixin.py:95} INFO - [2019-10-16 14:43:48,222] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:43:48,249] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:43:48,316] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 14:43:48,342] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:05:00+00:00: scheduled__2019-10-16T09:05:00+00:00, externally triggered: False>
[2019-10-16 14:43:48,367] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 14:43:48,373] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.158 seconds
[2019-10-16 14:43:58,399] {logging_mixin.py:95} INFO - [2019-10-16 14:43:58,399] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=11066
[2019-10-16 14:43:58,405] {scheduler_job.py:146} INFO - Started process (PID=11066) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:43:58,410] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:43:58,411] {logging_mixin.py:95} INFO - [2019-10-16 14:43:58,411] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:43:58,424] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:43:58,452] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 14:43:58,466] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:05:00+00:00: scheduled__2019-10-16T09:05:00+00:00, externally triggered: False>
[2019-10-16 14:43:58,490] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 14:43:58,496] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.091 seconds
[2019-10-16 14:44:08,511] {logging_mixin.py:95} INFO - [2019-10-16 14:44:08,511] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=11092
[2019-10-16 14:44:08,514] {scheduler_job.py:146} INFO - Started process (PID=11092) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:44:08,516] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:44:08,516] {logging_mixin.py:95} INFO - [2019-10-16 14:44:08,516] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:44:08,527] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:44:08,559] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 14:44:08,573] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:05:00+00:00: scheduled__2019-10-16T09:05:00+00:00, externally triggered: False>
[2019-10-16 14:44:08,597] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 14:44:08,602] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.print_first_ten_lines 2019-10-16 09:05:00+00:00 [scheduled]> in ORM
[2019-10-16 14:44:08,615] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.101 seconds
[2019-10-16 14:44:18,634] {logging_mixin.py:95} INFO - [2019-10-16 14:44:18,633] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=11156
[2019-10-16 14:44:18,638] {scheduler_job.py:146} INFO - Started process (PID=11156) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:44:18,641] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:44:18,642] {logging_mixin.py:95} INFO - [2019-10-16 14:44:18,642] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:44:18,651] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:44:18,682] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 14:44:18,696] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:05:00+00:00: scheduled__2019-10-16T09:05:00+00:00, externally triggered: False>
[2019-10-16 14:44:18,720] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 14:44:18,726] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.088 seconds
[2019-10-16 14:44:28,749] {logging_mixin.py:95} INFO - [2019-10-16 14:44:28,749] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=11180
[2019-10-16 14:44:28,755] {scheduler_job.py:146} INFO - Started process (PID=11180) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:44:28,759] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:44:28,760] {logging_mixin.py:95} INFO - [2019-10-16 14:44:28,760] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:44:28,773] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:44:28,802] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 14:44:28,815] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:05:00+00:00: scheduled__2019-10-16T09:05:00+00:00, externally triggered: False>
[2019-10-16 14:44:28,839] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 14:44:28,845] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.091 seconds
[2019-10-16 14:44:38,860] {logging_mixin.py:95} INFO - [2019-10-16 14:44:38,860] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=11204
[2019-10-16 14:44:38,866] {scheduler_job.py:146} INFO - Started process (PID=11204) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:44:38,870] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:44:38,871] {logging_mixin.py:95} INFO - [2019-10-16 14:44:38,871] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:44:38,884] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:44:38,913] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 14:44:38,926] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:05:00+00:00: scheduled__2019-10-16T09:05:00+00:00, externally triggered: False>
[2019-10-16 14:44:38,950] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 14:44:38,956] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.090 seconds
[2019-10-16 14:44:48,971] {logging_mixin.py:95} INFO - [2019-10-16 14:44:48,971] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=11225
[2019-10-16 14:44:48,974] {scheduler_job.py:146} INFO - Started process (PID=11225) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:44:48,976] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:44:48,977] {logging_mixin.py:95} INFO - [2019-10-16 14:44:48,976] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:44:48,985] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:44:49,015] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 14:44:49,028] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:05:00+00:00: scheduled__2019-10-16T09:05:00+00:00, externally triggered: False>
[2019-10-16 14:44:49,053] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 14:44:49,059] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.085 seconds
[2019-10-16 14:44:59,084] {logging_mixin.py:95} INFO - [2019-10-16 14:44:59,084] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=11248
[2019-10-16 14:44:59,087] {scheduler_job.py:146} INFO - Started process (PID=11248) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:44:59,089] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:44:59,090] {logging_mixin.py:95} INFO - [2019-10-16 14:44:59,090] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:44:59,099] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:44:59,128] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 14:44:59,141] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:05:00+00:00: scheduled__2019-10-16T09:05:00+00:00, externally triggered: False>
[2019-10-16 14:44:59,166] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 14:44:59,173] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.085 seconds
[2019-10-16 14:45:09,188] {logging_mixin.py:95} INFO - [2019-10-16 14:45:09,188] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=11277
[2019-10-16 14:45:09,191] {scheduler_job.py:146} INFO - Started process (PID=11277) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:45:09,193] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:45:09,193] {logging_mixin.py:95} INFO - [2019-10-16 14:45:09,193] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:45:09,202] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:45:09,233] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 14:45:09,265] {scheduler_job.py:1265} INFO - Created <DagRun file_operations_pipeline @ 2019-10-16T09:10:00+00:00: scheduled__2019-10-16T09:10:00+00:00, externally triggered: False>
[2019-10-16 14:45:09,269] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:05:00+00:00: scheduled__2019-10-16T09:05:00+00:00, externally triggered: False>
[2019-10-16 14:45:09,280] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:10:00+00:00: scheduled__2019-10-16T09:10:00+00:00, externally triggered: False>
[2019-10-16 14:45:09,335] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 14:45:09,338] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.sleep 2019-10-16 09:10:00+00:00 [scheduled]> in ORM
[2019-10-16 14:45:09,342] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.zip_target 2019-10-16 09:10:00+00:00 [scheduled]> in ORM
[2019-10-16 14:45:09,354] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.163 seconds
[2019-10-16 14:45:19,316] {logging_mixin.py:95} INFO - [2019-10-16 14:45:19,316] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=11365
[2019-10-16 14:45:19,319] {scheduler_job.py:146} INFO - Started process (PID=11365) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:45:19,321] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:45:19,322] {logging_mixin.py:95} INFO - [2019-10-16 14:45:19,321] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:45:19,332] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:45:19,359] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 14:45:19,373] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:05:00+00:00: scheduled__2019-10-16T09:05:00+00:00, externally triggered: False>
[2019-10-16 14:45:19,387] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:10:00+00:00: scheduled__2019-10-16T09:10:00+00:00, externally triggered: False>
[2019-10-16 14:45:19,426] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 14:45:19,430] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.move_target_to_source 2019-10-16 09:10:00+00:00 [scheduled]> in ORM
[2019-10-16 14:45:19,441] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.122 seconds
[2019-10-16 14:45:29,431] {logging_mixin.py:95} INFO - [2019-10-16 14:45:29,431] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=11434
[2019-10-16 14:45:29,438] {scheduler_job.py:146} INFO - Started process (PID=11434) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:45:29,441] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:45:29,442] {logging_mixin.py:95} INFO - [2019-10-16 14:45:29,442] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:45:29,459] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:45:29,513] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 14:45:29,544] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:05:00+00:00: scheduled__2019-10-16T09:05:00+00:00, externally triggered: False>
[2019-10-16 14:45:29,581] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:10:00+00:00: scheduled__2019-10-16T09:10:00+00:00, externally triggered: False>
[2019-10-16 14:45:29,721] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 14:45:29,734] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.unzip_source 2019-10-16 09:10:00+00:00 [scheduled]> in ORM
[2019-10-16 14:45:29,769] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.331 seconds
[2019-10-16 14:45:39,550] {logging_mixin.py:95} INFO - [2019-10-16 14:45:39,549] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=11510
[2019-10-16 14:45:39,558] {scheduler_job.py:146} INFO - Started process (PID=11510) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:45:39,562] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:45:39,562] {logging_mixin.py:95} INFO - [2019-10-16 14:45:39,562] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:45:39,581] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:45:39,632] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 14:45:39,663] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:05:00+00:00: scheduled__2019-10-16T09:05:00+00:00, externally triggered: False>
[2019-10-16 14:45:39,690] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:10:00+00:00: scheduled__2019-10-16T09:10:00+00:00, externally triggered: False>
[2019-10-16 14:45:39,757] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 14:45:39,764] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.print_first_ten_lines 2019-10-16 09:10:00+00:00 [scheduled]> in ORM
[2019-10-16 14:45:39,785] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.227 seconds
[2019-10-16 14:45:49,719] {logging_mixin.py:95} INFO - [2019-10-16 14:45:49,719] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=11574
[2019-10-16 14:45:49,723] {scheduler_job.py:146} INFO - Started process (PID=11574) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:45:49,727] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:45:49,728] {logging_mixin.py:95} INFO - [2019-10-16 14:45:49,728] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:45:49,742] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:45:49,783] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 14:45:49,805] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:05:00+00:00: scheduled__2019-10-16T09:05:00+00:00, externally triggered: False>
[2019-10-16 14:45:49,826] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:10:00+00:00: scheduled__2019-10-16T09:10:00+00:00, externally triggered: False>
[2019-10-16 14:45:49,891] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 14:45:49,906] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.183 seconds
[2019-10-16 14:45:59,832] {logging_mixin.py:95} INFO - [2019-10-16 14:45:59,831] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=11602
[2019-10-16 14:45:59,834] {scheduler_job.py:146} INFO - Started process (PID=11602) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:45:59,837] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:45:59,837] {logging_mixin.py:95} INFO - [2019-10-16 14:45:59,837] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:45:59,846] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:45:59,872] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 14:45:59,886] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:05:00+00:00: scheduled__2019-10-16T09:05:00+00:00, externally triggered: False>
[2019-10-16 14:45:59,899] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:10:00+00:00: scheduled__2019-10-16T09:10:00+00:00, externally triggered: False>
[2019-10-16 14:45:59,931] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 14:45:59,937] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.103 seconds
[2019-10-16 14:50:20,032] {logging_mixin.py:95} INFO - [2019-10-16 14:50:20,032] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=11799
[2019-10-16 14:50:20,036] {scheduler_job.py:146} INFO - Started process (PID=11799) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:50:20,039] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:50:20,039] {logging_mixin.py:95} INFO - [2019-10-16 14:50:20,039] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:50:20,060] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:50:20,111] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.075 seconds
[2019-10-16 14:50:40,310] {logging_mixin.py:95} INFO - [2019-10-16 14:50:40,309] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=11966
[2019-10-16 14:50:40,318] {scheduler_job.py:146} INFO - Started process (PID=11966) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:50:40,324] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:50:40,325] {logging_mixin.py:95} INFO - [2019-10-16 14:50:40,325] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:50:40,338] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:50:40,371] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.053 seconds
[2019-10-16 14:51:00,568] {logging_mixin.py:95} INFO - [2019-10-16 14:51:00,568] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=12026
[2019-10-16 14:51:00,574] {scheduler_job.py:146} INFO - Started process (PID=12026) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:51:00,580] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:51:00,580] {logging_mixin.py:95} INFO - [2019-10-16 14:51:00,580] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:51:00,598] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:51:00,631] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 14:51:00,661] {scheduler_job.py:1265} INFO - Created <DagRun file_operations_pipeline @ 2019-10-16T09:15:00+00:00: scheduled__2019-10-16T09:15:00+00:00, externally triggered: False>
[2019-10-16 14:51:00,665] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:15:00+00:00: scheduled__2019-10-16T09:15:00+00:00, externally triggered: False>
[2019-10-16 14:51:00,705] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 14:51:00,709] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.sleep 2019-10-16 09:15:00+00:00 [scheduled]> in ORM
[2019-10-16 14:51:00,714] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.zip_target 2019-10-16 09:15:00+00:00 [scheduled]> in ORM
[2019-10-16 14:51:00,724] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.150 seconds
[2019-10-16 14:51:20,775] {logging_mixin.py:95} INFO - [2019-10-16 14:51:20,774] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=12149
[2019-10-16 14:51:20,783] {scheduler_job.py:146} INFO - Started process (PID=12149) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:51:20,787] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:51:20,788] {logging_mixin.py:95} INFO - [2019-10-16 14:51:20,788] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:51:20,799] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:51:20,836] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 14:51:20,850] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:15:00+00:00: scheduled__2019-10-16T09:15:00+00:00, externally triggered: False>
[2019-10-16 14:51:20,883] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 14:51:20,887] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.move_target_to_source 2019-10-16 09:15:00+00:00 [scheduled]> in ORM
[2019-10-16 14:51:20,901] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.118 seconds
[2019-10-16 14:51:41,019] {logging_mixin.py:95} INFO - [2019-10-16 14:51:41,018] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=12246
[2019-10-16 14:51:41,026] {scheduler_job.py:146} INFO - Started process (PID=12246) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:51:41,034] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:51:41,035] {logging_mixin.py:95} INFO - [2019-10-16 14:51:41,035] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:51:41,061] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:51:41,121] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 14:51:41,141] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:15:00+00:00: scheduled__2019-10-16T09:15:00+00:00, externally triggered: False>
[2019-10-16 14:51:41,195] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 14:51:41,201] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.unzip_source 2019-10-16 09:15:00+00:00 [scheduled]> in ORM
[2019-10-16 14:51:41,216] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.190 seconds
[2019-10-16 14:52:01,265] {logging_mixin.py:95} INFO - [2019-10-16 14:52:01,264] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=12341
[2019-10-16 14:52:01,272] {scheduler_job.py:146} INFO - Started process (PID=12341) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:52:01,278] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:52:01,279] {logging_mixin.py:95} INFO - [2019-10-16 14:52:01,279] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:52:01,301] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:52:01,340] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 14:52:01,354] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:15:00+00:00: scheduled__2019-10-16T09:15:00+00:00, externally triggered: False>
[2019-10-16 14:52:01,381] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 14:52:01,385] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.print_first_ten_lines 2019-10-16 09:15:00+00:00 [scheduled]> in ORM
[2019-10-16 14:52:01,399] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.127 seconds
[2019-10-16 14:52:21,502] {logging_mixin.py:95} INFO - [2019-10-16 14:52:21,502] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=12426
[2019-10-16 14:52:21,505] {scheduler_job.py:146} INFO - Started process (PID=12426) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:52:21,507] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:52:21,507] {logging_mixin.py:95} INFO - [2019-10-16 14:52:21,507] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:52:21,516] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:52:21,548] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 14:52:21,561] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:15:00+00:00: scheduled__2019-10-16T09:15:00+00:00, externally triggered: False>
[2019-10-16 14:52:21,585] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 14:52:21,592] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.087 seconds
[2019-10-16 14:52:41,701] {logging_mixin.py:95} INFO - [2019-10-16 14:52:41,701] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=12477
[2019-10-16 14:52:41,704] {scheduler_job.py:146} INFO - Started process (PID=12477) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:52:41,707] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:52:41,707] {logging_mixin.py:95} INFO - [2019-10-16 14:52:41,707] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:52:41,716] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:52:41,755] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 14:52:41,770] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:15:00+00:00: scheduled__2019-10-16T09:15:00+00:00, externally triggered: False>
[2019-10-16 14:52:41,794] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 14:52:41,800] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.096 seconds
[2019-10-16 14:53:01,910] {logging_mixin.py:95} INFO - [2019-10-16 14:53:01,909] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=12522
[2019-10-16 14:53:01,915] {scheduler_job.py:146} INFO - Started process (PID=12522) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:53:01,920] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:53:01,921] {logging_mixin.py:95} INFO - [2019-10-16 14:53:01,921] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:53:01,940] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:53:01,981] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 14:53:01,995] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:15:00+00:00: scheduled__2019-10-16T09:15:00+00:00, externally triggered: False>
[2019-10-16 14:53:02,020] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 14:53:02,026] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.111 seconds
[2019-10-16 14:53:22,116] {logging_mixin.py:95} INFO - [2019-10-16 14:53:22,116] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=12568
[2019-10-16 14:53:22,119] {scheduler_job.py:146} INFO - Started process (PID=12568) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:53:22,121] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:53:22,122] {logging_mixin.py:95} INFO - [2019-10-16 14:53:22,121] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:53:22,130] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:53:22,158] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 14:53:22,172] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:15:00+00:00: scheduled__2019-10-16T09:15:00+00:00, externally triggered: False>
[2019-10-16 14:53:22,196] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 14:53:22,202] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.083 seconds
[2019-10-16 14:53:42,380] {logging_mixin.py:95} INFO - [2019-10-16 14:53:42,379] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=12630
[2019-10-16 14:53:42,388] {scheduler_job.py:146} INFO - Started process (PID=12630) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:53:42,393] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:53:42,394] {logging_mixin.py:95} INFO - [2019-10-16 14:53:42,394] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:53:42,406] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:53:42,439] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 14:53:42,453] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:15:00+00:00: scheduled__2019-10-16T09:15:00+00:00, externally triggered: False>
[2019-10-16 14:53:42,479] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 14:53:42,486] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.098 seconds
[2019-10-16 14:54:02,677] {logging_mixin.py:95} INFO - [2019-10-16 14:54:02,677] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=12676
[2019-10-16 14:54:02,683] {scheduler_job.py:146} INFO - Started process (PID=12676) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:54:02,689] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:54:02,689] {logging_mixin.py:95} INFO - [2019-10-16 14:54:02,689] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:54:02,703] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:54:02,733] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 14:54:02,746] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:15:00+00:00: scheduled__2019-10-16T09:15:00+00:00, externally triggered: False>
[2019-10-16 14:54:02,770] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 14:54:02,777] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.093 seconds
[2019-10-16 14:56:13,971] {logging_mixin.py:95} INFO - [2019-10-16 14:56:13,970] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=12833
[2019-10-16 14:56:13,973] {scheduler_job.py:146} INFO - Started process (PID=12833) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:56:13,975] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:56:13,975] {logging_mixin.py:95} INFO - [2019-10-16 14:56:13,975] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:56:13,984] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:56:14,015] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.042 seconds
[2019-10-16 14:56:24,097] {logging_mixin.py:95} INFO - [2019-10-16 14:56:24,096] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=12934
[2019-10-16 14:56:24,103] {scheduler_job.py:146} INFO - Started process (PID=12934) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:56:24,106] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:56:24,107] {logging_mixin.py:95} INFO - [2019-10-16 14:56:24,107] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:56:24,118] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:56:24,158] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.055 seconds
[2019-10-16 14:56:34,196] {logging_mixin.py:95} INFO - [2019-10-16 14:56:34,196] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=12987
[2019-10-16 14:56:34,199] {scheduler_job.py:146} INFO - Started process (PID=12987) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:56:34,201] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:56:34,202] {logging_mixin.py:95} INFO - [2019-10-16 14:56:34,202] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:56:34,216] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:56:34,244] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.045 seconds
[2019-10-16 14:56:44,336] {logging_mixin.py:95} INFO - [2019-10-16 14:56:44,336] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=13016
[2019-10-16 14:56:44,339] {scheduler_job.py:146} INFO - Started process (PID=13016) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:56:44,341] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:56:44,342] {logging_mixin.py:95} INFO - [2019-10-16 14:56:44,342] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:56:44,351] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:56:44,379] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 14:56:44,410] {scheduler_job.py:1265} INFO - Created <DagRun file_operations_pipeline @ 2019-10-16T09:20:00+00:00: scheduled__2019-10-16T09:20:00+00:00, externally triggered: False>
[2019-10-16 14:56:44,414] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:20:00+00:00: scheduled__2019-10-16T09:20:00+00:00, externally triggered: False>
[2019-10-16 14:56:44,456] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 14:56:44,460] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.sleep 2019-10-16 09:20:00+00:00 [scheduled]> in ORM
[2019-10-16 14:56:44,465] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.zip_target 2019-10-16 09:20:00+00:00 [scheduled]> in ORM
[2019-10-16 14:56:44,476] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.137 seconds
[2019-10-16 14:56:54,429] {logging_mixin.py:95} INFO - [2019-10-16 14:56:54,429] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=13103
[2019-10-16 14:56:54,432] {scheduler_job.py:146} INFO - Started process (PID=13103) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:56:54,434] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:56:54,434] {logging_mixin.py:95} INFO - [2019-10-16 14:56:54,434] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:56:54,444] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:56:54,504] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 14:56:54,518] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:20:00+00:00: scheduled__2019-10-16T09:20:00+00:00, externally triggered: False>
[2019-10-16 14:56:54,549] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 14:56:54,554] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.move_target_to_source 2019-10-16 09:20:00+00:00 [scheduled]> in ORM
[2019-10-16 14:56:54,644] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.212 seconds
[2019-10-16 14:57:04,527] {logging_mixin.py:95} INFO - [2019-10-16 14:57:04,527] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=13168
[2019-10-16 14:57:04,530] {scheduler_job.py:146} INFO - Started process (PID=13168) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:57:04,532] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:57:04,533] {logging_mixin.py:95} INFO - [2019-10-16 14:57:04,532] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:57:04,541] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:57:04,571] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 14:57:04,584] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:20:00+00:00: scheduled__2019-10-16T09:20:00+00:00, externally triggered: False>
[2019-10-16 14:57:04,623] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 14:57:04,627] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.unzip_source 2019-10-16 09:20:00+00:00 [scheduled]> in ORM
[2019-10-16 14:57:04,643] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.113 seconds
[2019-10-16 14:57:14,626] {logging_mixin.py:95} INFO - [2019-10-16 14:57:14,626] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=13231
[2019-10-16 14:57:14,629] {scheduler_job.py:146} INFO - Started process (PID=13231) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:57:14,631] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:57:14,631] {logging_mixin.py:95} INFO - [2019-10-16 14:57:14,631] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:57:14,640] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:57:14,670] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 14:57:14,683] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:20:00+00:00: scheduled__2019-10-16T09:20:00+00:00, externally triggered: False>
[2019-10-16 14:57:14,707] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 14:57:14,712] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.print_first_ten_lines 2019-10-16 09:20:00+00:00 [scheduled]> in ORM
[2019-10-16 14:57:14,728] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.099 seconds
[2019-10-16 14:57:24,723] {logging_mixin.py:95} INFO - [2019-10-16 14:57:24,723] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=13299
[2019-10-16 14:57:24,725] {scheduler_job.py:146} INFO - Started process (PID=13299) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:57:24,727] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:57:24,728] {logging_mixin.py:95} INFO - [2019-10-16 14:57:24,728] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:57:24,740] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:57:24,770] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 14:57:24,784] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:20:00+00:00: scheduled__2019-10-16T09:20:00+00:00, externally triggered: False>
[2019-10-16 14:57:24,808] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 14:57:24,815] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.089 seconds
[2019-10-16 14:57:34,825] {logging_mixin.py:95} INFO - [2019-10-16 14:57:34,825] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=13326
[2019-10-16 14:57:34,828] {scheduler_job.py:146} INFO - Started process (PID=13326) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:57:34,830] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:57:34,830] {logging_mixin.py:95} INFO - [2019-10-16 14:57:34,830] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:57:34,839] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:57:34,879] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 14:57:34,895] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:20:00+00:00: scheduled__2019-10-16T09:20:00+00:00, externally triggered: False>
[2019-10-16 14:57:34,920] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 14:57:34,926] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.098 seconds
[2019-10-16 14:57:44,932] {logging_mixin.py:95} INFO - [2019-10-16 14:57:44,931] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=13347
[2019-10-16 14:57:44,934] {scheduler_job.py:146} INFO - Started process (PID=13347) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:57:44,936] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:57:44,937] {logging_mixin.py:95} INFO - [2019-10-16 14:57:44,937] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:57:44,945] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:57:44,974] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 14:57:44,987] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:20:00+00:00: scheduled__2019-10-16T09:20:00+00:00, externally triggered: False>
[2019-10-16 14:57:45,011] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 14:57:45,017] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.083 seconds
[2019-10-16 14:57:55,034] {logging_mixin.py:95} INFO - [2019-10-16 14:57:55,034] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=13372
[2019-10-16 14:57:55,038] {scheduler_job.py:146} INFO - Started process (PID=13372) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:57:55,041] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:57:55,041] {logging_mixin.py:95} INFO - [2019-10-16 14:57:55,041] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:57:55,052] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:57:55,089] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 14:57:55,103] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:20:00+00:00: scheduled__2019-10-16T09:20:00+00:00, externally triggered: False>
[2019-10-16 14:57:55,130] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 14:57:55,137] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.099 seconds
[2019-10-16 14:58:05,159] {logging_mixin.py:95} INFO - [2019-10-16 14:58:05,159] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=13400
[2019-10-16 14:58:05,166] {scheduler_job.py:146} INFO - Started process (PID=13400) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:58:05,172] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:58:05,173] {logging_mixin.py:95} INFO - [2019-10-16 14:58:05,173] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:58:05,196] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:58:05,246] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 14:58:05,262] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:20:00+00:00: scheduled__2019-10-16T09:20:00+00:00, externally triggered: False>
[2019-10-16 14:58:05,297] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 14:58:05,305] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.139 seconds
[2019-10-16 14:58:15,335] {logging_mixin.py:95} INFO - [2019-10-16 14:58:15,335] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=13437
[2019-10-16 14:58:15,340] {scheduler_job.py:146} INFO - Started process (PID=13437) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:58:15,344] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:58:15,345] {logging_mixin.py:95} INFO - [2019-10-16 14:58:15,344] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:58:15,357] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:58:15,396] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 14:58:15,410] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:20:00+00:00: scheduled__2019-10-16T09:20:00+00:00, externally triggered: False>
[2019-10-16 14:58:15,440] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 14:58:15,448] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.108 seconds
[2019-10-16 14:58:25,470] {logging_mixin.py:95} INFO - [2019-10-16 14:58:25,470] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=13463
[2019-10-16 14:58:25,473] {scheduler_job.py:146} INFO - Started process (PID=13463) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:58:25,475] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:58:25,475] {logging_mixin.py:95} INFO - [2019-10-16 14:58:25,475] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:58:25,486] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:58:25,514] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 14:58:25,528] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:20:00+00:00: scheduled__2019-10-16T09:20:00+00:00, externally triggered: False>
[2019-10-16 14:58:25,556] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 14:58:25,562] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.090 seconds
[2019-10-16 14:58:35,615] {logging_mixin.py:95} INFO - [2019-10-16 14:58:35,615] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=13483
[2019-10-16 14:58:35,618] {scheduler_job.py:146} INFO - Started process (PID=13483) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:58:35,620] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:58:35,620] {logging_mixin.py:95} INFO - [2019-10-16 14:58:35,620] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:58:35,629] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:58:35,654] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 14:58:35,668] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:20:00+00:00: scheduled__2019-10-16T09:20:00+00:00, externally triggered: False>
[2019-10-16 14:58:35,692] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 14:58:35,698] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.080 seconds
[2019-10-16 14:59:40,154] {logging_mixin.py:95} INFO - [2019-10-16 14:59:40,154] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=13569
[2019-10-16 14:59:40,156] {scheduler_job.py:146} INFO - Started process (PID=13569) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:59:40,159] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:59:40,159] {logging_mixin.py:95} INFO - [2019-10-16 14:59:40,159] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:59:40,167] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:59:40,196] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.040 seconds
[2019-10-16 14:59:51,281] {logging_mixin.py:95} INFO - [2019-10-16 14:59:51,280] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=13713
[2019-10-16 14:59:51,286] {scheduler_job.py:146} INFO - Started process (PID=13713) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:59:51,291] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 14:59:51,292] {logging_mixin.py:95} INFO - [2019-10-16 14:59:51,292] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:59:51,306] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 14:59:51,334] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.048 seconds
[2019-10-16 15:00:01,407] {logging_mixin.py:95} INFO - [2019-10-16 15:00:01,407] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=13743
[2019-10-16 15:00:01,410] {scheduler_job.py:146} INFO - Started process (PID=13743) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:00:01,416] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 15:00:01,417] {logging_mixin.py:95} INFO - [2019-10-16 15:00:01,417] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:00:01,432] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:00:01,493] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 15:00:01,548] {scheduler_job.py:1265} INFO - Created <DagRun file_operations_pipeline @ 2019-10-16T09:25:00+00:00: scheduled__2019-10-16T09:25:00+00:00, externally triggered: False>
[2019-10-16 15:00:01,555] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:25:00+00:00: scheduled__2019-10-16T09:25:00+00:00, externally triggered: False>
[2019-10-16 15:00:01,644] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 15:00:01,655] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.sleep 2019-10-16 09:25:00+00:00 [scheduled]> in ORM
[2019-10-16 15:00:01,664] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.zip_target 2019-10-16 09:25:00+00:00 [scheduled]> in ORM
[2019-10-16 15:00:01,689] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.279 seconds
[2019-10-16 15:00:11,525] {logging_mixin.py:95} INFO - [2019-10-16 15:00:11,525] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=13841
[2019-10-16 15:00:11,528] {scheduler_job.py:146} INFO - Started process (PID=13841) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:00:11,530] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 15:00:11,531] {logging_mixin.py:95} INFO - [2019-10-16 15:00:11,531] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:00:11,540] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:00:11,575] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 15:00:11,593] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:25:00+00:00: scheduled__2019-10-16T09:25:00+00:00, externally triggered: False>
[2019-10-16 15:00:11,633] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 15:00:11,639] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.move_target_to_source 2019-10-16 09:25:00+00:00 [scheduled]> in ORM
[2019-10-16 15:00:11,656] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.128 seconds
[2019-10-16 15:00:21,628] {logging_mixin.py:95} INFO - [2019-10-16 15:00:21,628] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=13907
[2019-10-16 15:00:21,631] {scheduler_job.py:146} INFO - Started process (PID=13907) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:00:21,633] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 15:00:21,633] {logging_mixin.py:95} INFO - [2019-10-16 15:00:21,633] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:00:21,642] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:00:21,686] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 15:00:21,701] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:25:00+00:00: scheduled__2019-10-16T09:25:00+00:00, externally triggered: False>
[2019-10-16 15:00:21,740] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 15:00:21,744] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.unzip_source 2019-10-16 09:25:00+00:00 [scheduled]> in ORM
[2019-10-16 15:00:21,756] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.125 seconds
[2019-10-16 15:00:31,730] {logging_mixin.py:95} INFO - [2019-10-16 15:00:31,730] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=13971
[2019-10-16 15:00:31,733] {scheduler_job.py:146} INFO - Started process (PID=13971) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:00:31,735] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 15:00:31,735] {logging_mixin.py:95} INFO - [2019-10-16 15:00:31,735] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:00:31,744] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:00:31,776] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 15:00:31,790] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:25:00+00:00: scheduled__2019-10-16T09:25:00+00:00, externally triggered: False>
[2019-10-16 15:00:31,813] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 15:00:31,818] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.print_first_ten_lines 2019-10-16 09:25:00+00:00 [scheduled]> in ORM
[2019-10-16 15:00:31,831] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.098 seconds
[2019-10-16 15:00:41,831] {logging_mixin.py:95} INFO - [2019-10-16 15:00:41,831] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=14036
[2019-10-16 15:00:41,834] {scheduler_job.py:146} INFO - Started process (PID=14036) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:00:41,836] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 15:00:41,836] {logging_mixin.py:95} INFO - [2019-10-16 15:00:41,836] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:00:41,845] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:00:41,878] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 15:00:41,892] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:25:00+00:00: scheduled__2019-10-16T09:25:00+00:00, externally triggered: False>
[2019-10-16 15:00:41,916] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 15:00:41,923] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.089 seconds
[2019-10-16 15:00:51,928] {logging_mixin.py:95} INFO - [2019-10-16 15:00:51,928] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=14059
[2019-10-16 15:00:51,931] {scheduler_job.py:146} INFO - Started process (PID=14059) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:00:51,934] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 15:00:51,934] {logging_mixin.py:95} INFO - [2019-10-16 15:00:51,934] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:00:51,942] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:00:51,976] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 15:00:51,990] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:25:00+00:00: scheduled__2019-10-16T09:25:00+00:00, externally triggered: False>
[2019-10-16 15:00:52,014] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 15:00:52,020] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.089 seconds
[2019-10-16 15:01:02,026] {logging_mixin.py:95} INFO - [2019-10-16 15:01:02,026] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=14084
[2019-10-16 15:01:02,029] {scheduler_job.py:146} INFO - Started process (PID=14084) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:01:02,031] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 15:01:02,031] {logging_mixin.py:95} INFO - [2019-10-16 15:01:02,031] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:01:02,040] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:01:02,071] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 15:01:02,084] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:25:00+00:00: scheduled__2019-10-16T09:25:00+00:00, externally triggered: False>
[2019-10-16 15:01:02,109] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 15:01:02,115] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.087 seconds
[2019-10-16 15:01:12,121] {logging_mixin.py:95} INFO - [2019-10-16 15:01:12,121] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=14111
[2019-10-16 15:01:12,124] {scheduler_job.py:146} INFO - Started process (PID=14111) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:01:12,126] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 15:01:12,126] {logging_mixin.py:95} INFO - [2019-10-16 15:01:12,126] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:01:12,134] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:01:12,168] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 15:01:12,182] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:25:00+00:00: scheduled__2019-10-16T09:25:00+00:00, externally triggered: False>
[2019-10-16 15:01:12,207] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 15:01:12,214] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.090 seconds
[2019-10-16 15:01:22,216] {logging_mixin.py:95} INFO - [2019-10-16 15:01:22,216] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=14131
[2019-10-16 15:01:22,219] {scheduler_job.py:146} INFO - Started process (PID=14131) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:01:22,221] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 15:01:22,222] {logging_mixin.py:95} INFO - [2019-10-16 15:01:22,222] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:01:22,230] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:01:22,256] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 15:01:22,270] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:25:00+00:00: scheduled__2019-10-16T09:25:00+00:00, externally triggered: False>
[2019-10-16 15:01:22,294] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 15:01:22,300] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.081 seconds
[2019-10-16 15:01:32,314] {logging_mixin.py:95} INFO - [2019-10-16 15:01:32,314] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=14154
[2019-10-16 15:01:32,317] {scheduler_job.py:146} INFO - Started process (PID=14154) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:01:32,319] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 15:01:32,319] {logging_mixin.py:95} INFO - [2019-10-16 15:01:32,319] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:01:32,328] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:01:32,360] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 15:01:32,374] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:25:00+00:00: scheduled__2019-10-16T09:25:00+00:00, externally triggered: False>
[2019-10-16 15:01:32,399] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 15:01:32,405] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.089 seconds
[2019-10-16 15:01:42,426] {logging_mixin.py:95} INFO - [2019-10-16 15:01:42,426] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=14181
[2019-10-16 15:01:42,429] {scheduler_job.py:146} INFO - Started process (PID=14181) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:01:42,431] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 15:01:42,431] {logging_mixin.py:95} INFO - [2019-10-16 15:01:42,431] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:01:42,439] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:01:42,472] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 15:01:42,487] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:25:00+00:00: scheduled__2019-10-16T09:25:00+00:00, externally triggered: False>
[2019-10-16 15:01:42,510] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 15:01:42,517] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.088 seconds
[2019-10-16 15:01:52,528] {logging_mixin.py:95} INFO - [2019-10-16 15:01:52,528] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=14203
[2019-10-16 15:01:52,531] {scheduler_job.py:146} INFO - Started process (PID=14203) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:01:52,534] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 15:01:52,534] {logging_mixin.py:95} INFO - [2019-10-16 15:01:52,534] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:01:52,542] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:01:52,579] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 15:01:52,593] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:25:00+00:00: scheduled__2019-10-16T09:25:00+00:00, externally triggered: False>
[2019-10-16 15:01:52,618] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 15:01:52,624] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.093 seconds
[2019-10-16 15:02:02,660] {logging_mixin.py:95} INFO - [2019-10-16 15:02:02,660] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=14237
[2019-10-16 15:02:02,668] {scheduler_job.py:146} INFO - Started process (PID=14237) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:02:02,674] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 15:02:02,674] {logging_mixin.py:95} INFO - [2019-10-16 15:02:02,674] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:02:02,687] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:02:02,724] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 15:02:02,740] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:25:00+00:00: scheduled__2019-10-16T09:25:00+00:00, externally triggered: False>
[2019-10-16 15:02:02,766] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 15:02:02,773] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.106 seconds
[2019-10-16 15:02:12,782] {logging_mixin.py:95} INFO - [2019-10-16 15:02:12,782] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=14262
[2019-10-16 15:02:12,785] {scheduler_job.py:146} INFO - Started process (PID=14262) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:02:12,787] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 15:02:12,787] {logging_mixin.py:95} INFO - [2019-10-16 15:02:12,787] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:02:12,796] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:02:12,832] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 15:02:12,847] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:25:00+00:00: scheduled__2019-10-16T09:25:00+00:00, externally triggered: False>
[2019-10-16 15:02:12,871] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 15:02:12,878] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.093 seconds
[2019-10-16 15:02:22,940] {logging_mixin.py:95} INFO - [2019-10-16 15:02:22,940] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=14282
[2019-10-16 15:02:22,948] {scheduler_job.py:146} INFO - Started process (PID=14282) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:02:22,952] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 15:02:22,953] {logging_mixin.py:95} INFO - [2019-10-16 15:02:22,952] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:02:22,964] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:02:22,998] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 15:02:23,013] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:25:00+00:00: scheduled__2019-10-16T09:25:00+00:00, externally triggered: False>
[2019-10-16 15:02:23,039] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 15:02:23,047] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.098 seconds
[2019-10-16 15:02:33,045] {logging_mixin.py:95} INFO - [2019-10-16 15:02:33,045] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=14312
[2019-10-16 15:02:33,049] {scheduler_job.py:146} INFO - Started process (PID=14312) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:02:33,051] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 15:02:33,052] {logging_mixin.py:95} INFO - [2019-10-16 15:02:33,052] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:02:33,060] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:02:33,091] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 15:02:33,104] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:25:00+00:00: scheduled__2019-10-16T09:25:00+00:00, externally triggered: False>
[2019-10-16 15:02:33,128] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 15:02:33,134] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.086 seconds
[2019-10-16 15:02:43,149] {logging_mixin.py:95} INFO - [2019-10-16 15:02:43,149] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=14341
[2019-10-16 15:02:43,152] {scheduler_job.py:146} INFO - Started process (PID=14341) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:02:43,154] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 15:02:43,154] {logging_mixin.py:95} INFO - [2019-10-16 15:02:43,154] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:02:43,162] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:02:43,262] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 15:02:43,283] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:25:00+00:00: scheduled__2019-10-16T09:25:00+00:00, externally triggered: False>
[2019-10-16 15:02:43,308] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 15:02:43,312] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.print_first_ten_lines 2019-10-16 09:25:00+00:00 [scheduled]> in ORM
[2019-10-16 15:02:43,352] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.200 seconds
[2019-10-16 15:02:53,245] {logging_mixin.py:95} INFO - [2019-10-16 15:02:53,245] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=14399
[2019-10-16 15:02:53,248] {scheduler_job.py:146} INFO - Started process (PID=14399) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:02:53,250] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 15:02:53,250] {logging_mixin.py:95} INFO - [2019-10-16 15:02:53,250] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:02:53,258] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:02:53,286] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 15:02:53,299] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:25:00+00:00: scheduled__2019-10-16T09:25:00+00:00, externally triggered: False>
[2019-10-16 15:02:53,323] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 15:02:53,329] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.081 seconds
[2019-10-16 15:03:03,340] {logging_mixin.py:95} INFO - [2019-10-16 15:03:03,340] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=14426
[2019-10-16 15:03:03,343] {scheduler_job.py:146} INFO - Started process (PID=14426) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:03:03,345] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 15:03:03,346] {logging_mixin.py:95} INFO - [2019-10-16 15:03:03,346] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:03:03,356] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:03:03,384] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 15:03:03,397] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:25:00+00:00: scheduled__2019-10-16T09:25:00+00:00, externally triggered: False>
[2019-10-16 15:03:03,421] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 15:03:03,427] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.084 seconds
[2019-10-16 15:03:13,439] {logging_mixin.py:95} INFO - [2019-10-16 15:03:13,438] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=14449
[2019-10-16 15:03:13,441] {scheduler_job.py:146} INFO - Started process (PID=14449) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:03:13,443] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 15:03:13,444] {logging_mixin.py:95} INFO - [2019-10-16 15:03:13,444] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:03:13,452] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:03:13,485] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 15:03:13,499] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:25:00+00:00: scheduled__2019-10-16T09:25:00+00:00, externally triggered: False>
[2019-10-16 15:03:13,522] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 15:03:13,529] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.088 seconds
[2019-10-16 15:03:23,536] {logging_mixin.py:95} INFO - [2019-10-16 15:03:23,535] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=14474
[2019-10-16 15:03:23,539] {scheduler_job.py:146} INFO - Started process (PID=14474) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:03:23,541] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 15:03:23,541] {logging_mixin.py:95} INFO - [2019-10-16 15:03:23,541] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:03:23,549] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:03:23,582] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 15:03:23,595] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:25:00+00:00: scheduled__2019-10-16T09:25:00+00:00, externally triggered: False>
[2019-10-16 15:03:23,620] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 15:03:23,626] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.088 seconds
[2019-10-16 15:03:33,637] {logging_mixin.py:95} INFO - [2019-10-16 15:03:33,637] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=14497
[2019-10-16 15:03:33,640] {scheduler_job.py:146} INFO - Started process (PID=14497) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:03:33,642] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 15:03:33,642] {logging_mixin.py:95} INFO - [2019-10-16 15:03:33,642] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:03:33,650] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:03:33,681] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 15:03:33,695] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:25:00+00:00: scheduled__2019-10-16T09:25:00+00:00, externally triggered: False>
[2019-10-16 15:03:33,720] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 15:03:33,727] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.087 seconds
[2019-10-16 15:03:43,744] {logging_mixin.py:95} INFO - [2019-10-16 15:03:43,744] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=14518
[2019-10-16 15:03:43,747] {scheduler_job.py:146} INFO - Started process (PID=14518) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:03:43,749] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 15:03:43,749] {logging_mixin.py:95} INFO - [2019-10-16 15:03:43,749] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:03:43,757] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:03:43,789] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 15:03:43,802] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:25:00+00:00: scheduled__2019-10-16T09:25:00+00:00, externally triggered: False>
[2019-10-16 15:03:43,826] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 15:03:43,832] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.086 seconds
[2019-10-16 15:03:53,847] {logging_mixin.py:95} INFO - [2019-10-16 15:03:53,847] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=14543
[2019-10-16 15:03:53,849] {scheduler_job.py:146} INFO - Started process (PID=14543) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:03:53,852] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 15:03:53,852] {logging_mixin.py:95} INFO - [2019-10-16 15:03:53,852] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:03:53,860] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:03:53,891] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 15:03:53,905] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:25:00+00:00: scheduled__2019-10-16T09:25:00+00:00, externally triggered: False>
[2019-10-16 15:03:53,930] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 15:03:53,936] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.087 seconds
[2019-10-16 15:04:03,969] {logging_mixin.py:95} INFO - [2019-10-16 15:04:03,968] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=14563
[2019-10-16 15:04:03,976] {scheduler_job.py:146} INFO - Started process (PID=14563) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:04:03,982] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 15:04:03,982] {logging_mixin.py:95} INFO - [2019-10-16 15:04:03,982] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:04:03,995] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:04:04,034] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 15:04:04,056] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:25:00+00:00: scheduled__2019-10-16T09:25:00+00:00, externally triggered: False>
[2019-10-16 15:04:04,106] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 15:04:04,114] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.138 seconds
[2019-10-16 15:04:14,093] {logging_mixin.py:95} INFO - [2019-10-16 15:04:14,092] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=14593
[2019-10-16 15:04:14,100] {scheduler_job.py:146} INFO - Started process (PID=14593) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:04:14,106] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 15:04:14,107] {logging_mixin.py:95} INFO - [2019-10-16 15:04:14,107] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:04:14,131] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:04:14,204] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 15:04:14,239] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:25:00+00:00: scheduled__2019-10-16T09:25:00+00:00, externally triggered: False>
[2019-10-16 15:04:14,287] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 15:04:14,297] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.197 seconds
[2019-10-16 15:04:24,225] {logging_mixin.py:95} INFO - [2019-10-16 15:04:24,224] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=14625
[2019-10-16 15:04:24,232] {scheduler_job.py:146} INFO - Started process (PID=14625) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:04:24,237] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 15:04:24,238] {logging_mixin.py:95} INFO - [2019-10-16 15:04:24,238] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:04:24,251] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:04:24,280] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 15:04:24,298] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:25:00+00:00: scheduled__2019-10-16T09:25:00+00:00, externally triggered: False>
[2019-10-16 15:04:24,332] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 15:04:24,338] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.106 seconds
[2019-10-16 15:04:34,344] {logging_mixin.py:95} INFO - [2019-10-16 15:04:34,343] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=14649
[2019-10-16 15:04:34,350] {scheduler_job.py:146} INFO - Started process (PID=14649) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:04:34,355] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 15:04:34,356] {logging_mixin.py:95} INFO - [2019-10-16 15:04:34,355] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:04:34,370] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:04:34,407] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 15:04:34,429] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:25:00+00:00: scheduled__2019-10-16T09:25:00+00:00, externally triggered: False>
[2019-10-16 15:04:34,461] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 15:04:34,468] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.118 seconds
[2019-10-16 15:04:44,510] {logging_mixin.py:95} INFO - [2019-10-16 15:04:44,509] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=14671
[2019-10-16 15:04:44,519] {scheduler_job.py:146} INFO - Started process (PID=14671) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:04:44,531] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 15:04:44,532] {logging_mixin.py:95} INFO - [2019-10-16 15:04:44,532] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:04:44,553] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:04:44,606] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 15:04:44,633] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:25:00+00:00: scheduled__2019-10-16T09:25:00+00:00, externally triggered: False>
[2019-10-16 15:04:44,677] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 15:04:44,684] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.165 seconds
[2019-10-16 15:04:54,620] {logging_mixin.py:95} INFO - [2019-10-16 15:04:54,619] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=14695
[2019-10-16 15:04:54,623] {scheduler_job.py:146} INFO - Started process (PID=14695) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:04:54,625] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 15:04:54,626] {logging_mixin.py:95} INFO - [2019-10-16 15:04:54,626] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:04:54,634] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:04:54,665] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 15:04:54,678] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:25:00+00:00: scheduled__2019-10-16T09:25:00+00:00, externally triggered: False>
[2019-10-16 15:04:54,703] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 15:04:54,706] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.print_first_ten_lines 2019-10-16 09:25:00+00:00 [scheduled]> in ORM
[2019-10-16 15:04:54,719] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.096 seconds
[2019-10-16 15:05:04,731] {logging_mixin.py:95} INFO - [2019-10-16 15:05:04,730] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=14759
[2019-10-16 15:05:04,738] {scheduler_job.py:146} INFO - Started process (PID=14759) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:05:04,744] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 15:05:04,745] {logging_mixin.py:95} INFO - [2019-10-16 15:05:04,744] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:05:04,756] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:05:04,787] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 15:05:04,817] {scheduler_job.py:1265} INFO - Created <DagRun file_operations_pipeline @ 2019-10-16T09:30:00+00:00: scheduled__2019-10-16T09:30:00+00:00, externally triggered: False>
[2019-10-16 15:05:04,821] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:25:00+00:00: scheduled__2019-10-16T09:25:00+00:00, externally triggered: False>
[2019-10-16 15:05:04,832] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:30:00+00:00: scheduled__2019-10-16T09:30:00+00:00, externally triggered: False>
[2019-10-16 15:05:04,885] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 15:05:04,890] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.sleep 2019-10-16 09:30:00+00:00 [scheduled]> in ORM
[2019-10-16 15:05:04,894] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.zip_target 2019-10-16 09:30:00+00:00 [scheduled]> in ORM
[2019-10-16 15:05:04,905] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.167 seconds
[2019-10-16 15:05:14,848] {logging_mixin.py:95} INFO - [2019-10-16 15:05:14,847] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=14854
[2019-10-16 15:05:14,855] {scheduler_job.py:146} INFO - Started process (PID=14854) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:05:14,860] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 15:05:14,861] {logging_mixin.py:95} INFO - [2019-10-16 15:05:14,861] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:05:14,872] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:05:14,900] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 15:05:14,913] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:25:00+00:00: scheduled__2019-10-16T09:25:00+00:00, externally triggered: False>
[2019-10-16 15:05:14,927] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:30:00+00:00: scheduled__2019-10-16T09:30:00+00:00, externally triggered: False>
[2019-10-16 15:05:14,966] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 15:05:14,970] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.move_target_to_source 2019-10-16 09:30:00+00:00 [scheduled]> in ORM
[2019-10-16 15:05:14,981] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.126 seconds
[2019-10-16 15:05:24,965] {logging_mixin.py:95} INFO - [2019-10-16 15:05:24,965] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=14937
[2019-10-16 15:05:24,972] {scheduler_job.py:146} INFO - Started process (PID=14937) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:05:24,981] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 15:05:24,982] {logging_mixin.py:95} INFO - [2019-10-16 15:05:24,981] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:05:25,009] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:05:25,074] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 15:05:25,092] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:25:00+00:00: scheduled__2019-10-16T09:25:00+00:00, externally triggered: False>
[2019-10-16 15:05:25,111] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:30:00+00:00: scheduled__2019-10-16T09:30:00+00:00, externally triggered: False>
[2019-10-16 15:05:25,172] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 15:05:25,177] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.unzip_source 2019-10-16 09:30:00+00:00 [scheduled]> in ORM
[2019-10-16 15:05:25,195] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.223 seconds
[2019-10-16 15:05:35,085] {logging_mixin.py:95} INFO - [2019-10-16 15:05:35,084] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=14998
[2019-10-16 15:05:35,087] {scheduler_job.py:146} INFO - Started process (PID=14998) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:05:35,090] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 15:05:35,090] {logging_mixin.py:95} INFO - [2019-10-16 15:05:35,090] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:05:35,098] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:05:35,128] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 15:05:35,142] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:25:00+00:00: scheduled__2019-10-16T09:25:00+00:00, externally triggered: False>
[2019-10-16 15:05:35,156] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:30:00+00:00: scheduled__2019-10-16T09:30:00+00:00, externally triggered: False>
[2019-10-16 15:05:35,188] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 15:05:35,192] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.print_first_ten_lines 2019-10-16 09:30:00+00:00 [scheduled]> in ORM
[2019-10-16 15:05:35,203] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.116 seconds
[2019-10-16 15:05:45,207] {logging_mixin.py:95} INFO - [2019-10-16 15:05:45,206] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=15060
[2019-10-16 15:05:45,214] {scheduler_job.py:146} INFO - Started process (PID=15060) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:05:45,219] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 15:05:45,219] {logging_mixin.py:95} INFO - [2019-10-16 15:05:45,219] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:05:45,229] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:05:45,263] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 15:05:45,277] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:25:00+00:00: scheduled__2019-10-16T09:25:00+00:00, externally triggered: False>
[2019-10-16 15:05:45,293] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:30:00+00:00: scheduled__2019-10-16T09:30:00+00:00, externally triggered: False>
[2019-10-16 15:05:45,327] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 15:05:45,333] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.119 seconds
[2019-10-16 15:05:55,307] {logging_mixin.py:95} INFO - [2019-10-16 15:05:55,307] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=15092
[2019-10-16 15:05:55,310] {scheduler_job.py:146} INFO - Started process (PID=15092) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:05:55,313] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 15:05:55,313] {logging_mixin.py:95} INFO - [2019-10-16 15:05:55,313] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:05:55,322] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:05:55,351] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 15:05:55,365] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:25:00+00:00: scheduled__2019-10-16T09:25:00+00:00, externally triggered: False>
[2019-10-16 15:05:55,379] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:30:00+00:00: scheduled__2019-10-16T09:30:00+00:00, externally triggered: False>
[2019-10-16 15:05:55,413] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 15:05:55,419] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.109 seconds
[2019-10-16 15:07:18,118] {logging_mixin.py:95} INFO - [2019-10-16 15:07:18,117] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=15151
[2019-10-16 15:07:18,121] {scheduler_job.py:146} INFO - Started process (PID=15151) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:07:18,124] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 15:07:18,124] {logging_mixin.py:95} INFO - [2019-10-16 15:07:18,124] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:07:18,137] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:07:18,172] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.051 seconds
[2019-10-16 15:07:29,243] {logging_mixin.py:95} INFO - [2019-10-16 15:07:29,242] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=15236
[2019-10-16 15:07:29,251] {scheduler_job.py:146} INFO - Started process (PID=15236) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:07:29,258] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 15:07:29,259] {logging_mixin.py:95} INFO - [2019-10-16 15:07:29,259] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:07:29,283] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:07:29,365] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 15:07:29,408] {scheduler_job.py:1265} INFO - Created <DagRun file_operations_pipeline @ 2019-10-16T09:30:00+00:00: scheduled__2019-10-16T09:30:00+00:00, externally triggered: False>
[2019-10-16 15:07:29,412] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:30:00+00:00: scheduled__2019-10-16T09:30:00+00:00, externally triggered: False>
[2019-10-16 15:07:29,472] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 15:07:29,479] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.sleep 2019-10-16 09:30:00+00:00 [scheduled]> in ORM
[2019-10-16 15:07:29,485] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.zip_target 2019-10-16 09:30:00+00:00 [scheduled]> in ORM
[2019-10-16 15:07:29,500] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.249 seconds
[2019-10-16 15:07:39,357] {logging_mixin.py:95} INFO - [2019-10-16 15:07:39,357] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=15319
[2019-10-16 15:07:39,359] {scheduler_job.py:146} INFO - Started process (PID=15319) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:07:39,362] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 15:07:39,362] {logging_mixin.py:95} INFO - [2019-10-16 15:07:39,362] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:07:39,370] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:07:39,415] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 15:07:39,429] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:30:00+00:00: scheduled__2019-10-16T09:30:00+00:00, externally triggered: False>
[2019-10-16 15:07:39,459] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 15:07:39,463] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.move_target_to_source 2019-10-16 09:30:00+00:00 [scheduled]> in ORM
[2019-10-16 15:07:39,488] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.129 seconds
[2019-10-16 15:07:49,467] {logging_mixin.py:95} INFO - [2019-10-16 15:07:49,467] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=15393
[2019-10-16 15:07:49,470] {scheduler_job.py:146} INFO - Started process (PID=15393) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:07:49,472] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 15:07:49,472] {logging_mixin.py:95} INFO - [2019-10-16 15:07:49,472] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:07:49,487] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:07:49,521] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 15:07:49,538] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:30:00+00:00: scheduled__2019-10-16T09:30:00+00:00, externally triggered: False>
[2019-10-16 15:07:49,587] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 15:07:49,592] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.unzip_source 2019-10-16 09:30:00+00:00 [scheduled]> in ORM
[2019-10-16 15:07:49,609] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.139 seconds
[2019-10-16 15:07:59,573] {logging_mixin.py:95} INFO - [2019-10-16 15:07:59,573] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=15469
[2019-10-16 15:07:59,577] {scheduler_job.py:146} INFO - Started process (PID=15469) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:07:59,581] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 15:07:59,582] {logging_mixin.py:95} INFO - [2019-10-16 15:07:59,582] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:07:59,599] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:07:59,646] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 15:07:59,665] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:30:00+00:00: scheduled__2019-10-16T09:30:00+00:00, externally triggered: False>
[2019-10-16 15:07:59,696] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 15:07:59,701] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.print_first_ten_lines 2019-10-16 09:30:00+00:00 [scheduled]> in ORM
[2019-10-16 15:07:59,718] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.141 seconds
[2019-10-16 15:08:09,693] {logging_mixin.py:95} INFO - [2019-10-16 15:08:09,693] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=15531
[2019-10-16 15:08:09,697] {scheduler_job.py:146} INFO - Started process (PID=15531) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:08:09,699] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 15:08:09,700] {logging_mixin.py:95} INFO - [2019-10-16 15:08:09,700] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:08:09,709] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:08:09,742] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 15:08:09,759] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:30:00+00:00: scheduled__2019-10-16T09:30:00+00:00, externally triggered: False>
[2019-10-16 15:08:09,792] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 15:08:09,799] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.print_last_ten_lines 2019-10-16 09:30:00+00:00 [scheduled]> in ORM
[2019-10-16 15:08:09,820] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.123 seconds
[2019-10-16 15:08:19,802] {logging_mixin.py:95} INFO - [2019-10-16 15:08:19,802] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=15596
[2019-10-16 15:08:19,805] {scheduler_job.py:146} INFO - Started process (PID=15596) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:08:19,807] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 15:08:19,808] {logging_mixin.py:95} INFO - [2019-10-16 15:08:19,808] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:08:19,816] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:08:19,847] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 15:08:19,861] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:30:00+00:00: scheduled__2019-10-16T09:30:00+00:00, externally triggered: False>
[2019-10-16 15:08:19,870] {logging_mixin.py:95} INFO - [2019-10-16 15:08:19,870] {dagrun.py:316} INFO - Marking run <DagRun file_operations_pipeline @ 2019-10-16 09:30:00+00:00: scheduled__2019-10-16T09:30:00+00:00, externally triggered: False> successful
[2019-10-16 15:08:19,875] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 15:08:19,882] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.076 seconds
[2019-10-16 15:08:29,900] {logging_mixin.py:95} INFO - [2019-10-16 15:08:29,900] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=15628
[2019-10-16 15:08:29,903] {scheduler_job.py:146} INFO - Started process (PID=15628) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:08:29,905] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 15:08:29,905] {logging_mixin.py:95} INFO - [2019-10-16 15:08:29,905] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:08:29,913] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:08:29,946] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 15:08:29,962] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 15:08:29,970] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.068 seconds
[2019-10-16 15:08:39,998] {logging_mixin.py:95} INFO - [2019-10-16 15:08:39,998] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=15648
[2019-10-16 15:08:40,001] {scheduler_job.py:146} INFO - Started process (PID=15648) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:08:40,003] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 15:08:40,003] {logging_mixin.py:95} INFO - [2019-10-16 15:08:40,003] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:08:40,012] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:08:40,047] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 15:08:40,062] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 15:08:40,070] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.069 seconds
[2019-10-16 15:08:50,098] {logging_mixin.py:95} INFO - [2019-10-16 15:08:50,098] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=15669
[2019-10-16 15:08:50,100] {scheduler_job.py:146} INFO - Started process (PID=15669) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:08:50,103] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 15:08:50,103] {logging_mixin.py:95} INFO - [2019-10-16 15:08:50,103] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:08:50,111] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:08:50,143] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 15:08:50,158] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 15:08:50,166] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.065 seconds
[2019-10-16 15:09:00,201] {logging_mixin.py:95} INFO - [2019-10-16 15:09:00,201] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=15694
[2019-10-16 15:09:00,204] {scheduler_job.py:146} INFO - Started process (PID=15694) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:09:00,206] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 15:09:00,207] {logging_mixin.py:95} INFO - [2019-10-16 15:09:00,207] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:09:00,215] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:09:00,245] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 15:09:00,259] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 15:09:00,267] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.063 seconds
[2019-10-16 15:09:10,320] {logging_mixin.py:95} INFO - [2019-10-16 15:09:10,319] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=15721
[2019-10-16 15:09:10,326] {scheduler_job.py:146} INFO - Started process (PID=15721) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:09:10,331] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 15:09:10,332] {logging_mixin.py:95} INFO - [2019-10-16 15:09:10,332] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:09:10,354] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:09:10,415] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 15:09:10,436] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 15:09:10,449] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.123 seconds
[2019-10-16 15:09:20,465] {logging_mixin.py:95} INFO - [2019-10-16 15:09:20,465] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=15752
[2019-10-16 15:09:20,468] {scheduler_job.py:146} INFO - Started process (PID=15752) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:09:20,470] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 15:09:20,471] {logging_mixin.py:95} INFO - [2019-10-16 15:09:20,470] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:09:20,480] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:09:20,512] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 15:09:20,527] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 15:09:20,535] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.067 seconds
[2019-10-16 15:09:30,611] {logging_mixin.py:95} INFO - [2019-10-16 15:09:30,610] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=15788
[2019-10-16 15:09:30,621] {scheduler_job.py:146} INFO - Started process (PID=15788) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:09:30,627] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 15:09:30,628] {logging_mixin.py:95} INFO - [2019-10-16 15:09:30,628] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:09:30,654] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:09:30,695] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 15:09:30,715] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 15:09:30,724] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.103 seconds
[2019-10-16 15:09:40,744] {logging_mixin.py:95} INFO - [2019-10-16 15:09:40,743] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=15810
[2019-10-16 15:09:40,746] {scheduler_job.py:146} INFO - Started process (PID=15810) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:09:40,749] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 15:09:40,749] {logging_mixin.py:95} INFO - [2019-10-16 15:09:40,749] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:09:40,757] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:09:40,789] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 15:09:40,803] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 15:09:40,811] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.065 seconds
[2019-10-16 15:09:50,856] {logging_mixin.py:95} INFO - [2019-10-16 15:09:50,856] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=15830
[2019-10-16 15:09:50,862] {scheduler_job.py:146} INFO - Started process (PID=15830) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:09:50,867] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 15:09:50,868] {logging_mixin.py:95} INFO - [2019-10-16 15:09:50,868] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:09:50,885] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:09:50,920] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 15:09:50,936] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 15:09:50,945] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.084 seconds
[2019-10-16 15:10:00,964] {logging_mixin.py:95} INFO - [2019-10-16 15:10:00,964] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=15855
[2019-10-16 15:10:00,968] {scheduler_job.py:146} INFO - Started process (PID=15855) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:10:00,971] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 15:10:00,972] {logging_mixin.py:95} INFO - [2019-10-16 15:10:00,972] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:10:00,993] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:10:01,031] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 15:10:01,064] {scheduler_job.py:1265} INFO - Created <DagRun file_operations_pipeline @ 2019-10-16T09:35:00+00:00: scheduled__2019-10-16T09:35:00+00:00, externally triggered: False>
[2019-10-16 15:10:01,067] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:35:00+00:00: scheduled__2019-10-16T09:35:00+00:00, externally triggered: False>
[2019-10-16 15:10:01,113] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 15:10:01,117] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.sleep 2019-10-16 09:35:00+00:00 [scheduled]> in ORM
[2019-10-16 15:10:01,121] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.zip_target 2019-10-16 09:35:00+00:00 [scheduled]> in ORM
[2019-10-16 15:10:01,132] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.164 seconds
[2019-10-16 15:10:11,062] {logging_mixin.py:95} INFO - [2019-10-16 15:10:11,062] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=15946
[2019-10-16 15:10:11,065] {scheduler_job.py:146} INFO - Started process (PID=15946) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:10:11,067] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 15:10:11,067] {logging_mixin.py:95} INFO - [2019-10-16 15:10:11,067] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:10:11,076] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:10:11,116] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 15:10:11,130] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:35:00+00:00: scheduled__2019-10-16T09:35:00+00:00, externally triggered: False>
[2019-10-16 15:10:11,163] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 15:10:11,167] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.move_target_to_source 2019-10-16 09:35:00+00:00 [scheduled]> in ORM
[2019-10-16 15:10:11,180] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.116 seconds
[2019-10-16 15:10:21,172] {logging_mixin.py:95} INFO - [2019-10-16 15:10:21,171] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=16010
[2019-10-16 15:10:21,178] {scheduler_job.py:146} INFO - Started process (PID=16010) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:10:21,181] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 15:10:21,182] {logging_mixin.py:95} INFO - [2019-10-16 15:10:21,182] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:10:21,190] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:10:21,221] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 15:10:21,235] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:35:00+00:00: scheduled__2019-10-16T09:35:00+00:00, externally triggered: False>
[2019-10-16 15:10:21,273] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 15:10:21,277] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.unzip_source 2019-10-16 09:35:00+00:00 [scheduled]> in ORM
[2019-10-16 15:10:21,288] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.111 seconds
[2019-10-16 15:10:31,279] {logging_mixin.py:95} INFO - [2019-10-16 15:10:31,279] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=16076
[2019-10-16 15:10:31,282] {scheduler_job.py:146} INFO - Started process (PID=16076) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:10:31,284] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 15:10:31,285] {logging_mixin.py:95} INFO - [2019-10-16 15:10:31,285] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:10:31,293] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:10:31,326] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 15:10:31,341] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:35:00+00:00: scheduled__2019-10-16T09:35:00+00:00, externally triggered: False>
[2019-10-16 15:10:31,365] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 15:10:31,369] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.print_first_ten_lines 2019-10-16 09:35:00+00:00 [scheduled]> in ORM
[2019-10-16 15:10:31,384] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.102 seconds
[2019-10-16 15:10:41,378] {logging_mixin.py:95} INFO - [2019-10-16 15:10:41,378] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=16147
[2019-10-16 15:10:41,381] {scheduler_job.py:146} INFO - Started process (PID=16147) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:10:41,383] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 15:10:41,384] {logging_mixin.py:95} INFO - [2019-10-16 15:10:41,384] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:10:41,392] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:10:41,426] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 15:10:41,440] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:35:00+00:00: scheduled__2019-10-16T09:35:00+00:00, externally triggered: False>
[2019-10-16 15:10:41,461] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 15:10:41,465] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: file_operations_pipeline.print_last_ten_lines 2019-10-16 09:35:00+00:00 [scheduled]> in ORM
[2019-10-16 15:10:41,476] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.095 seconds
[2019-10-16 15:10:51,483] {logging_mixin.py:95} INFO - [2019-10-16 15:10:51,483] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=16205
[2019-10-16 15:10:51,486] {scheduler_job.py:146} INFO - Started process (PID=16205) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:10:51,490] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 15:10:51,490] {logging_mixin.py:95} INFO - [2019-10-16 15:10:51,490] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:10:51,504] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:10:51,549] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 15:10:51,567] {scheduler_job.py:729} INFO - Examining DAG run <DagRun file_operations_pipeline @ 2019-10-16 09:35:00+00:00: scheduled__2019-10-16T09:35:00+00:00, externally triggered: False>
[2019-10-16 15:10:51,579] {logging_mixin.py:95} INFO - [2019-10-16 15:10:51,579] {dagrun.py:316} INFO - Marking run <DagRun file_operations_pipeline @ 2019-10-16 09:35:00+00:00: scheduled__2019-10-16T09:35:00+00:00, externally triggered: False> successful
[2019-10-16 15:10:51,584] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 15:10:51,593] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.106 seconds
[2019-10-16 15:11:01,595] {logging_mixin.py:95} INFO - [2019-10-16 15:11:01,595] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=16230
[2019-10-16 15:11:01,598] {scheduler_job.py:146} INFO - Started process (PID=16230) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:11:01,600] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 15:11:01,600] {logging_mixin.py:95} INFO - [2019-10-16 15:11:01,600] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:11:01,608] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:11:01,636] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 15:11:01,651] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 15:11:01,659] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.061 seconds
[2019-10-16 15:11:11,711] {logging_mixin.py:95} INFO - [2019-10-16 15:11:11,711] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=16257
[2019-10-16 15:11:11,714] {scheduler_job.py:146} INFO - Started process (PID=16257) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:11:11,716] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 15:11:11,717] {logging_mixin.py:95} INFO - [2019-10-16 15:11:11,717] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:11:11,725] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:11:11,757] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 15:11:11,771] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 15:11:11,781] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.067 seconds
[2019-10-16 15:11:21,822] {logging_mixin.py:95} INFO - [2019-10-16 15:11:21,822] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=16278
[2019-10-16 15:11:21,825] {scheduler_job.py:146} INFO - Started process (PID=16278) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:11:21,827] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 15:11:21,827] {logging_mixin.py:95} INFO - [2019-10-16 15:11:21,827] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:11:21,836] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:11:21,879] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 15:11:21,901] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 15:11:21,910] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.085 seconds
[2019-10-16 15:11:31,928] {logging_mixin.py:95} INFO - [2019-10-16 15:11:31,927] {settings.py:213} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=16300
[2019-10-16 15:11:31,934] {scheduler_job.py:146} INFO - Started process (PID=16300) to work on /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:11:31,938] {scheduler_job.py:1520} INFO - Processing file /home/sat/Projects/p1/dags/file_mover.py for tasks to queue
[2019-10-16 15:11:31,939] {logging_mixin.py:95} INFO - [2019-10-16 15:11:31,939] {dagbag.py:90} INFO - Filling up the DagBag from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:11:31,950] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['file_operations_pipeline']) retrieved from /home/sat/Projects/p1/dags/file_mover.py
[2019-10-16 15:11:31,982] {scheduler_job.py:1255} INFO - Processing file_operations_pipeline
[2019-10-16 15:11:31,998] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: file_operations_pipeline> because no tasks in DAG have SLAs
[2019-10-16 15:11:32,007] {scheduler_job.py:152} INFO - Processing /home/sat/Projects/p1/dags/file_mover.py took 0.073 seconds
